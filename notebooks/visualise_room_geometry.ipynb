{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "\n",
    "from diff_gfdn.config.config import DiffGFDNConfig\n",
    "from diff_gfdn.dataloader import ThreeRoomDataset, load_dataset, custom_collate, RoomDataset\n",
    "from diff_gfdn.gain_filters import OneHotEncoding, SinusoidalEncoding\n",
    "from src.run_model import load_and_validate_config\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Visualise the 3D mesh of the geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'data/config/'\n",
    "fig_path = 'figures/'\n",
    "config_name = 'treble_data_grid_training_1000Hz_colorless_loss.yml'\n",
    "config_file = config_path + config_name\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       DiffGFDNConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"3room_FDTD\" in config_dict.room_dataset_path:\n",
    "    room_data = ThreeRoomDataset(Path(config_dict.room_dataset_path).resolve(), config_dict)\n",
    "else:\n",
    "    room_data = convert_common_slopes_rir_to_room_dataset(config_dict.room_dataset_path, \n",
    "                                                          num_freq_bins=config_dict.trainer_config.num_freq_bins,\n",
    "                                                          )\n",
    "\n",
    "config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "room_data.plot_3D_meshgrid(room_data.mesh_3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Check if the one-hot encoding works as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3D_receiver_points(room_data: RoomDataset, rec_points: torch.Tensor):\n",
    "    \"\"\"Plot the 3D receiver points to see if one-hot encoding works\"\"\"\n",
    "    rec_pos = rec_points.cpu().detach().numpy()\n",
    "    x_rec = rec_pos[:, 0]\n",
    "    y_rec = rec_pos[:, 1]\n",
    "    z_rec = rec_pos[:, 2]\n",
    "\n",
    "    # Plot using scatter without any additional data for color\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Plot the X, Y, Z points\n",
    "    ax.scatter(x_rec, y_rec, z_rec, color='k', marker='x')\n",
    "\n",
    "    # Set the limits for all axes\n",
    "    ax.set_xlim(0,\n",
    "                room_data.room_dims[-1][0] + room_data.room_start_coord[-1][0] + 0.5)\n",
    "    ax.set_ylim(0,\n",
    "                room_data.room_dims[-1][1] + room_data.room_start_coord[-1][1] + 0.5)\n",
    "    ax.set_zlim(0, room_data.room_dims[-1][-1] + 0.5)\n",
    "\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "    ax.set_title('Receiver grid')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of groups to the config dictionary\n",
    "config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "\n",
    "if config_dict.sample_rate != room_data.sample_rate:\n",
    "    logger.warn(\"Config sample rate does not match data, alterning it\")\n",
    "    config_dict.sample_rate = sample_rate\n",
    "\n",
    "# get the training config.\n",
    "trainer_config = config_dict.trainer_config\n",
    "\n",
    "# prepare the training and validation data for DiffGFDN\n",
    "train_dataset, valid_dataset = load_dataset(\n",
    "    room_data, trainer_config.device, 1.0,\n",
    "    trainer_config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_points = []\n",
    "for data in train_dataset:\n",
    "    encoder = OneHotEncoding()\n",
    "    one_hot_encode, closest_point, _ = encoder(data['mesh_3D'], data['listener_position'])\n",
    "    closest_points.append(closest_point)\n",
    "\n",
    "closest_points = torch.stack(closest_points)\n",
    "closest_points = closest_points.view(-1, closest_points.shape[-1])\n",
    "\n",
    "plot_3D_receiver_points(room_data, closest_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Plot the Fourier encodings to see if it can capture spatial variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slope2noise.rooms import RoomGeometry\n",
    "room = RoomGeometry(room_data.sample_rate,\n",
    "                    room_data.num_rooms,\n",
    "                    np.array(room_data.room_dims),\n",
    "                    np.array(room_data.room_start_coord),\n",
    "                    aperture_coords=room_data.aperture_coords)\n",
    "\n",
    "npos = 0\n",
    "num_encoded_features = 3 * 2 * config_dict.output_filter_config.num_fourier_features\n",
    "encoded_positions = np.zeros((room_data.num_rec, num_encoded_features))\n",
    "shuffled_positions = np.zeros((room_data.num_rec, 3))\n",
    "\n",
    "for data in train_dataset:\n",
    "    encoder = SinusoidalEncoding(num_fourier_features=config_dict.output_filter_config.num_fourier_features)\n",
    "    encoded_positions[npos*trainer_config.batch_size:(npos+1)*trainer_config.batch_size, :] = encoder(data['norm_listener_position'])\n",
    "    shuffled_positions[npos*trainer_config.batch_size:(npos+1)*trainer_config.batch_size, :] = data['listener_position']\n",
    "    npos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(config_dict.output_filter_config.num_fourier_features):\n",
    "    room.plot_amps_at_receiver_points(\n",
    "            shuffled_positions,\n",
    "            np.squeeze(np.array(room_data.source_position)),\n",
    "            encoded_positions[:, k*6:k*6 + 3].T,\n",
    "            scatter_plot=False,\n",
    "            cur_freq_hz=None,\n",
    "            title=f'Sine Fourier encodings, order = {k}',\n",
    "            save_path=f'figures/spatial_encodings/sine_encoding_order={k}.png')\n",
    "\n",
    "    room.plot_amps_at_receiver_points(\n",
    "                shuffled_positions,\n",
    "                np.squeeze(np.array(room_data.source_position)),\n",
    "                encoded_positions[:, k*6 + 3:k*6 + 6].T,\n",
    "                scatter_plot=False,\n",
    "                cur_freq_hz=None,\n",
    "                title=f'Cosine Fourier encodings, order = {k}',\n",
    "                save_path=f'figures/spatial_encodings/cosine_encoding_order={k}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
