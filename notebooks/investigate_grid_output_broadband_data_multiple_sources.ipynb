{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from torch import nn\n",
    "from numpy.typing import ArrayLike\n",
    "from typing import Optional, List\n",
    "from IPython import display\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "from copy import deepcopy\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "\n",
    "from diff_gfdn.dataloader import load_dataset, RIRData\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n",
    "from diff_gfdn.model import DiffGFDNVarSourceReceiverPos\n",
    "from diff_gfdn.utils import is_unitary, db2lin, db, ms_to_samps, get_response\n",
    "from diff_gfdn.plot import plot_edr, animate_coupled_feedback_matrix, plot_amps_in_space, plot_edc_error_in_space\n",
    "from diff_gfdn.analysis import get_decay_fit_net_params\n",
    "from diff_gfdn.colorless_fdn.utils import get_colorless_fdn_params\n",
    "from src.run_model import load_and_validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'data/config/'\n",
    "fig_path = 'figures/'\n",
    "config_name = 'synth_data_broadband_two_coupled_rooms_multi_source_colorless_loss.yml'\n",
    "config_file = config_path + config_name\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       DiffGFDNConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_data = convert_common_slopes_rir_to_room_dataset(config_dict.room_dataset_path, \n",
    "                                                      num_freq_bins=config_dict.trainer_config.num_freq_bins,\n",
    "                                                      )\n",
    "\n",
    "config_dict = config_dict.copy(update={\"num_groups\": room_data.num_rooms})\n",
    "\n",
    "trainer_config = config_dict.trainer_config\n",
    "\n",
    "# force the trainer config device to be CPU\n",
    "if trainer_config.device != 'cpu':\n",
    "    trainer_config = trainer_config.copy(update={\"device\": 'cpu'})\n",
    "\n",
    "# prepare the training and validation data for DiffGFDN\n",
    "train_dataset, valid_dataset = load_dataset(\n",
    "    room_data, trainer_config.device, train_valid_split_ratio=1.0,\n",
    "    batch_size=trainer_config.batch_size, shuffle=False)\n",
    "\n",
    "# get the colorless FDN params\n",
    "if config_dict.colorless_fdn_config.use_colorless_prototype:\n",
    "    colorless_fdn_params = get_colorless_fdn_params(config_dict)\n",
    "else:\n",
    "    colorless_fdn_params = None\n",
    "\n",
    "# initialise the model\n",
    "model = DiffGFDNVarSourceReceiverPos(config_dict.sample_rate,\n",
    "                 config_dict.num_groups,\n",
    "                 config_dict.delay_length_samps,\n",
    "                 trainer_config.device,\n",
    "                 config_dict.feedback_loop_config,\n",
    "                 config_dict.output_filter_config,\n",
    "                 config_dict.input_filter_config,\n",
    "                 use_absorption_filters=False,\n",
    "                 common_decay_times=room_data.common_decay_times,\n",
    "                 colorless_fdn_params=colorless_fdn_params,\n",
    "                 use_colorless_loss=trainer_config.use_colorless_loss\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory  = Path(\"audio/\")\n",
    "fig_path = Path(\"figures\").resolve()\n",
    "checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "max_epochs = trainer_config.max_epochs\n",
    "plot_ir = True\n",
    "use_fixed_pos = True\n",
    "if use_fixed_pos:\n",
    "    rec_pos_to_investigate = [1.12, 1.47, 1.69]\n",
    "    src_pos_to_investigate = [4.48, 2.59, 1.29]\n",
    "else:\n",
    "    rec_idx = np.random.randint(0, high=room_data.num_rec, size=1, dtype=int)\n",
    "    src_idx = np.random.randint(0, high=room_data.num_src, size=1, dtype=int)\n",
    "    rec_pos_to_investigate = np.round(np.squeeze(room_data.receiver_position[rec_idx,:]), 2)\n",
    "    src_pos_to_investigate = np.round(np.squeeze(room_data.source_position[src_idx,:]), 2)\n",
    "desired_filename = f'ir_src_pos=({src_pos_to_investigate[0]:.2f}, {src_pos_to_investigate[1]:.2f}, {src_pos_to_investigate[2]:.2f})'\\\n",
    "+f'_rec_pos=({rec_pos_to_investigate[0]:.2f}, {rec_pos_to_investigate[1]:.2f}, {rec_pos_to_investigate[2]:.2f}).wav'\n",
    "\n",
    "# find amplitudes corresponding to the receiver position\n",
    "rec_pos_idx = np.argwhere(\n",
    "    np.all(np.round(room_data.receiver_position,2) == rec_pos_to_investigate, axis=1))[0]\n",
    "src_pos_idx = np.argwhere(\n",
    "    np.all(np.round(room_data.source_position,2) == src_pos_to_investigate, axis=1))[0] \n",
    "amps_at_pos = np.squeeze(room_data.amplitudes[src_pos_idx, rec_pos_idx, :])\n",
    "h_true = np.squeeze(room_data.rirs[src_pos_idx, rec_pos_idx, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Iterate through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_approx_list = []\n",
    "output_gains = []\n",
    "input_gains = []\n",
    "input_scalars = []\n",
    "output_scalars = []\n",
    "coupled_feedback_matrix = []\n",
    "coupling_matrix = []\n",
    "all_rirs_mat = np.zeros_like(room_data.rirs)\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # load the trained weights for the particular epoch\n",
    "    checkpoint = torch.load(f'{checkpoint_dir}/model_e{epoch}.pt', weights_only=True, map_location=torch.device('cpu'))\n",
    "    # Load the trained model state\n",
    "    model.load_state_dict(checkpoint)\n",
    "    # in eval mode, no gradients are calculated\n",
    "    model.eval()\n",
    "    break_outer_loop = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        param_dict = model.get_param_dict()\n",
    "        input_gains.append(deepcopy(param_dict['input_gains']))\n",
    "        output_gains.append(deepcopy(param_dict['output_gains']))\n",
    "        coupled_feedback_matrix.append(deepcopy(param_dict['coupled_feedback_matrix']))\n",
    "        coupling_matrix.append(deepcopy(param_dict['coupling_matrix']))\n",
    "    \n",
    "        for data in train_dataset:\n",
    "            rec_position = data['listener_position']\n",
    "            src_position = data['source_position']\n",
    "            rec_pos_idx = np.zeros(trainer_config.batch_size, dtype=np.int32)\n",
    "            src_pos_idx = np.zeros(trainer_config.batch_size, dtype=np.int32)\n",
    "            \n",
    "            if trainer_config.use_colorless_loss:\n",
    "                H, H_sub_fdn, h = get_response(data, model)\n",
    "            else:\n",
    "                H, h = get_response(data, model)\n",
    "\n",
    "            for (src_idx, num_pos) in zip(range(src_position.shape[0]), range(rec_position.shape[0])):\n",
    "                if epoch == max_epochs - 1:\n",
    "                    rec_pos_idx[num_pos] = np.argwhere(np.all(np.isclose(room_data.receiver_position, rec_position[num_pos]), axis=1))[0][0]\n",
    "                    src_pos_idx[src_idx] = np.argwhere(np.all(np.isclose(room_data.source_position, src_position[src_idx]), axis=1))[0][0]\n",
    "\n",
    "                filename = f'ir_src_pos=({src_position[src_idx, 0]:.2f}, {src_position[src_idx, 1]:.2f}, {src_position[src_idx, 2]:.2f})'\\\n",
    "                f'_rec_pos=({rec_position[num_pos,0]:.2f}, {rec_position[num_pos, 1]:.2f}, {rec_position[num_pos, 2]:.2f}).wav'\n",
    "                \n",
    "                if filename == desired_filename:\n",
    "                    # get parameter dictionary used in inferencing\n",
    "                    inf_param_dict = model.get_param_dict_inference(data)\n",
    "\n",
    "                    # get the ir at this position\n",
    "                    h_approx_list.append(h[num_pos])\n",
    "    \n",
    "                    # get the gains for this position\n",
    "                    if 'output_scalars' in inf_param_dict.keys():\n",
    "                        output_scalars.append(deepcopy(inf_param_dict['output_scalars'][num_pos]))\n",
    "                    if 'input_scalars' in inf_param_dict.keys():\n",
    "                        input_scalars.append(deepcopy(inf_param_dict['input_scalars'][src_idx]))\n",
    "\n",
    "                    # not breaking the loop to collect all the RIRs\n",
    "                    # break_outer_loop = True\n",
    "                    # break\n",
    "            if epoch == max_epochs - 1:\n",
    "                all_rirs_mat[src_pos_idx, rec_pos_idx, :] = h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Plot the EDCs as a function of epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_edc(h_true: ArrayLike, h_approx: List[ArrayLike], fs: float, pos_to_investigate: List, amps_at_pos: List, mixing_time_ms:float=20.0):\n",
    "    \"\"\"Plot true and synthesised EDC curves\"\"\"\n",
    "    \n",
    "    mixing_time_samp = ms_to_samps(mixing_time_ms, fs)\n",
    "    crop_end_samp = ms_to_samps(5.0, fs)\n",
    "    \n",
    "    trunc_true_ir = h_true[mixing_time_samp:-crop_end_samp]\n",
    "    true_edf = np.flipud(np.cumsum(np.flipud(trunc_true_ir**2), axis=-1))\n",
    "    time = np.linspace(0, (len(trunc_true_ir) - 1) / fs,\n",
    "                       len(trunc_true_ir))\n",
    "  \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(time, db(true_edf, is_squared=True), label='True EDF')\n",
    "    ax.plot(np.zeros(len(amps_at_pos)), db(amps_at_pos, is_squared=True), 'kx')       \n",
    "    ax.set_title(\n",
    "        f'Truncated EDF at position {pos_to_investigate[0]:.2f}, {pos_to_investigate[1]:.2f}, {pos_to_investigate[2]:.2f} m'\n",
    "    )\n",
    "    \n",
    "    num_epochs = len(h_approx)\n",
    "    for epoch in range(0, num_epochs, 4):\n",
    "        approx_ir = h_approx[epoch]\n",
    "        trunc_approx_ir = approx_ir[mixing_time_samp: mixing_time_samp + len(trunc_true_ir)]\n",
    "        synth_edf = np.flipud(np.cumsum(np.flipud(trunc_approx_ir**2), axis=-1))\n",
    "        ax.plot(time, db(synth_edf, is_squared=True), label=f'Epoch={epoch}')\n",
    "        ax.legend()\n",
    "        \n",
    "        display.display(fig)  # Display the updated figure\n",
    "        display.clear_output(wait=True)  # Clear the previous output to keep updates in place\n",
    "        plt.pause(0.1)\n",
    "\n",
    "    fig.savefig(Path(f'{fig_path}/compare_synth_edf_{pos_to_investigate}_{config_name}.png').resolve())\n",
    "    plt.show()\n",
    "\n",
    "plot_edc(h_true, h_approx_list, config_dict.sample_rate, rec_pos_to_investigate, amps_at_pos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Plot the desired and final EDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edc_params(rir: ArrayLike, n_slopes: int, fs:float):\n",
    "    est_params_decay_net, norm_vals, fitted_edc_subband = get_decay_fit_net_params(rir, None, n_slopes, fs)\n",
    "    est_t60 = np.mean(est_params_decay_net[0], axis=0)\n",
    "    est_amp = np.mean(est_params_decay_net[1], axis=0)\n",
    "    est_noise = np.mean(est_params_decay_net[2], axis=0)\n",
    "    fitted_edc = torch.squeeze(torch.mean(fitted_edc_subband, dim=0))\n",
    "    return est_t60, est_amp, est_noise, fitted_edc\n",
    "\n",
    "def plot_final_decay_fit_net_edc(num_groups:int, fs: float, og_amps: List, est_amps: List, \n",
    "                                 og_edc: ArrayLike, synth_edc:ArrayLike, \n",
    "                                 src_pos:Optional[List]=None, rec_pos: Optional[List]=None):\n",
    "    \n",
    "    time = np.linspace(0, (len(og_edc) - 1) / fs, len(og_edc))\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax.plot(time, db(og_edc, is_squared=True), linestyle='-', label=f'Original estimated EDC (norm)')\n",
    "    ax.plot(time[:len(synth_edc)], db(synth_edc, is_squared=True), linestyle='--', label=f'Final estimated EDC (norm)')\n",
    "    ax.plot(np.zeros(num_groups), db(og_amps, is_squared=True), 'kx', label='Original amps')\n",
    "    ax.plot(np.zeros(num_groups), db(est_amps, is_squared=True), 'gd', label='Synth amps')\n",
    "\n",
    "    if src_pos is not None and rec_pos is not None:\n",
    "        ax.set_title(f\"Source pos = {np.round(src_pos, 2)}, receiver pos = {np.round(rec_pos, 2)}\")\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "mixing_time_samp = ms_to_samps(20.0, config_dict.sample_rate)\n",
    "crop_end_samp = ms_to_samps(5.0, config_dict.sample_rate)\n",
    "trunc_true_ir = h_true[mixing_time_samp:-crop_end_samp]\n",
    "trunc_approx_ir = h_approx_list[-1][mixing_time_samp:len(trunc_true_ir)]\n",
    "og_est_t60, og_est_amp, og_noise_floor, og_fitted_edc = get_edc_params(trunc_true_ir, config_dict.num_groups, config_dict.sample_rate)\n",
    "est_t60, est_amp, _, fitted_edc = get_edc_params(trunc_approx_ir, config_dict.num_groups, config_dict.sample_rate)\n",
    "\n",
    "plot_final_decay_fit_net_edc(config_dict.num_groups, config_dict.sample_rate, amps_at_pos, est_amp, og_fitted_edc, fitted_edc, \n",
    "                             src_pos=src_pos_to_investigate, rec_pos=rec_pos_to_investigate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Get the overall amplitude and EDC mismatch as a function of spatial location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import diff_gfdn\n",
    "reload(diff_gfdn.plot)\n",
    "from diff_gfdn.plot import plot_amps_in_space, plot_edc_error_in_space\n",
    "\n",
    "plot_edc_error_in_space(room_data, all_rirs_mat, room_data.receiver_position, freq_to_plot=None, \n",
    "                         scatter=True, save_path=f'{fig_path}/{config_name}_mlp', pos_sorted=True)\n",
    "\n",
    "estimated_amps = plot_amps_in_space(room_data, all_rirs_mat, room_data.receiver_position, \n",
    "                                    freq_to_plot=None, scatter=True, save_path=f'{fig_path}/multiple_sources/{config_name}_mlp', pos_sorted=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
