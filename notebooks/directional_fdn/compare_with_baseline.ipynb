{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from loguru import logger\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from typing import List\n",
    "from scipy.fft import rfft, irfft\n",
    "import spaudiopy as spa\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('../..')\n",
    "from spatial_sampling.dataloader import parse_three_room_data, SpatialRoomDataset, load_dataset\n",
    "from src.sofa_parser import HRIRSOFAReader, SRIRSOFAWriter, convert_srir_to_brir\n",
    "from src.sound_examples import binaural_dynamic_rendering\n",
    "from src.dataclass import NAFDatasetUnpickler, NAFDatasetTrain, NAFDatasetInfer\n",
    "\n",
    "from diff_gfdn.config.config import DiffGFDNConfig\n",
    "from diff_gfdn.inference import infer_all_octave_bands_directional_fdn\n",
    "from diff_gfdn.plot import plot_edc_error_in_space, plot_edr_error_in_space, order_position_matrices\n",
    "from diff_gfdn.utils import ms_to_samps\n",
    "from diff_gfdn.config.config_loader import load_and_validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'output/directional_fdn/'\n",
    "room_data_pkl_path = Path('resources/Georg_3room_FDTD/srirs_spatial.pkl').resolve()\n",
    "config_path = Path('data/config/directional_fdn/').resolve()\n",
    "fig_path = Path('figures/directional_fdn').resolve()\n",
    "save_path = Path('resources/Georg_3room_FDTD').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_list = [63, 125, 250, 500, 1000, 2000, 4000, 8000]\n",
    "grid_resolution_m = 0.9\n",
    "config_dicts = []\n",
    "\n",
    "for k in range(len(freqs_list)):\n",
    "    config_name = f'/treble_data_grid_training_{freqs_list[k]}Hz_directional_fdn_grid_res={grid_resolution_m:.1f}m.yml'\n",
    "    cur_config_dict = load_and_validate_config(str(config_path) + config_name, DiffGFDNConfig)\n",
    "    config_dicts.append(cur_config_dict)\n",
    "    \n",
    "hrtf_path = Path('resources/HRTF/48kHz/KEMAR_Knowl_EarSim_SmallEars_FreeFieldComp_48kHz.sofa')\n",
    "\n",
    "# get the original dataset\n",
    "room_data = parse_three_room_data(room_data_pkl_path)\n",
    "\n",
    "# get the HRTF\n",
    "hrtf_reader = HRIRSOFAReader(hrtf_path)\n",
    "\n",
    "if hrtf_reader.fs != room_data.sample_rate:\n",
    "    logger.info(\n",
    "            f\"Resampling HRTFs to {room_data.sample_rate:.0f} Hz\")\n",
    "    hrtf_reader.resample_hrirs(room_data.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Get BRIRs from trained DFDNs / NAFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the only directions in NAF\n",
    "head_orientations = np.zeros((4, 2))\n",
    "head_orientations[:, 0] = np.array([0, 90, 180, 270])\n",
    "num_ori = head_orientations.shape[0]\n",
    "num_ears = 2\n",
    "error_edc = {}\n",
    "error_edr = {}\n",
    "leave_out_samps = ms_to_samps(5,room_data.sample_rate)\n",
    "mixing_time_samps = ms_to_samps(room_data.mixing_time_ms, room_data.sample_rate)\n",
    "trunc_at = ms_to_samps(2000, room_data.sample_rate)\n",
    "\n",
    "method = 'dfdn'\n",
    "logger.info(f\"Creating BRIRs for spacing = {grid_resolution_m:.1f}m\")\n",
    "if method == 'dfdn':\n",
    "    brir_pkl_path = f'{save_path}/diff_dfdn_pred_brirs_test_pos_only_grid_spacing={grid_resolution_m:.1f}m.pkl'\n",
    "elif method == 'naf':\n",
    "    brir_pkl_path = f'{save_path}/naf_dataset_infer_grid_spacing={grid_resolution_m:.1f}m.pkl'\n",
    "input_pkl_path = f'{save_path}/naf_dataset_grid_spacing={grid_resolution_m:.1f}m.pkl'\n",
    "cur_key = f'diff_dfdn_grid_spacing={grid_resolution_m:.1f}'\n",
    "error_edc[cur_key] = np.zeros((num_ori, num_ears))\n",
    "error_edr[cur_key] = np.zeros((num_ori, num_ears))\n",
    "\n",
    "\n",
    "with open(input_pkl_path, \"rb\") as f:\n",
    "    ref_naf_dataset = NAFDatasetUnpickler(f).load()\n",
    "infer_pos_list = ref_naf_dataset.infer_receiver_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(brir_pkl_path):\n",
    "    logger.info(f'BRIRs already saved for grid spacing = {grid_resolution_m:.1f}m')\n",
    "    with open(brir_pkl_path, \"rb\") as f:\n",
    "        brir_dataset = NAFDatasetUnpickler(f).load()\n",
    "    pred_brirs = brir_dataset.infer_brirs\n",
    "    pred_cs_room_data = deepcopy(room_data)\n",
    "    pred_cs_room_data.update_receiver_pos(infer_pos_list)\n",
    "else:\n",
    "    save_pkl_path = f'{out_path}/pred_ambi_rirs_test_pos_only_grid_res={grid_resolution_m:.1f}m/'\n",
    "    pred_cs_room_data = infer_all_octave_bands_directional_fdn(freqs_list,                                                        \n",
    "                                                               config_dicts, \n",
    "                                                               save_pkl_path, \n",
    "                                                               room_data, \n",
    "                                                               rec_pos_list=ref_naf_dataset.infer_receiver_pos,\n",
    "                                                              )\n",
    "  \n",
    "\n",
    "    pred_brirs = convert_srir_to_brir(pred_cs_room_data.rirs, hrtf_reader, head_orientations)\n",
    "    # ensure the position ordering is correct\n",
    "    logger.info(\"Ordering position data...\")\n",
    "    correct_pos_order = order_position_matrices(ref_naf_dataset.infer_receiver_pos, pred_cs_room_data.receiver_position)\n",
    "    pred_brirs = pred_brirs[correct_pos_order, ...]\n",
    "    # save dataset\n",
    "    dfdn_brir_dataset = NAFDatasetInfer(head_orientations[:, 0],\n",
    "                                       ref_naf_dataset.num_infer_receivers,\n",
    "                                       ref_naf_dataset.infer_receiver_pos,\n",
    "                                       gt_brirs = ref_naf_dataset.infer_brirs,\n",
    "                                       infer_brirs = pred_brirs\n",
    "                                       )\n",
    "    with open(brir_pkl_path, \"wb\") as f:\n",
    "        pickle.dump(dfdn_brir_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Plot an example BRIR for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slope2noise.utils import schroeder_backward_int\n",
    "from diff_gfdn.utils import db\n",
    "time_slice_idx = np.arange(mixing_time_samps, trunc_at-leave_out_samps, dtype=np.int32)\n",
    "\n",
    "true_brir = ref_naf_dataset.infer_brirs[53, 0, time_slice_idx, :]\n",
    "pred_brir = pred_brirs[53, 0, time_slice_idx, :]\n",
    "true_brir_edc = db(schroeder_backward_int(true_brir, time_axis=-2, normalize=True), is_squared=True)\n",
    "pred_brir_edc = db(schroeder_backward_int(pred_brir, time_axis=-2, normalize=True), is_squared=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(true_brir)\n",
    "plt.figure()\n",
    "plt.plot(pred_brir)\n",
    "plt.figure()\n",
    "plt.plot(true_brir_edc)\n",
    "plt.plot(pred_brir_edc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_to_investigate = [6.4, 3.2, 1.5]\n",
    "\n",
    "# find amplitudes corresponding to the receiver position\n",
    "rec_pos_idx = np.argwhere(\n",
    "    np.all(np.round(room_data.receiver_position,2) == pos_to_investigate, axis=1))[0]\n",
    "rec_pos_idx_pred = np.argwhere(\n",
    "    np.all(np.round(pred_cs_room_data.receiver_position,2) == pos_to_investigate, axis=1))[0]\n",
    "\n",
    "true_srir = room_data.rirs[rec_pos_idx, :, time_slice_idx]\n",
    "pred_srir = pred_cs_room_data.rirs[rec_pos_idx_pred, :, time_slice_idx]\n",
    "true_srir_edc = db(schroeder_backward_int(true_srir.copy(), time_axis=0, normalize=True), is_squared=True)\n",
    "pred_srir_edc = db(schroeder_backward_int(pred_srir.copy(), time_axis=0, normalize=True), is_squared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(true_srir_edc[:, 6])\n",
    "plt.plot(pred_srir_edc[:, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Calculate overall EDC error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the EDC error per orientation and ear\n",
    "time_slice_idx = np.arange(mixing_time_samps, mixing_time_samps + trunc_at-leave_out_samps, dtype=np.int32)\n",
    "\n",
    "for ori in range(head_orientations.shape[0]):\n",
    "    for ear in range(2):\n",
    "        cur_room_data = deepcopy(room_data)\n",
    "        cur_room_data.update_receiver_pos(infer_pos_list)\n",
    "        cur_room_data.update_rirs(ref_naf_dataset.infer_brirs[:, ori, time_slice_idx, ear])\n",
    "        cur_brirs = np.squeeze(pred_brirs[:, ori, time_slice_idx, ear])\n",
    "\n",
    "        save_path_edc = f'{fig_path}/edc_error_{method}_brir_ori={int(head_orientations[ori, 0])}_ear={ear}_grid_spacing={grid_resolution_m:.1f}m.png'\n",
    "        save_path_edr = f'{fig_path}/edr_error_{method}_brir_ori={int(head_orientations[ori, 0])}_ear={ear}_grid_spacing={grid_resolution_m:.1f}m.png'\n",
    "        \n",
    "        ## NOTE- IT IS VERY IMPORTANT TO SET NORM_EDC = TRUE.\n",
    "        #This is because the MLPs were trained on EDCs created from the common slope parameters(this reduced the amount of\n",
    "        #data to be loaded during training and sped it up considerably). Now, the common slope amps have been normalised\n",
    "        #in the downloaded dataset. Therefore, the scale of the predicted and true EDC won't match unless we normalise the EDCs.\n",
    "        \n",
    "        err_edc = plot_edc_error_in_space(cur_room_data, cur_brirs, infer_pos_list, scatter=True, \n",
    "                                          pos_sorted=True, save_path=save_path_edc, norm_edc=True)\n",
    "        error_edc[cur_key][ori, ear] = err_edc\n",
    "        err_edr = plot_edr_error_in_space(cur_room_data, cur_brirs, infer_pos_list, \n",
    "                                          scatter=True, pos_sorted=True, save_path=save_path_edr)\n",
    "        error_edr[cur_key][ori, ear] = err_edr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
