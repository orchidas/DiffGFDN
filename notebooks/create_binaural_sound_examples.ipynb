{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "This notebook generates binaural sound examples for the common slopes amplitudes interpolation problem. \n",
    "First the soundfield at octave bands is generated by getting the learned amplitudes from the DNN in octave bands. Then an ambisonics RIR is\n",
    "reconstructed from the learned amplitudes using white noise shaping.\n",
    "\n",
    "Simultaneously, an HRTF dataset is loaded and converted to the ambisonics domain. The ambisonics RIRs are first rotated, according to the head orientation and then convolved with the HRTFs' SH representation. This rotated soundfield is then convolved with the input mono signal to get the binauralised output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from spatial_sampling.inference import get_ambisonic_rirs\n",
    "from spatial_sampling.dataloader import parse_room_data\n",
    "from src.sofa_parser import HRIRSOFAReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Create a trajectory of a listener moving across the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# along x axis between three rooms\n",
    "start_pos_x, start_pos_y = (0.5, 3.5)\n",
    "end_pos_x, end_pos_y = (9, 3.5)\n",
    "num_pos = 50\n",
    "\n",
    "linear_trajectory_x = np.linspace(start_pos_x, end_pos_x, num_pos)\n",
    "linear_trajectory_y = np.linspace(start_pos_y, end_pos_y, num_pos)\n",
    "linear_trajectory_z = 1.5 * np.ones(num_pos)\n",
    "\n",
    "rec_pos_list = np.zeros((num_pos, 3))\n",
    "rec_pos_list[:, 0] = linear_trajectory_x\n",
    "rec_pos_list[:, 1] = linear_trajectory_y\n",
    "rec_pos_list[:, 2] = linear_trajectory_z\n",
    "\n",
    "# along y-axis between rooms 2 and 3\n",
    "start_pos_x, start_pos_y = (9.1, 3.5)\n",
    "end_pos_x, end_pos_y = (9.0, 12.0)\n",
    "num_pos = 68\n",
    "\n",
    "linear_trajectory_x = np.linspace(start_pos_x, end_pos_x, num_pos)\n",
    "linear_trajectory_y = np.linspace(start_pos_y, end_pos_y, num_pos)\n",
    "linear_trajectory_z = 1.5 * np.ones(num_pos)\n",
    "\n",
    "rec_pos_list = np.vstack((rec_pos_list, np.vstack((linear_trajectory_x, linear_trajectory_y, linear_trajectory_z)).T))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Get the true and predicted room datasets with its corresponding ambisonics RIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_data_pkl_path = Path('resources/Georg_3room_FDTD/srirs_spatial.pkl').resolve()\n",
    "output_pkl_path = Path('output/spatial_sampling/grid_rir_treble_ambi_rirs.pkl').resolve()\n",
    "config_path = Path('data/config/spatial_sampling/').resolve()\n",
    "\n",
    "# get the full band dataset\n",
    "true_cs_room_data = parse_room_data(room_data_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import spatial_sampling\n",
    "reload(spatial_sampling.inference)\n",
    "from spatial_sampling.inference import get_ambisonic_rirs\n",
    "\n",
    "# get predicted output from the trained models\n",
    "if not os.path.exists(output_pkl_path):\n",
    "    pred_cs_room_data = get_ambisonic_rirs(rec_pos_list, output_pkl_path, true_cs_room_data, config_path)\n",
    "else:\n",
    "    with open(output_pkl_path, \"rb\") as f:\n",
    "        pred_cs_room_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Load the HRTF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrtf_path = Path('resources/HRTF/48kHz/KEMAR_Knowl_EarSim_SmallEars_FreeFieldComp_48kHz.sofa')\n",
    "hrtf_reader = HRIRSOFAReader(hrtf_path, true_cs_room_data.ambi_order)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
