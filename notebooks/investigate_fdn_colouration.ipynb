{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### In this notebook, we want to investigate the colouration when we filter and sum multiple subband GFDNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio.functional as F\n",
    "import re\n",
    "import pyfar as pf\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "scale = 2\n",
    "plt.rcParams.update({\n",
    "    'font.size': scale * 8,  # base font size\n",
    "    'axes.labelsize': scale * 9,  # x/y label\n",
    "    'xtick.labelsize': scale * 8,\n",
    "    'ytick.labelsize': scale * 8,\n",
    "    'legend.fontsize': scale * 8,\n",
    "    'axes.titlesize': scale * 10,  # usually unused in journal figures\n",
    "})\n",
    "\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import sosfreqz, sosfiltfilt\n",
    "from scipy.fft import rfft, irfft, rfftfreq\n",
    "from torch import nn\n",
    "from torchaudio.functional import lfilter\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from typing import Optional, List, Tuple\n",
    "from IPython import display\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "from copy import deepcopy\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "\n",
    "from diff_gfdn.dataloader import load_dataset, RIRData, ThreeRoomDataset, RoomDataset\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType, SubbandProcessingConfig\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n",
    "from diff_gfdn.model import DiffGFDNVarReceiverPos\n",
    "from diff_gfdn.utils import db, ms_to_samps,is_unitary, get_response, spectral_flatness, normalised_echo_density, time_reversed_filtering\n",
    "from diff_gfdn.plot import plot_magnitude_response\n",
    "from diff_gfdn.colorless_fdn.utils import get_colorless_fdn_params\n",
    "from diff_gfdn.colorless_fdn.model import ColorlessFDN\n",
    "from slope2noise.utils import schroeder_backward_int\n",
    "from src.run_model import load_and_validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [63, 125, 250, 500, 1000, 2000, 4000, 8000]\n",
    "num_fir_taps = 2**12\n",
    "\n",
    "for k in range(len(freqs)):\n",
    "    config_path = 'data/config/'\n",
    "    fig_path = 'figures/'\n",
    "    config_name = f'treble_data_grid_training_{freqs[k]}Hz_colorless_loss_diff_delays'\n",
    "    config_file = config_path + config_name\n",
    "    config_dict = load_and_validate_config(config_file + '.yml',\n",
    "                                           DiffGFDNConfig)\n",
    "    room_data = ThreeRoomDataset(Path(config_dict.room_dataset_path).resolve(), config_dict)\n",
    "    dataset_has_cs_params = True    \n",
    "    config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "    trainer_config = config_dict.trainer_config\n",
    "\n",
    "    ## initialise variables\n",
    "    if k == 0:\n",
    "        H_fdn_init = torch.zeros((trainer_config.num_freq_bins // 2 + 1, config_dict.num_groups, len(freqs)), \n",
    "                            dtype=torch.complex64, requires_grad=False)\n",
    "        H_fdn_subband_init = torch.zeros(((trainer_config.num_freq_bins  + num_fir_taps) // 2, config_dict.num_groups, len(freqs)), \n",
    "                            dtype=torch.complex64, requires_grad=False)\n",
    "        \n",
    "        H_fdn_final = torch.zeros_like(H_fdn_init)\n",
    "        H_fdn_subband_final = torch.zeros_like(H_fdn_subband_init)\n",
    "    \n",
    "    # force the trainer config device to be CPU\n",
    "    if trainer_config.device != 'cpu':\n",
    "        trainer_config = trainer_config.model_copy(update={\"device\": 'cpu'})\n",
    "\n",
    "    # get the colorless FDN params\n",
    "    if config_dict.colorless_fdn_config.use_colorless_prototype:\n",
    "        colorless_fdn_params = get_colorless_fdn_params(config_dict)\n",
    "    else:\n",
    "        colorless_fdn_params = None\n",
    "    \n",
    "    # initialise the model\n",
    "    model = DiffGFDNVarReceiverPos(config_dict.sample_rate,\n",
    "                     config_dict.num_groups,\n",
    "                     config_dict.delay_length_samps,\n",
    "                     trainer_config.device,\n",
    "                     config_dict.feedback_loop_config,\n",
    "                     config_dict.output_filter_config,\n",
    "                     config_dict.decay_filter_config.use_absorption_filters,\n",
    "                     common_decay_times=room_data.common_decay_times if config_dict.decay_filter_config.initialise_with_opt_values else None,\n",
    "                     learn_common_decay_times=config_dict.decay_filter_config.learn_common_decay_times,\n",
    "                     colorless_fdn_params=colorless_fdn_params,\n",
    "                     use_colorless_loss=trainer_config.use_colorless_loss\n",
    "                     )\n",
    "\n",
    "    ### Get each FDN's magnitude response\n",
    "    freq_bins_rad = torch.tensor(room_data.freq_bins_rad)\n",
    "    freq_bins_hz = torch.fft.rfftfreq((trainer_config.num_freq_bins  + num_fir_taps - 1), d=1.0/config_dict.sample_rate)\n",
    "    z_values = torch.polar(torch.ones_like(freq_bins_rad),\n",
    "                           freq_bins_rad)\n",
    "    \n",
    "    # load the trained weights for the particular epoch\n",
    "    max_epochs = trainer_config.max_epochs\n",
    "    checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "\n",
    "    init_checkpoint = torch.load(f'{checkpoint_dir}/model_e-1.pt',\n",
    "                                 weights_only=True,\n",
    "                                 map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(init_checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    H_fdn_init[...,k], _ = model.sub_fdn_output(z_values)\n",
    "\n",
    "    final_checkpoint = torch.load(f'{checkpoint_dir}/model_e{max_epochs-1}.pt',\n",
    "                                  weights_only=True,\n",
    "                                  map_location=torch.device('cpu'))\n",
    "    # Load the trained model state\n",
    "\n",
    "    model.load_state_dict(final_checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    \n",
    "    # check for losslessness\n",
    "    param_dict = model.get_param_dict()\n",
    "    coupled_feedback_matrix = torch.tensor(param_dict['coupled_feedback_matrix'])\n",
    "    feedback_matrix = torch.tensor(param_dict['individual_mixing_matrix'])\n",
    "    assert [is_unitary(feedback_matrix[n]) for n in range(config_dict.num_groups)]\n",
    "    assert is_unitary(coupled_feedback_matrix)\n",
    "    \n",
    "    H_fdn_final[..., k] , _ = model.sub_fdn_output(z_values)\n",
    "\n",
    "    ### Filter the sub-FDN outputs with the pyfar filters, sum them and observe colouration\n",
    "    if trainer_config.subband_process_config.use_amp_preserving_filterbank:\n",
    "        if k == 0:\n",
    "            subband_filters, subband_freqs = pf.dsp.filter.reconstructing_fractional_octave_bands(\n",
    "                        None,\n",
    "                        num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                        frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "                        sampling_rate=config_dict.sample_rate,\n",
    "            )\n",
    "\n",
    "        subband_filter_idx = np.argmin(\n",
    "            np.abs(subband_freqs -\n",
    "                   trainer_config.subband_process_config.centre_frequency))\n",
    "        subband_filter = torch.tensor(\n",
    "            subband_filters.coefficients[subband_filter_idx])\n",
    "      \n",
    "        # proper filtering with linear convolution\n",
    "        H_fdn_subband_init[..., k] = torch.fft.rfft(F.fftconvolve(torch.fft.irfft(H_fdn_init[..., k], dim=0).T, \n",
    "                                                                  subband_filter.unsqueeze(0)), dim=-1).T\n",
    "        H_fdn_subband_final[..., k] = torch.fft.rfft(F.fftconvolve(torch.fft.irfft(H_fdn_final[..., k], dim=0).T, \n",
    "                                                                   subband_filter.unsqueeze(0)), dim=-1).T\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if k == 0:\n",
    "            subband_filters = pf.dsp.filter.fractional_octave_bands(\n",
    "                    None,\n",
    "                    num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                    frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "                    sampling_rate=config_dict.sample_rate,\n",
    "                )\n",
    "            subband_freqs, _ = pf.dsp.filter.fractional_octave_frequencies(\n",
    "                num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "            )\n",
    "\n",
    "        subband_filter_idx = np.argmin(\n",
    "            np.abs(subband_freqs -\n",
    "                   trainer_config.subband_process_config.centre_frequency))\n",
    "    \n",
    "        # safest to filter in time domain and then take transform\n",
    "        h_fdn_subband_init = sosfiltfilt(subband_filters.coefficients[subband_filter_idx, ...], \n",
    "                                         torch.fft.irfft(H_fdn_init[...,k], dim=0).detach().numpy(), \n",
    "                                         axis=0)\n",
    "        H_fdn_subband_init[...,k] = torch.fft.rfft(torch.from_numpy(h_fdn_subband_init.copy()), n=trainer_config.num_freq_bins, dim=0)\n",
    "        \n",
    "        h_fdn_subband_final = sosfiltfilt(subband_filters.coefficients[subband_filter_idx, ...], \n",
    "                                          torch.fft.irfft(H_fdn_final[...,k], dim=0).detach().numpy(), \n",
    "                                          axis=0)\n",
    "        H_fdn_subband_final[...,k] = torch.fft.rfft(torch.from_numpy(h_fdn_subband_final.copy()), n=trainer_config.num_freq_bins, dim=0) \n",
    "\n",
    "    \n",
    "    # plot colouration of individual FDNs\n",
    "    save_path = f'{fig_path}/{config_name}_mag_spectrum.png'\n",
    "    plot_magnitude_response(room_data, config_dict, model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Plot colouration of filtered and summed FDNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_response_plot(room_data:RoomDataset, H_sub_fdn_filtered: NDArray, freq_bins_hz:torch.tensor, freq_labels:List[int], \n",
    "                      title:Optional[str]=None, save_path:Optional[str] = None, subband_filter_coeffs: Optional[NDArray]=None):\n",
    "    \"\"\"Plot magnitude response of filtered sub-FDN responses\n",
    "    Args:\n",
    "        H_sub_fdn_filtered is of shape num_bins x num_groups x num_freq_bands\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(room_data.num_rooms,\n",
    "                             1,\n",
    "                             figsize=(8, 10),\n",
    "                             sharex=True)\n",
    "\n",
    "    if subband_filter_coeffs is not None:\n",
    "        subband_filter_response = rfft(subband_filter_coeffs, n=2 * H_sub_fdn_filtered.shape[0]-1, axis=-1)\n",
    "\n",
    "    for i in range(room_data.num_rooms):\n",
    "       \n",
    "        axes[i].semilogx(\n",
    "            freq_bins_hz,\n",
    "            db(H_sub_fdn_filtered[:, i, :]),\n",
    "            label=[f\"{freq_labels[k]} Hz\" for k in range(len(freq_labels))],\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.6,\n",
    "        )\n",
    "\n",
    "        axes[i].semilogx(freq_bins_hz, db(np.sum(H_sub_fdn_filtered[:,i,:], axis=-1)), \n",
    "                         label='summed', linestyle=':')\n",
    "        \n",
    "        if subband_filter_coeffs is not None:\n",
    "            axes[i].semilogx(\n",
    "                freq_bins_hz,\n",
    "                db(subband_filter_response.T),\n",
    "                label=[f\"OG filter response at {freq_labels[k]} Hz\" for k in range(len(freq_labels))],\n",
    "                linestyle=\"-.\",\n",
    "                alpha=0.8,\n",
    "            )\n",
    "\n",
    "        # axes[i].semilogx(freq_bins_hz, db(np.sum(subband_filter_response, axis=0)), \n",
    "        #                  label='summed filter response', linestyle='-')\n",
    "\n",
    "        # draw octave bands\n",
    "        for freq in freq_labels:\n",
    "            axes[i].axvline(freq, ymin=0, ymax=1, color=\"red\", linestyle=\"--\")\n",
    "        \n",
    "\n",
    "        axes[i].set_ylabel(\"Magnitude (dB)\")\n",
    "        axes[i].set_xlabel('Frequencies (Hz)')\n",
    "        axes[i].set_title(f\"FDN {i+1}\")\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_xlim([20, 16000])\n",
    "        axes[i].set_ylim([-60, 20])\n",
    "\n",
    "        logger.info(\n",
    "            f'FDN {i+1} spectral flatness is {spectral_flatness(db(np.sum(H_sub_fdn_filtered[:, i, :], axis=-1))):.3f}'\n",
    "        )\n",
    "    \n",
    "    axes[i].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    # plt.tight_layout()\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def impulse_response_plot(room_data:RoomDataset, H_sub_fdn_filtered: NDArray, freq_labels:List[int], \n",
    "                      title:Optional[str]=None, save_path:Optional[str] = None):\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(room_data.num_rooms,\n",
    "                             1,\n",
    "                             figsize=(8, 10),\n",
    "                             sharex=True)\n",
    "    \n",
    "    h_sub_fdn_filtered = irfft(H_sub_fdn_filtered, axis=0)\n",
    "    time = np.arange(0, h_sub_fdn_filtered.shape[0]/room_data.sample_rate, 1.0/room_data.sample_rate)\n",
    "\n",
    "    for i in range(room_data.num_rooms):\n",
    "        for k in range(H_sub_fdn_filtered.shape[-1]):\n",
    "            axes[i].plot(\n",
    "                time,\n",
    "                db(h_sub_fdn_filtered[:, i, k]),\n",
    "                label=f\"{freq_labels[k]} Hz\",\n",
    "                linestyle=\"-\",\n",
    "                alpha=0.8,\n",
    "            )\n",
    "            # display.display(fig)  # Display the updated figure\n",
    "            # display.clear_output(wait=True)  # Clear the previous output to keep updates in place\n",
    "            # plt.pause(1.0)\n",
    "\n",
    "        # axes[i].plot(time, db(np.sum(h_sub_fdn_filtered[:,i,:], axis=-1)), \n",
    "        #                  label='summed', linestyle='--', alpha=0.8)\n",
    "        \n",
    "        axes[i].set_ylabel(\"Amplitude (dB)\")\n",
    "        axes[i].set_xlabel('Time (s)')\n",
    "        axes[i].set_title(f\"FDN {i+1}\")\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_ylim([-80, 0])\n",
    "    \n",
    "    axes[i].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    plt.tight_layout()\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Pre-optimisation response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = Path('figures/').resolve()\n",
    "save_path = f'{fig_path}/test_plots/{config_name}_init_gfdn_summed_spectrum.png'\n",
    "mag_response_plot(room_data, H_fdn_subband_init.detach().numpy(), freq_bins_hz, freqs, title=\"Initialisation\", save_path=save_path)\n",
    "\n",
    "impulse_response_plot(room_data, H_fdn_subband_init.detach().numpy(), freqs, \n",
    "                      title=\"Initialisation\", \n",
    "                      save_path=f'{save_path[:-4]}_ir.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Post-optimisation response, no filterbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = Path('figures/').resolve()\n",
    "save_path = f'{fig_path}/test_plots/{config_name}_opt_gfdn_summed_spectrum.png'\n",
    "mag_response_plot(room_data, H_fdn_final.detach().numpy(), torch.fft.rfftfreq(trainer_config.num_freq_bins, d=1.0/config_dict.sample_rate),\n",
    "                  freqs, \n",
    "                  title=\"Post optimisation, no filtering\", \n",
    "                  save_path=save_path)\n",
    "impulse_response_plot(room_data, H_fdn_final.detach().numpy(), freqs, \n",
    "                      title=\"Post optimisation, no filtering\", \n",
    "                      save_path=f'{save_path[:-4]}_ir.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Post optimisation response with filterbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'{fig_path}/test_plots/{config_name}_opt_gfdn_filtered_spectrum.png'\n",
    "mag_response_plot(room_data, H_fdn_subband_final.detach().numpy(), freq_bins_hz, freqs, \n",
    "                  title=\"Post optimisation with filtering\", \n",
    "                  save_path=save_path, \n",
    "                  # subband_filter_coeffs=subband_filters.coefficients\n",
    "                 )\n",
    "impulse_response_plot(room_data, H_fdn_subband_final.detach().numpy(), freqs, \n",
    "                      title=\"Post optimisation with filtering\", \n",
    "                      save_path=f'{save_path[:-4]}_ir.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Post optimisation filtering with time-reversed filterbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import diff_gfdn\n",
    "reload(diff_gfdn.utils)\n",
    "from diff_gfdn.utils import time_reversed_filtering\n",
    "\n",
    "if trainer_config.subband_process_config.use_amp_preserving_filterbank:\n",
    "    h_fdn_final = torch.fft.irfft(H_fdn_final, n=trainer_config.num_freq_bins, dim=0).detach().numpy()\n",
    "\n",
    "    h_fdn_subband_time_rev_final = time_reversed_filtering(h_fdn_final, subband_filters.coefficients, \n",
    "                                                           time_axis=0, \n",
    "                                                           freq_labels=subband_freqs)\n",
    "    H_fdn_subband_time_rev_final = rfft(h_fdn_subband_time_rev_final, n=trainer_config.num_freq_bins + num_fir_taps - 1, axis=0)\n",
    "\n",
    "    save_path = f'{fig_path}/test_plots/{config_name}_opt_gfdn_time_reversed_filtered_spectrum.png'\n",
    "    mag_response_plot(room_data, H_fdn_subband_time_rev_final, freq_bins_hz, freqs,\n",
    "                      title=\"Post optimisation with time-reversed filtering\", \n",
    "                      save_path=save_path,\n",
    "                     )\n",
    "    impulse_response_plot(room_data, H_fdn_subband_time_rev_final, freqs, \n",
    "                          title=\"Post optimisation with time-reversed filtering\", \n",
    "                          save_path=f'{save_path[:-4]}_ir.png',\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Get time domain impulse responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impulse response of each FDN\n",
    "h_init_fdn = torch.fft.irfft(torch.sum(H_fdn_subband_init, dim=-1), dim=0)\n",
    "h_final_fdn_no_filter = torch.fft.irfft(torch.sum(H_fdn_final, dim=-1), dim=0)\n",
    "h_final_fdn = torch.fft.irfft(torch.sum(H_fdn_subband_final, dim=-1), dim=0)\n",
    "\n",
    "# impulse response of the GFDN\n",
    "audio_path = Path('audio/filterbank_test/').resolve()\n",
    "h_final_no_filter = torch.sum(h_final_fdn_no_filter, dim=-1)\n",
    "h_init = torch.sum(h_init_fdn, dim=-1)\n",
    "h_final = torch.sum(h_final_fdn, dim=-1)\n",
    "\n",
    "if trainer_config.subband_process_config.use_amp_preserving_filterbank:\n",
    "    h_final_time_rev_fdn = irfft(np.sum(H_fdn_subband_time_rev_final, axis=-1), axis=0)\n",
    "    h_final_time_rev_fdn = np.sum(h_final_time_rev_fdn, axis=-1)\n",
    "    sf.write(f'{audio_path}/{config_name}_sum_time_rev_filtered_colorless_fdn.wav', h_final_time_rev_fdn, room_data.sample_rate)\n",
    "\n",
    "sf.write(f'{audio_path}/{config_name}_sum_colorless_gfdn.wav', h_final_no_filter.detach().numpy(), room_data.sample_rate)\n",
    "sf.write(f'{audio_path}/{config_name}_sum_filtered_colorless_gfdn.wav', h_final.detach().numpy(), room_data.sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Plot NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial group delay because of FIR filtering with pyfar\n",
    "init_fir_delay = subband_filters.coefficients[0].shape[0] // 2\n",
    "\n",
    "fs = room_data.sample_rate\n",
    "mixing_time_samp = ms_to_samps(50.0, fs)\n",
    "crop_end_samp = ms_to_samps(2000.0, fs)\n",
    "h_init_trunc = h_init[mixing_time_samp:-crop_end_samp-init_fir_delay]\n",
    "h_final_trunc = h_final[init_fir_delay+mixing_time_samp:-crop_end_samp]\n",
    "len_ir = len(h_init_trunc)\n",
    "time = np.linspace(0, (len_ir-1)/ fs, len_ir-1)\n",
    "\n",
    "ned_init = normalised_echo_density(h_init_trunc, fs, window_length_ms=50)\n",
    "ned_final = normalised_echo_density(h_final_trunc, fs, window_length_ms=50)\n",
    "\n",
    "fig, ax = plt.subplots(config_dict.num_groups + 1, 1, figsize=(6, 10))\n",
    "ax[0].plot(time, ned_init, label='Initial')\n",
    "ax[0].plot(time, ned_final, label='Post optimisation')\n",
    "for k in range(config_dict.num_groups):\n",
    "    ned_init_fdn = normalised_echo_density(h_init_fdn[mixing_time_samp:-crop_end_samp-init_fir_delay, k], fs, window_length_ms=50)\n",
    "    ned_final_fdn = normalised_echo_density(h_final_fdn[init_fir_delay + mixing_time_samp:-crop_end_samp, k], \n",
    "                                            fs, window_length_ms=50)\n",
    "    ax[k+1].plot(time, ned_init_fdn, label=f'Initial, group={k+1}')\n",
    "    ax[k+1].plot(time, ned_final_fdn, label=f'Final, group={k+1}')\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    ax[i].set_xlabel('Time (s)')\n",
    "    ax[i].set_ylabel('NED')  \n",
    "    ax[i].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax[i].set_xlim([0.001, max(time)])\n",
    "\n",
    "fig.savefig(f'{fig_path}/test_plots/{config_name}_ned.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
