{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### In this notebook, we want to investigate the colouration when we filter and sum multiple subband GFDNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import pyfar as pf\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import sosfreqz, sosfiltfilt\n",
    "from scipy.fft import rfft\n",
    "from torch import nn\n",
    "from torchaudio.functional import lfilter\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from typing import Optional, List, Tuple\n",
    "from IPython import display\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "from copy import deepcopy\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "\n",
    "from diff_gfdn.dataloader import load_dataset, RIRData, ThreeRoomDataset, RoomDataset\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType, SubbandProcessingConfig\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n",
    "from diff_gfdn.model import DiffGFDNVarReceiverPos\n",
    "from diff_gfdn.utils import db, ms_to_samps, get_response, spectral_flatness, normalised_echo_density, get_time_reversed_fir_filterbank\n",
    "from diff_gfdn.plot import plot_magnitude_response\n",
    "from diff_gfdn.colorless_fdn.utils import get_colorless_fdn_params\n",
    "from diff_gfdn.colorless_fdn.model import ColorlessFDN\n",
    "from slope2noise.utils import schroeder_backward_int\n",
    "from src.run_model import load_and_validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_reversed_filtering(num_poly: NDArray, den_poly: NDArray, signal_freq_domain: torch.Tensor, num_fft_bins: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Time reversed filtering of input signal with FIR filterbank h\n",
    "    Args:\n",
    "        num_poly, denom_poly: numerator and denominator coefficients of the time reversed filterbank\n",
    "        signal_freq_domain: input signal of shape num_freq_bins x num_bands\n",
    "    Returns:\n",
    "        torch.tensor: output signal of shape num_freq_bins x num_bands\n",
    "    \"\"\"\n",
    "    signal = torch.fft.irfft(signal_freq_domain, dim=0)\n",
    "    num_coeffs = len(num_poly) \n",
    "    output_signal = torch.zeros(*signal.shape)\n",
    "    den_poly_pad = torch.tensor(den_poly, dtype=torch.float32)\n",
    "    num_poly_pad = torch.cat([torch.tensor(num_poly.copy(), dtype=torch.float32), torch.zeros(num_coeffs-1, dtype=torch.float32)])\n",
    "    output_signal = lfilter(signal, num_poly_pad, den_poly_pad)\n",
    "    return torch.fft.rfft(output_signal, n=num_fft_bins, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [63, 125, 250, 500, 1000, 2000, 4000, 8000]\n",
    "\n",
    "for k in range(len(freqs)):\n",
    "    config_path = 'data/config/'\n",
    "    fig_path = 'figures/'\n",
    "    config_name = f'treble_data_grid_training_{freqs[k]}Hz_colorless_loss_diff_delays'\n",
    "    config_file = config_path + config_name\n",
    "    config_dict = load_and_validate_config(config_file + '.yml',\n",
    "                                           DiffGFDNConfig)\n",
    "    room_data = ThreeRoomDataset(Path(config_dict.room_dataset_path).resolve(), config_dict)\n",
    "    dataset_has_cs_params = True    \n",
    "    config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "    trainer_config = config_dict.trainer_config\n",
    "\n",
    "    ## initialise variables\n",
    "    if k == 0:\n",
    "        H_fdn_init = torch.zeros((trainer_config.num_freq_bins // 2 + 1, config_dict.num_groups, len(freqs)), \n",
    "                            dtype=torch.complex64, requires_grad=False)\n",
    "        H_fdn_subband_init = torch.zeros_like(H_fdn_init)\n",
    "        H_fdn_subband_time_rev_init = torch.zeros_like(H_fdn_init)\n",
    "        \n",
    "        H_fdn_final = torch.zeros_like(H_fdn_init)\n",
    "        H_fdn_subband_final = torch.zeros_like(H_fdn_final)\n",
    "        H_fdn_subband_time_rev_final = torch.zeros_like(H_fdn_final)\n",
    "    \n",
    "    # force the trainer config device to be CPU\n",
    "    if trainer_config.device != 'cpu':\n",
    "        trainer_config = trainer_config.model_copy(update={\"device\": 'cpu'})\n",
    "\n",
    "    # get the colorless FDN params\n",
    "    if config_dict.colorless_fdn_config.use_colorless_prototype:\n",
    "        colorless_fdn_params = get_colorless_fdn_params(config_dict)\n",
    "    else:\n",
    "        colorless_fdn_params = None\n",
    "    \n",
    "    # initialise the model\n",
    "    model = DiffGFDNVarReceiverPos(config_dict.sample_rate,\n",
    "                     config_dict.num_groups,\n",
    "                     config_dict.delay_length_samps,\n",
    "                     trainer_config.device,\n",
    "                     config_dict.feedback_loop_config,\n",
    "                     config_dict.output_filter_config,\n",
    "                     config_dict.decay_filter_config.use_absorption_filters,\n",
    "                     common_decay_times=room_data.common_decay_times if config_dict.decay_filter_config.initialise_with_opt_values else None,\n",
    "                     learn_common_decay_times=config_dict.decay_filter_config.learn_common_decay_times,\n",
    "                     colorless_fdn_params=colorless_fdn_params,\n",
    "                     use_colorless_loss=trainer_config.use_colorless_loss\n",
    "                     )\n",
    "\n",
    "    ### Get each FDN's magnitude response\n",
    "    freq_bins_rad = torch.tensor(room_data.freq_bins_rad)\n",
    "    freq_bins_hz = room_data.freq_bins_hz\n",
    "    z_values = torch.polar(torch.ones_like(freq_bins_rad),\n",
    "                           freq_bins_rad * 2 * np.pi)\n",
    "    \n",
    "    # load the trained weights for the particular epoch\n",
    "    max_epochs = trainer_config.max_epochs\n",
    "    checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "\n",
    "    init_checkpoint = torch.load(f'{checkpoint_dir}/model_e-1.pt',\n",
    "                                 weights_only=True,\n",
    "                                 map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(init_checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    H_fdn_init[...,k], _ = model.sub_fdn_output(z_values)\n",
    "\n",
    "    final_checkpoint = torch.load(f'{checkpoint_dir}/model_e{max_epochs-1}.pt',\n",
    "                                  weights_only=True,\n",
    "                                  map_location=torch.device('cpu'))\n",
    "    # Load the trained model state\n",
    "    model.load_state_dict(final_checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    H_fdn_final[..., k] , _ = model.sub_fdn_output(z_values)\n",
    "\n",
    "    ### Filter the sub-FDN outputs with the pyfar filters, sum them and observe colouration\n",
    "    if trainer_config.subband_process_config.use_amp_preserving_filterbank:\n",
    "        print(\"I am here\")\n",
    "        if k == 0:\n",
    "            subband_filters, subband_freqs = pf.dsp.filter.reconstructing_fractional_octave_bands(\n",
    "                        None,\n",
    "                        num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                        frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "                        sampling_rate=config_dict.sample_rate,\n",
    "                    )\n",
    "            h_time_rev = get_time_reversed_fir_filterbank(subband_filters.coefficients, \n",
    "                                                      freq_bins_rad.detach().numpy(), \n",
    "                                                      trainer_config.num_freq_bins, \n",
    "                                                      plot=True, \n",
    "                                                      freq_labels=freqs)\n",
    "\n",
    "        subband_filter_idx = np.argmin(\n",
    "            np.abs(subband_freqs -\n",
    "                   trainer_config.subband_process_config.centre_frequency))\n",
    "        subband_filter = torch.tensor(\n",
    "            subband_filters.coefficients[subband_filter_idx])\n",
    "        subband_filter_freq_resp = torch.fft.rfft(\n",
    "            subband_filter, n=trainer_config.num_freq_bins)\n",
    "        subband_rev_filter_req_response = torch.tensor(h_time_rev[subband_filter_idx])\n",
    "\n",
    "        H_fdn_subband_init[..., k] = H_fdn_init[..., k] * subband_filter_freq_resp.unsqueeze(1)\n",
    "        H_fdn_subband_final[..., k] = H_fdn_final[..., k] * subband_filter_freq_resp.unsqueeze(1)\n",
    "\n",
    "        # get time reversed filtered output\n",
    "        H_fdn_subband_time_rev_init[..., k] = H_fdn_init[...,k] * subband_rev_filter_req_response.unsqueeze(1)\n",
    "        H_fdn_subband_time_rev_final[..., k] = H_fdn_final[...,k] * subband_rev_filter_req_response.unsqueeze(1)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        if k == 0:\n",
    "            subband_filters = pf.dsp.filter.fractional_octave_bands(\n",
    "                    None,\n",
    "                    num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                    frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "                    sampling_rate=config_dict.sample_rate,\n",
    "                )\n",
    "            subband_freqs, _ = pf.dsp.filter.fractional_octave_frequencies(\n",
    "                num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "            )\n",
    "\n",
    "        subband_filter_idx = np.argmin(\n",
    "            np.abs(subband_freqs -\n",
    "                   trainer_config.subband_process_config.centre_frequency))\n",
    "    \n",
    "        # safest to filter in time domain and then take transform\n",
    "        h_fdn_subband_init = sosfiltfilt(subband_filters.coefficients[subband_filter_idx, ...], \n",
    "                                         torch.fft.irfft(H_fdn_init[...,k], dim=0).detach().numpy(), \n",
    "                                         axis=0)\n",
    "        H_fdn_subband_init[...,k] = torch.fft.rfft(torch.from_numpy(h_fdn_subband_init.copy()), n=trainer_config.num_freq_bins, dim=0)\n",
    "        \n",
    "        h_fdn_subband_final = sosfiltfilt(subband_filters.coefficients[subband_filter_idx, ...], \n",
    "                                          torch.fft.irfft(H_fdn_final[...,k], dim=0).detach().numpy(), \n",
    "                                          axis=0)\n",
    "        H_fdn_subband_final[...,k] = torch.fft.rfft(torch.from_numpy(h_fdn_subband_final.copy()), n=trainer_config.num_freq_bins, dim=0) \n",
    "\n",
    "    \n",
    "    # plot colouration of individual FDNs\n",
    "    save_path = f'{fig_path}/{config_name}_mag_spectrum.png'\n",
    "    plot_magnitude_response(room_data, config_dict, model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Plot colouration of filtered and summed FDNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_response_plot(room_data:RoomDataset, H_sub_fdn_filtered: torch.tensor, freq_bins_hz:torch.tensor, freq_labels:List[int], \n",
    "                      title:Optional[str]=None, save_path:Optional[str] = None):\n",
    "    \"\"\"Plot magnitude response of filtered sub-FDN responses\n",
    "    Args:\n",
    "        H_sub_fdn_filtered is of shape num_bins x num_groups x num_freq_bands\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(room_data.num_rooms,\n",
    "                             1,\n",
    "                             figsize=(8, 10),\n",
    "                             sharex=True)\n",
    "\n",
    "    for i in range(room_data.num_rooms):\n",
    "       \n",
    "        axes[i].semilogx(\n",
    "            freq_bins_hz,\n",
    "            db(H_sub_fdn_filtered[:, i, :].detach().numpy()),\n",
    "            label=[f\"{freq_labels[k]} Hz\" for k in range(len(freq_labels))],\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        axes[i].semilogx(freq_bins_hz, db(torch.sum(H_sub_fdn_filtered[:,i,:], dim=-1).detach().numpy()), \n",
    "                         label='summed', linestyle='--')\n",
    "\n",
    "        axes[i].set_ylabel(\"Magnitude (dB)\")\n",
    "        axes[i].set_xlabel('Frequencies (Hz)')\n",
    "        axes[i].set_title(f\"FDN {i+1}\")\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_xlim([20, 16000])\n",
    "        axes[i].set_ylim([-60, 20])\n",
    "\n",
    "        logger.info(\n",
    "            f'FDN {i+1} spectral flatness is {spectral_flatness(db(torch.sum(H_sub_fdn_filtered[:, i, :], dim=-1).detach().numpy())):.3f}'\n",
    "        )\n",
    "    \n",
    "    axes[i].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "    if save_path is not None:\n",
    "        fig.savefig(save_path)\n",
    "\n",
    "mag_response_plot(room_data, H_fdn_subband_init, freq_bins_hz, freqs, title=\"Initialisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path = Path('figures/').resolve()\n",
    "save_path = f'{fig_path}/test_plots/{config_name}_opt_gfdn_summed_spectrum.png'\n",
    "mag_response_plot(room_data, H_fdn_final, freq_bins_hz, freqs, title=\"Post optimisation, no filtering\", save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'{fig_path}/test_plots/{config_name}_opt_gfdn_filtered_spectrum.png'\n",
    "mag_response_plot(room_data, H_fdn_subband_final, freq_bins_hz, freqs, title=\"Post optimisation with filtering\", save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trainer_config.subband_process_config.use_amp_preserving_filterbank:\n",
    "    save_path = f'{fig_path}/test_plots/{config_name}_opt_gfdn_time_reversed_filtered_spectrum.png'\n",
    "    mag_response_plot(room_data, H_fdn_subband_time_rev_final, freq_bins_hz, freqs, \n",
    "                      title=\"Post optimisation with time-reversed filtering\", save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Plot NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impulse response of each FDN\n",
    "h_init_fdn = torch.fft.irfft(torch.sum(H_fdn_subband_init, dim=-1), dim=0)\n",
    "h_final_fdn = torch.fft.irfft(torch.sum(H_fdn_subband_final, dim=-1), dim=0)\n",
    "\n",
    "# initial group delay because of FIR filtering with pyfar\n",
    "init_fir_delay = subband_filters.coefficients[0].shape[0] // 2\n",
    "\n",
    "# impulse response of the GFDN\n",
    "h_init = torch.sum(h_init_fdn, dim=-1)\n",
    "h_final = torch.sum(h_final_fdn, dim=-1)\n",
    "\n",
    "fs = room_data.sample_rate\n",
    "mixing_time_samp = ms_to_samps(0.0, fs)\n",
    "crop_end_samp = ms_to_samps(5.0, fs)\n",
    "h_init_trunc = h_init[mixing_time_samp:-crop_end_samp-init_fir_delay]\n",
    "h_final_trunc = h_final[init_fir_delay+mixing_time_samp:-crop_end_samp]\n",
    "len_ir = len(h_init_trunc)\n",
    "time = np.linspace(0, (len_ir-1)/ fs, len_ir-1)\n",
    "\n",
    "ned_init = normalised_echo_density(h_init_trunc, fs, window_length_ms=50)\n",
    "ned_final = normalised_echo_density(h_final_trunc, fs, window_length_ms=50)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 8))\n",
    "ax[0].plot(time, ned_init, label='Initial')\n",
    "ax[0].plot(time, ned_final, label='Post optimisation')\n",
    "for k in range(config_dict.num_groups):\n",
    "    ned_init_fdn = normalised_echo_density(h_init_fdn[mixing_time_samp:-crop_end_samp-init_fir_delay, k], fs, window_length_ms=50)\n",
    "    ned_final_fdn = normalised_echo_density(h_final_fdn[init_fir_delay + mixing_time_samp:-crop_end_samp, k], \n",
    "                                            fs, window_length_ms=50)\n",
    "    ax[1].plot(time, ned_init_fdn, label=f'Initial, group={k+1}')\n",
    "    ax[1].plot(time, ned_final_fdn, label=f'Final, group={k+1}')\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlabel('Time (s)')\n",
    "    ax[i].set_ylabel('NED')  \n",
    "    ax[i].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    ax[i].set_xlim([0.001, max(time)])\n",
    "plt.show()\n",
    "plt.savefig(f'{fig_path}/test_plots/{config_name}_ned.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
