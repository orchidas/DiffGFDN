{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### In this notebook, we want to investigate the colouration when we filter and sum multiple subband GFDNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import pyfar as pf\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from torch import nn\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from typing import Optional, List\n",
    "from IPython import display\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "from copy import deepcopy\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "\n",
    "from diff_gfdn.dataloader import load_dataset, RIRData, ThreeRoomDataset, RoomDataset\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType, SubbandProcessingConfig\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n",
    "from diff_gfdn.model import DiffGFDNVarReceiverPos\n",
    "from diff_gfdn.utils import is_unitary, db2lin, db, ms_to_samps, get_response, spectral_flatness\n",
    "from diff_gfdn.plot import plot_magnitude_response\n",
    "from diff_gfdn.colorless_fdn.utils import get_colorless_fdn_params\n",
    "from diff_gfdn.colorless_fdn.model import ColorlessFDN\n",
    "from slope2noise.utils import schroeder_backward_int\n",
    "from src.run_model import load_and_validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = [63, 125, 250, 500, 1000, 2000, 4000, 8000]\n",
    "\n",
    "for k in range(len(freqs)):\n",
    "    config_path = 'data/config/'\n",
    "    fig_path = 'figures/'\n",
    "    config_name = f'treble_data_grid_training_{freqs[k]}Hz_colorless_loss'\n",
    "    config_file = config_path + config_name\n",
    "    config_dict = load_and_validate_config(config_file + '.yml',\n",
    "                                           DiffGFDNConfig)\n",
    "    room_data = ThreeRoomDataset(Path(config_dict.room_dataset_path).resolve(), config_dict)\n",
    "    dataset_has_cs_params = True    \n",
    "    config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "    trainer_config = config_dict.trainer_config\n",
    "\n",
    "    ## initialise variables\n",
    "    if k == 0:\n",
    "        H_fdn_init = torch.zeros((trainer_config.num_freq_bins // 2 + 1, config_dict.num_groups, len(freqs)), \n",
    "                            dtype=torch.complex64, requires_grad=False)\n",
    "        H_fdn_subband_init = torch.zeros_like(H_fdn_init)\n",
    "        H_fdn_final = torch.zeros_like(H_fdn_init)\n",
    "        H_fdn_subband_final = torch.zeros_like(H_fdn_final)\n",
    "    \n",
    "    # force the trainer config device to be CPU\n",
    "    if trainer_config.device != 'cpu':\n",
    "        trainer_config = trainer_config.model_copy(update={\"device\": 'cpu'})\n",
    "    \n",
    "    # prepare the training and validation data for DiffGFDN\n",
    "    train_dataset, valid_dataset = load_dataset(\n",
    "        room_data, trainer_config.device, train_valid_split_ratio=1.0,\n",
    "        batch_size=trainer_config.batch_size, shuffle=False)\n",
    "    \n",
    "    # get the colorless FDN params\n",
    "    if config_dict.colorless_fdn_config.use_colorless_prototype:\n",
    "        colorless_fdn_params = get_colorless_fdn_params(config_dict)\n",
    "    else:\n",
    "        colorless_fdn_params = None\n",
    "    \n",
    "    # initialise the model\n",
    "    model = DiffGFDNVarReceiverPos(config_dict.sample_rate,\n",
    "                     config_dict.num_groups,\n",
    "                     config_dict.delay_length_samps,\n",
    "                     trainer_config.device,\n",
    "                     config_dict.feedback_loop_config,\n",
    "                     config_dict.output_filter_config,\n",
    "                     config_dict.decay_filter_config.use_absorption_filters,\n",
    "                     common_decay_times=room_data.common_decay_times if config_dict.decay_filter_config.initialise_with_opt_values else None,\n",
    "                     learn_common_decay_times=config_dict.decay_filter_config.learn_common_decay_times,\n",
    "                     colorless_fdn_params=colorless_fdn_params,\n",
    "                     use_colorless_loss=trainer_config.use_colorless_loss\n",
    "                     )\n",
    "\n",
    "    ### Get each FDN's magnitude response\n",
    "    freq_bins_rad = torch.tensor(room_data.freq_bins_rad)\n",
    "    freq_bins_hz = room_data.freq_bins_hz\n",
    "    z_values = torch.polar(torch.ones_like(freq_bins_rad),\n",
    "                           freq_bins_rad * 2 * np.pi)\n",
    "    \n",
    "    # load the trained weights for the particular epoch\n",
    "    max_epochs = trainer_config.max_epochs\n",
    "    checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "\n",
    "    init_checkpoint = torch.load(f'{checkpoint_dir}/model_e-1.pt',\n",
    "                                 weights_only=True,\n",
    "                                 map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(init_checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    H_fdn_init[...,k], _ = model.sub_fdn_output(z_values)\n",
    "\n",
    "    final_checkpoint = torch.load(f'{checkpoint_dir}/model_e{max_epochs-1}.pt',\n",
    "                                  weights_only=True,\n",
    "                                  map_location=torch.device('cpu'))\n",
    "    # Load the trained model state\n",
    "    model.load_state_dict(final_checkpoint, strict=False)\n",
    "    model.eval()\n",
    "    H_fdn_final[..., k] , _ = model.sub_fdn_output(z_values)\n",
    "\n",
    "    ### Filter the sub-FDN outputs with the pyfar filters, sum them and observe colouration\n",
    "    subband_filters, subband_freqs = pf.dsp.filter.reconstructing_fractional_octave_bands(\n",
    "                None,\n",
    "                num_fractions=trainer_config.subband_process_config.num_fraction_octaves,\n",
    "                frequency_range=trainer_config.subband_process_config.frequency_range,\n",
    "                sampling_rate=config_dict.sample_rate,\n",
    "            )\n",
    "    subband_filter_idx = np.argmin(\n",
    "        np.abs(subband_freqs -\n",
    "               trainer_config.subband_process_config.centre_frequency))\n",
    "    subband_filter = torch.tensor(\n",
    "        subband_filters.coefficients[subband_filter_idx])\n",
    "    subband_filter_freq_resp = torch.fft.rfft(\n",
    "        subband_filter, n=trainer_config.num_freq_bins)\n",
    "    H_fdn_subband_init[..., k] = H_fdn_init[..., k] * subband_filter_freq_resp.unsqueeze(1)\n",
    "    H_fdn_subband_final[..., k] = H_fdn_final[..., k] * subband_filter_freq_resp.unsqueeze(1)\n",
    "\n",
    "    \n",
    "    # plot colouration of individual FDNs\n",
    "    save_path = f'{fig_path}/{config_name}_mag_spectrum.png'\n",
    "    plot_magnitude_response(room_data, config_dict, model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "#### Plot colouration of filtered and summed FDNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_response_plot(room_data:RoomDataset, H_sub_fdn_filtered: torch.tensor, freq_bins_hz:torch.tensor, freq_labels:List[int], \n",
    "                      title:Optional[str]=None):\n",
    "    \"\"\"Plot magnitude response of filtered sub-FDN responses\n",
    "    Args:\n",
    "        H_sub_fdn_filtered is of shape num_bins x num_groups x num_freq_bands\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(room_data.num_rooms,\n",
    "                             1,\n",
    "                             figsize=(8, 10),\n",
    "                             sharex=True)\n",
    "\n",
    "    for i in range(room_data.num_rooms):\n",
    "       \n",
    "        axes[i].semilogx(\n",
    "            freq_bins_hz,\n",
    "            db(H_sub_fdn_filtered[:, i, :].detach().numpy()),\n",
    "            label=[f\"{freq_labels[k]} Hz\" for k in range(len(freq_labels))],\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.8,\n",
    "        )\n",
    "\n",
    "        axes[i].semilogx(freq_bins_hz, db(torch.sum(H_sub_fdn_filtered[:,i,:], dim=-1).detach().numpy()), \n",
    "                         label='summed', linestyle='--')\n",
    "\n",
    "        axes[i].set_ylabel(\"Magnitude (dB)\")\n",
    "        axes[i].set_xlabel('Frequencies (Hz)')\n",
    "        axes[i].set_title(f\"FDN {i+1}\")\n",
    "        axes[i].grid(True)\n",
    "        axes[i].set_xlim([20, 16000])\n",
    "\n",
    "        logger.info(\n",
    "            f'FDN {i+1} spectral flatness is {spectral_flatness(db(torch.sum(H_sub_fdn_filtered[:, i, :], dim=-1).detach().numpy())):.3f}'\n",
    "        )\n",
    "    \n",
    "    axes[i].legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title)\n",
    "\n",
    "mag_response_plot(room_data, H_fdn_subband_init, freq_bins_hz, freqs, title=\"Initialisation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_response_plot(room_data, H_fdn_subband_final, freq_bins_hz, freqs, title=\"Post optimisation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
