{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from torch import nn\n",
    "from numpy.typing import ArrayLike\n",
    "from typing import Optional, List\n",
    "from IPython import display\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "from copy import deepcopy\n",
    "\n",
    "from diff_gfdn.dataloader import load_dataset, RIRData\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n",
    "from diff_gfdn.model import DiffGFDNVarReceiverPos\n",
    "from diff_gfdn.utils import is_unitary, db2lin, db, ms_to_samps, get_response\n",
    "from diff_gfdn.plot import plot_edr, animate_coupled_feedback_matrix\n",
    "from diff_gfdn.analysis import get_decay_fit_net_params\n",
    "from run_model import load_and_validate_config\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'data/config/'\n",
    "fig_path = 'figures/'\n",
    "config_name = 'synth_data_two_coupled_rooms_grid_training.yml'\n",
    "config_file = config_path + config_name\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       DiffGFDNConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_data = convert_common_slopes_rir_to_room_dataset(config_dict.room_dataset_path, \n",
    "                                                      num_freq_bins=config_dict.trainer_config.num_freq_bins,\n",
    "                                                      )\n",
    "\n",
    "config_dict = config_dict.copy(update={\"num_groups\": room_data.num_rooms})\n",
    "\n",
    "trainer_config = config_dict.trainer_config\n",
    "\n",
    "# force the trainer config device to be CPU\n",
    "if trainer_config.device != 'cpu':\n",
    "    trainer_config = trainer_config.copy(update={\"device\": 'cpu'})\n",
    "\n",
    "# prepare the training and validation data for DiffGFDN\n",
    "train_dataset, valid_dataset = load_dataset(\n",
    "    room_data, trainer_config.device, train_valid_split_ratio=1.0,\n",
    "    batch_size=trainer_config.batch_size, shuffle=False)\n",
    "\n",
    "# initialise the model\n",
    "model = DiffGFDNVarReceiverPos(config_dict.sample_rate,\n",
    "                 config_dict.num_groups,\n",
    "                 config_dict.delay_length_samps,\n",
    "                 trainer_config.device,\n",
    "                 config_dict.feedback_loop_config,\n",
    "                 config_dict.output_filter_config,\n",
    "                 use_absorption_filters=False,\n",
    "                 common_decay_times=room_data.common_decay_times,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory  = Path(\"audio/\")\n",
    "fig_path = Path(\"figures\").resolve()\n",
    "checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "max_epochs = trainer_config.max_epochs\n",
    "plot_ir = True \n",
    "pos_to_investigate = [0.7, 1.59, 1.72] # [2.29, 5.47, 0.98] \n",
    "desired_filename = f'ir_({pos_to_investigate[0]:.2f}, {pos_to_investigate[1]:.2f}, {pos_to_investigate[2]:.2f}).wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Iterate through epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_approx_list = []\n",
    "output_gains = []\n",
    "input_gains = []\n",
    "coupled_feedback_matrix = []\n",
    "coupling_matrix = []\n",
    "# find the true IR corresponding to this position\n",
    "filepath_true = os.path.join(Path(audio_directory/'synthetic_true/two_coupled_rooms/').resolve(), desired_filename)\n",
    "h_true = torch.from_numpy(sf.read(filepath_true)[0])\n",
    "all_pos = []\n",
    "all_rirs = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # load the trained weights for the particular epoch\n",
    "    checkpoint = torch.load(f'{checkpoint_dir}/model_e{epoch}.pt', weights_only=True, map_location=torch.device('cpu'))\n",
    "    # Load the trained model state\n",
    "    model.load_state_dict(checkpoint)\n",
    "    # in eval mode, no gradients are calculated\n",
    "    model.eval()\n",
    "    break_outer_loop = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        param_dict = model.get_param_dict()\n",
    "        input_gains.append(deepcopy(param_dict['input_gains']))\n",
    "        coupled_feedback_matrix.append(deepcopy(param_dict['coupled_feedback_matrix']))\n",
    "        coupling_matrix.append(deepcopy(param_dict['coupling_matrix']))\n",
    "    \n",
    "        for data in train_dataset:\n",
    "            position = data['listener_position']\n",
    "            H, h = get_response(data, model)\n",
    "            \n",
    "            for num_pos in range(position.shape[0]):\n",
    "                if epoch == max_epochs - 1:\n",
    "                    all_pos.append(position[num_pos])\n",
    "                    all_rirs.append(h[num_pos, :])\n",
    "                filename = f'ir_({position[num_pos,0]:.2f}, {position[num_pos, 1]:.2f}, {position[num_pos, 2]:.2f}).wav'\n",
    "                \n",
    "                if filename == desired_filename:\n",
    "                    # get the ir at this position\n",
    "                    h_approx_list.append(h[num_pos, :])\n",
    "    \n",
    "                    # get the gains for this position\n",
    "                    output_gains.append(deepcopy(param_dict['output_gains'][num_pos]))\n",
    "    \n",
    "                    # not breaking the loop to collect all the RIRs\n",
    "                    # break_outer_loop = True\n",
    "                    # break\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### Plot the EDCs as a function of epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_edc(h_true: ArrayLike, h_approx: List[ArrayLike], fs: float, pos_to_investigate: List, mixing_time_ms:float=20.0):\n",
    "    \"\"\"Plot true and synthesised EDC curves\"\"\"\n",
    "    \n",
    "    mixing_time_samp = ms_to_samps(mixing_time_ms, fs)\n",
    "    crop_end_samp = ms_to_samps(5.0, fs)\n",
    "    \n",
    "    trunc_true_ir = h_true[mixing_time_samp:-crop_end_samp]\n",
    "    true_edf = np.flipud(np.cumsum(np.flipud(trunc_true_ir**2), axis=-1))\n",
    "    time = np.linspace(0, (len(trunc_true_ir) - 1) / fs,\n",
    "                       len(trunc_true_ir))\n",
    "  \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.plot(time, db(true_edf, is_squared=True), label='True EDF')\n",
    "\n",
    "    num_epochs = len(h_approx)\n",
    "    for epoch in range(num_epochs):\n",
    "        approx_ir = h_approx[epoch]\n",
    "        trunc_approx_ir = approx_ir[mixing_time_samp: mixing_time_samp + len(trunc_true_ir)]\n",
    "        synth_edf = np.flipud(np.cumsum(np.flipud(trunc_approx_ir**2), axis=-1))\n",
    "        ax.plot(time, db(synth_edf, is_squared=True), label=f'Epoch={epoch}')\n",
    "        ax.legend()\n",
    "        ax.set_ylim([-60,0])\n",
    "        \n",
    "        display.display(fig)  # Display the updated figure\n",
    "        display.clear_output(wait=True)  # Clear the previous output to keep updates in place\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "    ax.set_title(\n",
    "        f'Truncated EDF at position {pos_to_investigate[0]:.2f}, {pos_to_investigate[1]:.2f}, {pos_to_investigate[2]:.2f} m'\n",
    "    )\n",
    "    fig.savefig(Path(f'{fig_path}/compare_synth_edf_{pos_to_investigate}_{config_name}.png').resolve())\n",
    "    plt.show()\n",
    "\n",
    "plot_edc(h_true, h_approx_list, config_dict.sample_rate, pos_to_investigate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Plot the learnt feedback matrix and input gains for the grid, plot the output gains for a single position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_gfdn.plot import animate_coupled_feedback_matrix\n",
    "\n",
    "if config_dict.feedback_loop_config.coupling_matrix_type == CouplingMatrixType.SCALAR:\n",
    "    animate_coupled_feedback_matrix(np.abs(coupled_feedback_matrix), np.abs(coupling_matrix), \n",
    "                                    save_path=Path(f'{fig_path}/animation/{config_name}_{pos_to_investigate}_scalar_coupling_matrix.gif').resolve())\n",
    "else:\n",
    "    animate_coupled_feedback_matrix(np.abs(coupled_feedback_matrix), \n",
    "                                    save_path=Path(f'{fig_path}/animation/{config_name}_{pos_to_investigate}_random_coupling_matrix.gif').resolve())\n",
    "\n",
    "# also save the final optimised matrix\n",
    "if config_dict.feedback_loop_config.coupling_matrix_type == CouplingMatrixType.SCALAR:\n",
    "    assert is_unitary(torch.from_numpy(coupled_feedback_matrix[-1]))[0]    \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(4, 6))\n",
    "\n",
    "    # Coupling matrix subplot\n",
    "    cax1 = ax1.matshow(np.abs(coupling_matrix[-1]))\n",
    "    fig.colorbar(cax1, ax=ax1)\n",
    "    ax1.set_title('Coupling matrix')\n",
    "    \n",
    "    # Coupled feedback matrix subplot\n",
    "    cax2 = ax2.matshow(np.abs(coupled_feedback_matrix[-1]))\n",
    "    fig.colorbar(cax2, ax=ax2)\n",
    "    ax2.set_title('Coupled feedback matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/{config_name}_scalar_coupling_matrix.png', bbox_inches='tight')\n",
    "else:\n",
    "    unit_flag, max_val = is_unitary(torch.tensor(coupled_feedback_matrix[-1]), max_tol=1e-4)\n",
    "    assert unit_flag\n",
    "    plt.figure()\n",
    "    plt.matshow(np.abs(coupled_feedback_matrix[-1]))\n",
    "    plt.title('Optimised feedback matrix')\n",
    "    plt.savefig(f'{fig_path}/{config_name}_random_coupling_matrix.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of vectors to a 2D numpy array (N x M matrix)\n",
    "input_gain_matrix = np.stack([vec for vec in input_gains]).T\n",
    "output_gain_matrix = np.stack([vec for vec in output_gains]).T\n",
    "\n",
    "# Plot the matrix\n",
    "fig, ax = plt.subplots(2, figsize=(6,6))\n",
    "in_plot = ax[0].matshow(np.abs(input_gain_matrix), aspect='auto', cmap='viridis')\n",
    "fig.colorbar(in_plot, label=\"dB\", ax=ax[0])\n",
    "ax[0].set_ylabel(\"Delay line number\")\n",
    "ax[0].set_xlabel(\"Epoch number\")\n",
    "ax[0].set_title(\"Input gains vs epoch\")\n",
    "\n",
    "out_plot = ax[1].matshow(np.abs(output_gain_matrix), aspect='auto', cmap='viridis')\n",
    "fig.colorbar(out_plot, label=\"dB\", ax=ax[1])\n",
    "ax[1].set_ylabel(\"Delay line number\")\n",
    "ax[1].set_xlabel(\"Epoch number\")\n",
    "ax[1].set_title(\"Output gains vs epoch\")\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "plt.show()\n",
    "fig.savefig(Path(f'{fig_path}/{config_name}_{pos_to_investigate}_io_gains.png').resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Plot the amplitude distribution for each RIR as a position of space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Read the data and config file from slope2noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slope2noise.slope2noise.rooms import RoomGeometry\n",
    "from slope2noise.config.config import Config\n",
    "from slope2noise.slope2noise.utils import calculate_amplitudes_least_squares\n",
    "import yaml\n",
    "\n",
    "data_config_path = 'submodules/slope2noise/config/'\n",
    "data_config_name = 'rir_synthesis_coupled_room_single_batch.yml'\n",
    "data_config_path = Path(data_config_path + data_config_name).resolve()\n",
    "                                \n",
    "with open(data_config_path, 'r') as file:\n",
    "    config_data = yaml.safe_load(file)\n",
    "\n",
    "data_config_dict = Config(**config_data)\n",
    "num_rooms = data_config_dict.room_geom_config.num_rooms\n",
    "room_dims = data_config_dict.room_geom_config.room_dims\n",
    "start_coordinates = data_config_dict.room_geom_config.start_coordinates\n",
    "aperture_coordinates = data_config_dict.room_geom_config.aperture_coords\n",
    "t_vals = np.asarray(data_config_dict.t_vals)\n",
    "\n",
    "room = RoomGeometry(data_config_dict.fs, num_rooms, np.array(room_dims),\n",
    "                    np.array(start_coordinates), aperture_coordinates)\n",
    "exp_amps = room_data.amplitudes\n",
    "rec_points = room_data.receiver_position\n",
    "src_pos = room_data.source_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Estimate and plot all the amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rirs = np.asarray(all_rirs)\n",
    "est_rec_pos = np.asarray(all_pos)\n",
    "num_rirs = est_rirs.shape[0]\n",
    "t_vals_expanded = np.tile(t_vals.T, (num_rirs,1))\n",
    "est_amps = calculate_amplitudes_least_squares(t_vals_expanded[..., np.newaxis], \n",
    "                                              data_config_dict.fs, \n",
    "                                              est_rirs[:, :len(h_true), np.newaxis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "room.plot_amps_at_receiver_points(room_data.receiver_position, room_data.source_position, room_data.amplitudes.T, \n",
    "                                 scatter_plot=True, \n",
    "                                save_path=Path(f'{fig_path}/{config_name}_actual_amplitudes_in_space.png').resolve())\n",
    "\n",
    "\n",
    "room.plot_amps_at_receiver_points(est_rec_pos, room_data.source_position, np.squeeze(est_amps).T, \n",
    "                                 scatter_plot=True,\n",
    "                                 save_path=Path(f'{fig_path}/{config_name}_learnt_amplitudes_in_space.png').resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
