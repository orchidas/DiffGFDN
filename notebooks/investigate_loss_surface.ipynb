{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "For a GFDN with a single group, investigate the loss surfaces as a function of $g_{in}$ and $g_{out}$. This will be a 3D plot and give us more intuition about the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import soundfile as sf\n",
    "import pickle\n",
    "from torch import nn\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from numpy.typing import ArrayLike\n",
    "from typing import Optional, List, Dict\n",
    "from copy import deepcopy\n",
    "from IPython import display\n",
    "from loguru import logger\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "\n",
    "from diff_gfdn.dataloader import load_dataset, RIRData\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType\n",
    "from diff_gfdn.solver import convert_common_slopes_rir_to_room_dataset\n",
    "from diff_gfdn.model import DiffGFDN, DiffGFDNSinglePos\n",
    "from diff_gfdn.utils import is_unitary, db2lin, db, ms_to_samps, get_response, to_complex\n",
    "from diff_gfdn.plot import plot_edr, animate_coupled_feedback_matrix\n",
    "from diff_gfdn.analysis import get_decay_fit_net_params\n",
    "from diff_gfdn.colorless_fdn.utils import get_colorless_fdn_params\n",
    "from diff_gfdn.colorless_fdn.losses import amse_loss, sparsity_loss\n",
    "from diff_gfdn.losses import edc_loss, edr_loss\n",
    "from src.run_model import load_and_validate_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'data/config/'\n",
    "fig_path = 'figures/'\n",
    "config_name = 'single_rir_fit_broadband_two_stage_decay_colorless_prototype_pos2.yml'\n",
    "config_file = config_path + config_name\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       DiffGFDNConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_data = convert_common_slopes_rir_to_room_dataset(config_dict.room_dataset_path, \n",
    "                                                      num_freq_bins=config_dict.trainer_config.num_freq_bins,\n",
    "                                                      )\n",
    "\n",
    "config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "\n",
    "trainer_config = config_dict.trainer_config\n",
    "# prepare the training and validation data for DiffGFDN\n",
    "if trainer_config.batch_size != room_data.num_freq_bins:\n",
    "    trainer_config = trainer_config.model_copy(\n",
    "        update={\"batch_size\": room_data.num_freq_bins})\n",
    "\n",
    "# get the colorless FDN params\n",
    "if config_dict.colorless_fdn_config.use_colorless_prototype:\n",
    "    colorless_fdn_params = get_colorless_fdn_params(config_dict)\n",
    "else:\n",
    "    colorless_fdn_params = None\n",
    "\n",
    "# initialise the model\n",
    "model = DiffGFDNSinglePos(config_dict.sample_rate,\n",
    "                 config_dict.num_groups,\n",
    "                 config_dict.delay_length_samps,\n",
    "                 trainer_config.device,\n",
    "                 config_dict.feedback_loop_config,\n",
    "                 config_dict.output_filter_config,\n",
    "                 use_absorption_filters=False,\n",
    "                 common_decay_times=room_data.common_decay_times,\n",
    "                 colorless_fdn_params=colorless_fdn_params,\n",
    "                 use_colorless_loss=trainer_config.use_colorless_loss\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Find the desired RIR params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r'ir_\\([^)]+\\)', config_dict.ir_path)\n",
    "dir_name = Path(trainer_config.ir_dir).parts[-1]\n",
    "ir_name = match.group()\n",
    "approx_ir_path = f'{trainer_config.ir_dir}/approx_{ir_name}.wav'\n",
    "final_approx_ir, fs = sf.read(Path(approx_ir_path).resolve())\n",
    "\n",
    "# find receiver position from string\n",
    "match = re.search(r'ir_\\(([^,]+), ([^,]+), ([^,]+)\\)', ir_name)\n",
    "# Convert the extracted values to floats\n",
    "x, y, z = map(float, match.groups())\n",
    "rec_pos = np.array([x, y, z])\n",
    "\n",
    "# find amplitudes corresponding to the receiver position\n",
    "rec_pos_idx = np.argwhere(\n",
    "    np.all(np.round(room_data.receiver_position,2) == rec_pos, axis=1))[0]\n",
    "amplitudes = np.squeeze(room_data.amplitudes[rec_pos_idx, :])\n",
    "true_ir = np.squeeze(room_data.rirs[rec_pos_idx, :])\n",
    "\n",
    "# plot time domain RIRs\n",
    "if len(true_ir) > len(final_approx_ir):\n",
    "    plt.plot(np.stack((true_ir[:len(final_approx_ir)], final_approx_ir[:, 0]), axis=-1))\n",
    "    end_samp = len(final_approx_ir)\n",
    "else:\n",
    "    plt.plot(np.stack((true_ir, final_approx_ir[:len(true_ir), 0]), axis=-1))\n",
    "    end_samp = len(true_ir)\n",
    "\n",
    "plt.xlim([0, int(1.5 * config_dict.sample_rate)])\n",
    "plt.savefig(f'{fig_path}/compare_{dir_name}_{ir_name}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edc_params(rir: ArrayLike, n_slopes: int, fs:float):\n",
    "    est_params_decay_net, norm_vals, fitted_edc_subband = get_decay_fit_net_params(rir, None, n_slopes, fs)\n",
    "    est_t60 = np.mean(est_params_decay_net[0], axis=0)\n",
    "    est_amp = np.mean(est_params_decay_net[1], axis=0)\n",
    "    est_noise = np.mean(est_params_decay_net[2], axis=0)\n",
    "    fitted_edc = torch.squeeze(torch.mean(fitted_edc_subband, dim=0))\n",
    "    return est_t60, est_amp, est_noise, fitted_edc\n",
    "\n",
    "def plot_final_decay_fit_net_edc(num_groups:int, og_amps: List, est_amps: List, og_edc: ArrayLike, synth_edc:ArrayLike):\n",
    "    \n",
    "    time = np.linspace(0, (len(og_edc) - 1) / fs, len(og_edc))\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    ax.plot(time, db(og_edc, is_squared=True), linestyle='-', label=f'Original estimated EDC (norm)')\n",
    "    ax.plot(time[:len(synth_edc)], db(synth_edc, is_squared=True), linestyle='--', label=f'Final estimated EDC (norm)')\n",
    "    ax.plot(np.zeros(num_groups), db(og_amps, is_squared=True), 'kx', label='Original amps')\n",
    "    ax.plot(np.zeros(num_groups), db(est_amps, is_squared=True), 'gd', label='Synth amps')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    fig.savefig(Path(f'{fig_path}/final_synth_edf_{rec_pos}_{config_dict.feedback_loop_config.coupling_matrix_type.value}_random_init_lr={trainer_config.io_lr}.png').resolve())\n",
    "\n",
    "og_est_t60, og_est_amp, og_noise_floor, og_fitted_edc = get_edc_params(true_ir[:end_samp], config_dict.num_groups, config_dict.sample_rate)\n",
    "est_t60, est_amp, _, fitted_edc = get_edc_params(final_approx_ir[:end_samp,0], config_dict.num_groups, config_dict.sample_rate)\n",
    "plot_final_decay_fit_net_edc(config_dict.num_groups, og_est_amp, est_amp, og_fitted_edc, fitted_edc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RIRDataset\n",
    "rir_data = RIRData(rir=true_ir,\n",
    "                   sample_rate=config_dict.sample_rate,\n",
    "                   common_decay_times=room_data.common_decay_times,\n",
    "                   band_centre_hz=room_data.band_centre_hz,\n",
    "                   amplitudes=amplitudes,\n",
    "                   nfft=config_dict.trainer_config.num_freq_bins,\n",
    "                   )\n",
    "\n",
    "# prepare the training and validation data for DiffGFDN\n",
    "train_dataset = load_dataset(\n",
    "    rir_data, trainer_config.device, train_valid_split_ratio=1.0,\n",
    "    batch_size=trainer_config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Find each loss for a grid of source-receiver gain values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_multi_gain_transfer_function(model: DiffGFDN, b: torch.tensor, c: torch.tensor, data: Dict,  \n",
    "                                      input_scalars: torch.tensor, output_scalars:torch.tensor, num_inp_points: int, num_out_points: int):\n",
    "    \"\"\"\n",
    "    Calculate the Diff GFDN's transfer function for a grid of source-receiver gains specified by \n",
    "    input_scalars, output_scalars each containing num_point elements\n",
    "    Args:\n",
    "        input_scalars (Tensor): g_in of size num_points x num_groups x 1\n",
    "        output_scalars (Tensor): g_out of size num_points x num_groups x 1\n",
    "    Returns:\n",
    "        Tensor: magnitude response of size num_points x num_points x num_freq_bins\n",
    "    \"\"\"\n",
    "    z = data['z_values']\n",
    "    num_freq_pts = len(z)\n",
    "    c = c.unsqueeze(0).unsqueeze(-1)\n",
    "    b = b.unsqueeze(0).unsqueeze(-1)\n",
    "    output_scalars = output_scalars.view(*output_scalars.shape, 1)\n",
    "    input_scalars = input_scalars.view(*input_scalars.shape, 1)\n",
    "    \n",
    "    C_init = to_complex(\n",
    "        c.expand(num_out_points, model.num_delay_lines, num_freq_pts))\n",
    "    B_init = to_complex(\n",
    "        b.expand(num_inp_points, model.num_delay_lines, num_freq_pts))\n",
    "    \n",
    "    output_scalars_expanded = output_scalars.expand(\n",
    "                num_out_points, model.num_groups, num_freq_pts)\n",
    "    output_scalars_expanded = output_scalars_expanded.repeat_interleave(\n",
    "            model.num_delay_lines_per_group, dim=1)\n",
    "    # size num_out_points x num_del_lines x num_freq_bins\n",
    "    C = to_complex(output_scalars_expanded)\n",
    "\n",
    "    input_scalars_expanded = input_scalars.expand(\n",
    "                num_inp_points, model.num_groups, num_freq_pts)\n",
    "    input_scalars_expanded = input_scalars_expanded.repeat_interleave(\n",
    "            model.num_delay_lines_per_group, dim=1)\n",
    "    # size num_inp_points x num_del_lines x num_freq_bins\n",
    "    B = to_complex(input_scalars_expanded)\n",
    "\n",
    "    # of size num_points x Ndel x num_freq_points\n",
    "    C *= C_init\n",
    "    B *= B_init\n",
    "\n",
    "    # get the output of the feedback loop, this is of size num_freq_points x Ndel x Ndel\n",
    "    P = model.feedback_loop(z)\n",
    "    # this is of size num_freq_points x num_del_lines x num_out_points\n",
    "    Htemp = torch.einsum('kmb, kmn -> knb', C.permute(-1,1,0), P)\n",
    "    # Htemp = torch.einsum('knm, bmk -> bkn', P, C)\n",
    "    # this is of size num_inp_points x num_out_points x num_freq_points\n",
    "    H = torch.einsum('knb, knc -> kbc', Htemp, B.permute(-1,1,0)).permute(-1,1,0)\n",
    "    # H = torch.einsum('bnk, ckn -> bck', B, Htemp)\n",
    "    direct_filter = data['target_early_response']\n",
    "    direct_filter = direct_filter.view(1, 1, *direct_filter.shape).expand(num_inp_points, num_out_points, num_freq_pts)\n",
    "    H += direct_filter\n",
    "\n",
    "    if model.use_colorless_loss:\n",
    "        H_sub_fdn = model.sub_fdn_output(z)\n",
    "        return H, H_sub_fdn\n",
    "    else:\n",
    "        return H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the model parameters per epoch\n",
    "checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "max_epochs = trainer_config.max_epochs\n",
    "num_points = 100\n",
    "input_scalars = torch.linspace(-2.0, 2.0, num_points)\n",
    "output_scalars = torch.linspace(-2.0, 2.0, num_points)\n",
    "input_scalar_grid, output_scalar_grid = torch.meshgrid(input_scalars, output_scalars)\n",
    "\n",
    "\n",
    "edr_loss_val = torch.zeros((num_points, num_points))\n",
    "edc_loss_val = torch.zeros_like(edr_loss_val)\n",
    "criterion = [edr_loss(model.sample_rate, use_erb_grouping=trainer_config.use_erb_edr_loss, \n",
    "                      use_weight_fn=trainer_config.use_frequency_weighting),\n",
    "            edc_loss(model.common_decay_times.max() * 1e3,\n",
    "                     model.sample_rate)]\n",
    "\n",
    "if trainer_config.use_colorless_loss:\n",
    "    spectral_loss_val = torch.zeros_like(edr_loss_val)\n",
    "    sparsity_loss_val = torch.zeros_like(edr_loss_val)\n",
    "    colorless_criterion = [amse_loss(), sparsity_loss()]\n",
    "\n",
    "# load the trained weights for the particular epoch\n",
    "found_exception = True\n",
    "while found_exception:\n",
    "    try:\n",
    "        checkpoint = torch.load(f'{checkpoint_dir}/model_e{max_epochs-1}.pt', weights_only=True, map_location=torch.device('cpu'))\n",
    "        found_exception = False\n",
    "    except Exception as e:\n",
    "        max_epochs -= 1\n",
    "        found_exception = True\n",
    "    \n",
    "    \n",
    "# Load the trained model state\n",
    "model.load_state_dict(checkpoint)\n",
    "# in eval mode, no gradients are calculated\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    param_dict = model.get_param_dict()\n",
    "    input_gains = deepcopy(param_dict['input_gains'])\n",
    "    output_gains = deepcopy(param_dict['output_gains'])\n",
    "    opt_input_scalars = deepcopy(param_dict['input_scalars'])\n",
    "    opt_output_scalars = deepcopy(param_dict['output_scalars'])\n",
    "    logger.info(f'Opt source gain {np.round(opt_input_scalars, 3)}')\n",
    "    logger.info(f'Opt receiver gain {np.round(opt_output_scalars, 3)}')\n",
    "\n",
    "    if model.num_groups == 1:\n",
    "        input_scalars = input_scalars.unsqueeze(-1)\n",
    "        output_scalars = output_scalars.unsqueeze(-1)\n",
    "    else:\n",
    "        # because the input and output scalars are the same, we can only vary\n",
    "        # the input scalars and keep the output scalars static\n",
    "        input_scalars = torch.stack((opt_input_scalars[0] * torch.ones(num_points), input_scalars), dim=-1)\n",
    "        output_scalars = torch.stack((output_scalars, opt_output_scalars[1] * torch.ones(num_points)), dim=-1)\n",
    "        \n",
    "\n",
    "    for data in train_dataset:\n",
    "        # get the optimum losses while training\n",
    "        if trainer_config.use_colorless_loss:\n",
    "            Hopt, H_sub_fdn, approx_ir = get_response(data, model)\n",
    "        else:\n",
    "            Hopt, approx_ir = get_response(data, model)\n",
    "        \n",
    "        opt_edr_loss = criterion[0](data['target_rir_response'], Hopt)\n",
    "        opt_edc_loss = criterion[1](data['target_rir_response'], Hopt)\n",
    "        logger.info(f'Opt EDR loss {opt_edr_loss:.3f}')\n",
    "        logger.info(f'Opt EDC loss {opt_edc_loss:.3f}')\n",
    "        \n",
    "        if trainer_config.use_colorless_loss:\n",
    "            opt_spectral_loss = 0.0\n",
    "            opt_sparsity_loss = 0.0\n",
    "            for k in range(model.num_groups):\n",
    "                group_idx = torch.arange(\n",
    "                    k * model.num_delay_lines_per_group,\n",
    "                    (k + 1) * model.num_delay_lines_per_group,\n",
    "                    dtype=torch.int32)\n",
    "                opt_spectral_loss += colorless_criterion[0](H_sub_fdn[0][..., k], \n",
    "                                                            torch.ones_like(H_sub_fdn[0][..., k])) + + colorless_criterion[0](\n",
    "                                H_sub_fdn[1][group_idx, :,  k], \n",
    "                                torch.ones_like(H_sub_fdn[1][group_idx, :, k]))\n",
    "                opt_sparsity_loss += colorless_criterion[1](model.feedback_loop.ortho_param(model.feedback_loop.M[k]))\n",
    "        \n",
    "        # get the losses for a grid of source-receiver gains\n",
    "        if trainer_config.use_colorless_loss:\n",
    "            H, H_sub_fdn = find_multi_gain_transfer_function(model, torch.tensor(input_gains), torch.tensor(output_gains), data, \n",
    "                                             input_scalars, output_scalars, num_points, num_points)\n",
    "        else:\n",
    "            H = find_multi_gain_transfer_function(model, torch.tensor(input_gains), torch.tensor(output_gains), data, \n",
    "                                             input_scalars, output_scalars, num_points, num_points)\n",
    "\n",
    "        for i in tqdm(range(num_points)):        \n",
    "            for j in range(num_points):\n",
    "                    edr_loss_val[i,j] = criterion[0](data['target_rir_response'], H[i, j, :])\n",
    "                    edc_loss_val[i,j] = criterion[1](data['target_rir_response'], H[i, j, :])\n",
    "                    if trainer_config.use_colorless_loss:\n",
    "                        for k in range(model.num_groups):\n",
    "                            group_idx = torch.arange(k * model.num_delay_lines_per_group, (k + 1) * model.num_delay_lines_per_group, dtype=torch.int32)\n",
    "                            spectral_loss_val[i,j] += colorless_criterion[0](H_sub_fdn[0][..., k], \n",
    "                                                                             torch.ones_like(H_sub_fdn[0][..., k])) + colorless_criterion[0](\n",
    "                                H_sub_fdn[1][group_idx, :,  k], \n",
    "                                torch.ones_like(H_sub_fdn[1][group_idx, :, k]))\n",
    "                            sparsity_loss_val[i,j] += colorless_criterion[1](model.feedback_loop.ortho_param(model.feedback_loop.M[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Plot each loss surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Plot the 3D surface\n",
    "num_losses = 4 if trainer_config.use_colorless_loss else 2\n",
    "opt_losses = [opt_edr_loss, opt_edc_loss]\n",
    "loss_names = ['EDR','EDC','Spectral','Sparsity']\n",
    "\n",
    "if trainer_config.use_colorless_loss:\n",
    "    losses = torch.stack((edr_loss_val, edc_loss_val, spectral_loss_val, sparsity_loss_val), dim=-1)\n",
    "    opt_losses.extend([opt_spectral_loss, opt_sparsity_loss])\n",
    "else:\n",
    "    losses = torch.stack((edr_loss_val, edc_loss_val), dim=-1)\n",
    "\n",
    "if config_dict.num_groups == 1:\n",
    "    scatter_x = opt_input_scalars\n",
    "    scatter_y = opt_output_scalars\n",
    "    xlabel = 'Source gain'\n",
    "    ylabel = 'Receiver gain'\n",
    "else:\n",
    "    scatter_x = opt_input_scalars[0]\n",
    "    scatter_y = opt_input_scalars[-1]\n",
    "    xlabel = 'Receiver gain 2'\n",
    "    ylabel = 'Receiver gain 1'\n",
    "\n",
    "opt_x_idx = np.argmin(np.abs(input_scalars[:, -1].numpy() - opt_input_scalars[0]))\n",
    "opt_y_idx = np.argmin(np.abs(output_scalars[:, 0].numpy() - opt_output_scalars[1]))\n",
    "logger.info(f'Calc EDR loss at optimum values: {edr_loss_val[opt_x_idx, opt_y_idx]}')\n",
    "logger.info(f'Calc EDC loss at optimum values: {edc_loss_val[opt_x_idx, opt_y_idx]}')\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 15))\n",
    "for k in range(num_losses):\n",
    "    ax = fig.add_subplot(num_losses, 1, k+1, projection='3d')\n",
    "    surface = ax.plot_surface(input_scalar_grid, output_scalar_grid, losses[..., k].squeeze(), cmap='viridis', edgecolor='none', alpha=0.5)\n",
    "    ax.scatter(scatter_y, scatter_x, opt_losses[k], color='r', marker= 'x', s=100, label='Optimum loss', alpha=1.0)\n",
    "    ax.scatter(input_scalars[opt_x_idx, -1], output_scalars[opt_y_idx, 0], losses[opt_x_idx, opt_y_idx, k], \n",
    "               color='k', marker= 'x', s=100, label='Grid loss closest to opt values', alpha=1.0)\n",
    "\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_zlabel(f'{loss_names[k]} Loss')\n",
    "    \n",
    "    # Add color bar\n",
    "    fig.colorbar(surface, ax=ax, shrink=0.5, aspect=10)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'{fig_path}/{config_name}_loss_surfaces_masked_edc.png', bbox_inches='tight', pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Interactive plot with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Plotly figure\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add 3D surface and scatter for each loss type\n",
    "for k in range(num_losses):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add 3D surface for current loss\n",
    "    fig.add_trace(go.Surface(\n",
    "        z=losses[..., k].squeeze().numpy(),  # Losses data\n",
    "        x=input_scalar_grid,  # X coordinates (input_scalar_grid)\n",
    "        y=output_scalar_grid,  # Y coordinates (output_scalar_grid)\n",
    "        colorscale='Viridis',  # Colormap\n",
    "        opacity=0.5,\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=f'{loss_names[k]} Loss',\n",
    "                      thickness=20,  # Adjust thickness to make the colorbar narrower\n",
    "                        len=0.3,  # Adjust length to make the colorbar shorter\n",
    "                        x=1.05,  # Adjust x to place colorbar outside the plot\n",
    "                        y=0.5,   # Adjust y to place colorbar at the middle\n",
    "                        ticks='outside'  # Position ticks outside the colorbar\n",
    "        ),\n",
    "        name=f'{loss_names[k]} Surface'\n",
    "    ))\n",
    "\n",
    "    # Add scatter for optimal points\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[scatter_x], \n",
    "        y=[scatter_y], \n",
    "        z=opt_losses[k].numpy(), \n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=2, symbol='x'),\n",
    "        name='Optimum Loss'\n",
    "    ))\n",
    "\n",
    "    # fig.add_trace(go.Scatter3d(\n",
    "    #     x=[input_scalars[opt_x_idx,-1]], \n",
    "    #     y=[output_scalars[opt_y_idx,0]], \n",
    "    #     z=[losses[opt_x_idx, opt_y_idx, k]], \n",
    "    #     mode='markers',\n",
    "    #     marker=dict(color='black', size=2, symbol='x'),\n",
    "    #     name='Grid loss closest to opt values'\n",
    "    # ))\n",
    "\n",
    "    # Update layout to add axis labels and titles\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=xlabel,\n",
    "            yaxis_title=ylabel,\n",
    "            zaxis_title='Loss Value',\n",
    "        ),\n",
    "        # xaxis=dict(automargin=True),\n",
    "        # yaxis=dict(automargin=True),\n",
    "        margin=dict(l=0, r=0, b=0, t=40),\n",
    "        height=500,  # Adjust the height to make it bigger\n",
    "        width=600,\n",
    "        # for top vie\n",
    "        scene_camera=dict(\n",
    "        eye=dict(x=0, y=0, z=2.3)  # z=2 moves the camera directly above\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "    # Save the figure as PNG\n",
    "    fig.write_image(f'{fig_path}/{config_name}_{loss_names[k]}_surfaces_masked_edc.png', width=600, height=500, scale=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
