{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Load dataset and save IRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_gfdn.dataloader import ThreeRoomDataset, load_dataset\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType\n",
    "from diff_gfdn.model import DiffGFDNVarReceiverPos\n",
    "from diff_gfdn.utils import get_response, db, is_unitary, is_paraunitary\n",
    "from diff_gfdn.losses import get_stft_torch, get_edr_from_stft\n",
    "from diff_gfdn.plot import plot_polynomial_matrix_magnitude_response, plot_edr\n",
    "from run_model import load_and_validate_config\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional\n",
    "from numpy.typing import ArrayLike\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from loguru import logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Read config files and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../data/config/'\n",
    "config_name = 'antialiasing_reg_loss_more_layers_filter_coupling'\n",
    "config_file = config_path + f'{config_name}.yml'\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       DiffGFDNConfig)\n",
    "room_data = ThreeRoomDataset(Path(config_dict.room_dataset_path).resolve(), config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of groups to the config dictionary\n",
    "config_dict = config_dict.copy(update={\"num_groups\": room_data.num_rooms})\n",
    "\n",
    "if config_dict.sample_rate != room_data.sample_rate:\n",
    "    logger.warn(\"Config sample rate does not match data, alterning it\")\n",
    "    config_dict.sample_rate = sample_rate\n",
    "\n",
    "# get the training config\n",
    "trainer_config = config_dict.trainer_config\n",
    "\n",
    "# force the trainer config device to be CPU\n",
    "if trainer_config.device != 'cpu':\n",
    "    trainer_config = trainer_config.copy(update={\"device\": 'cpu'})\n",
    "\n",
    "# prepare the training and validation data for DiffGFDN\n",
    "train_dataset, valid_dataset = load_dataset(\n",
    "    room_data, trainer_config.device, trainer_config.train_valid_split,\n",
    "    trainer_config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Check output data and compare with true IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the model\n",
    "model = DiffGFDNVarReceiverPos(room_data.sample_rate, room_data.num_rooms,\n",
    "                 config_dict.delay_length_samps,\n",
    "                 trainer_config.device, \n",
    "                 config_dict.feedback_loop_config,\n",
    "                 config_dict.output_filter_config,\n",
    "                 config_dict.use_absorption_filters,\n",
    "                 common_decay_times=room_data.common_decay_times,\n",
    "                 band_centre_hz=room_data.band_centre_hz\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory  = Path(\"../audio/\")\n",
    "fig_path = Path(\"../figures\").resolve()\n",
    "checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "max_epochs = trainer_config.max_epochs\n",
    "save_ir_dir = Path(trainer_config.ir_dir).resolve() \n",
    "save_ir = False\n",
    "plot_ir = not save_ir \n",
    "pos_to_investigate = [0.20, 5.60, 1.50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    # load the trained weights for the particular epoch\n",
    "    checkpoint = torch.load(f'{checkpoint_dir}/model_e{epoch}.pt', weights_only=True, map_location=torch.device('cpu'))\n",
    "    # Load the trained model state\n",
    "    model.load_state_dict(checkpoint)\n",
    "    # in eval mode, no gradients are calculated\n",
    "    model.eval()\n",
    "    \n",
    "    for data in train_dataset:\n",
    "        position = data['listener_position']\n",
    "        H, h = get_response(data, model)\n",
    "        \n",
    "        for num_pos in range(position.shape[0]):\n",
    "            filename = f'ir_({position[num_pos,0]:.2f}, {position[num_pos, 1]:.2f}, {position[num_pos, 2]:.2f}).wav'\n",
    "            \n",
    "            # find the true IR corresponding to this position\n",
    "            filepath_true = os.path.join(Path(audio_directory/'true').resolve(), filename)\n",
    "            h_true = torch.from_numpy(sf.read(filepath_true)[0])\n",
    "\n",
    "            if plot_ir and np.array_equal(position[num_pos, :], pos_to_investigate):\n",
    "                # get the biquad coefficients for this position\n",
    "                param_dict = model.get_param_dict()\n",
    "                output_biquad_coeffs = param_dict['output_biquad_coeffs'][num_pos]\n",
    "\n",
    "                # plot the EDRs of the true and estimated\n",
    "                plot_edr(h_true, model.sample_rate, title=f'True RIR EDR, epoch={epoch}', \n",
    "                         save_path=f'{fig_path}/true_edr_{filename}_{config_name}_epoch={epoch}.png')\n",
    "\n",
    "                plot_edr(h[num_pos, :], model.sample_rate, title=f'Estimated RIR EDR, epoch={epoch}', \n",
    "                         save_path=f'{fig_path}/approx_edr_{filename}_{config_name}_epoch={epoch}.png')\n",
    "        \n",
    "                plt.plot(torch.stack((h_true, h[num_pos, :len(h_true)]), dim=-1))\n",
    "                plt.xlim([0, int(1.5 * model.sample_rate)])\n",
    "                plt.savefig(f'{fig_path}/ir_compare_{filename}_{config_name}_epoch={epoch}.png')\n",
    "                plt.show()\n",
    "                break\n",
    "\n",
    "            if save_ir and (epoch == max_epochs - 1):\n",
    "                outer_loop_break = False\n",
    "                filepath = os.path.join(save_ir_dir, filename)\n",
    "                torchaudio.save(filepath,\n",
    "                            torch.stack((h[num_pos, :], h[num_pos, :]),\n",
    "                                        dim=1).cpu(),\n",
    "                            int(model.sample_rate),\n",
    "                            bits_per_sample=32,\n",
    "                            channels_first=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Plot the output filter response for the position under investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import sosfreqz, sos2zpk\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig2, ax2 = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "\n",
    "for n in range(room_data.num_rooms):\n",
    "    cur_biquad_coeffs = output_biquad_coeffs[n]\n",
    "    num_biquads = cur_biquad_coeffs.shape[0]\n",
    "    # ensure a0 = 1 (needed by scipy)\n",
    "    for k in range(num_biquads):\n",
    "        cur_biquad_coeffs[k,:] /= cur_biquad_coeffs[k, 3]\n",
    "\n",
    "    freqs, filt_response = sosfreqz(cur_biquad_coeffs, worN=2**9, fs=room_data.sample_rate)\n",
    "    ax.semilogx(freqs, 20*np.log10(np.abs(filt_response)), label=f'Group {n}')\n",
    "\n",
    "    # also plot the poles and zeros\n",
    "    zeros, poles, gain = sos2zpk(cur_biquad_coeffs)\n",
    "    ax2.plot(np.angle(zeros), np.abs(zeros), 'o', label=f'Group {n}')\n",
    "    ax2.plot(np.angle(poles), np.abs(poles), 'x', label=f'Group {n}')\n",
    "\n",
    "    \n",
    "ax.set_xlabel('Frequency (Hz)')\n",
    "ax.set_ylabel('Magnitude (dB)')\n",
    "ax.set_title(f'Output filter for position {pos_to_investigate}')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "fig.savefig(f'{fig_path}/{config_name}_output_filter_response.png')\n",
    "\n",
    "ax2.set_rmax(1)\n",
    "ax2.set_rticks([0.25, 0.5, 1])  # Less radial ticks\n",
    "ax2.set_rlabel_position(-22.5)  # Move radial labels away from plotted line\n",
    "ax2.grid(True)\n",
    "fig2.savefig(f'{fig_path}/{config_name}_output_filter_pz_plot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Get the final trained parameters and investigate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "param_path = Path(trainer_config.train_dir + '/parameters_opt.mat')\n",
    "opt_params = loadmat(param_path.resolve())\n",
    "print(opt_params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Observe the individual mixing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import diff_gfdn\n",
    "reload(diff_gfdn.utils)\n",
    "from diff_gfdn.utils import is_unitary\n",
    "\n",
    "if config_dict.feedback_loop_config.coupling_matrix_type in (CouplingMatrixType.SCALAR, CouplingMatrixType.FILTER):\n",
    "    M_list = opt_params['feedback_loop.M']\n",
    "    num_groups = model.num_groups\n",
    "    fig, ax = plt.subplots(num_groups, 1, figsize=(6,6))\n",
    "    \n",
    "    for i in range(num_groups):\n",
    "        M = torch.from_numpy(M_list[i, ...])\n",
    "        with torch.no_grad():\n",
    "            M_ortho = model.feedback_loop.ortho_param(M)\n",
    "        ax[i].matshow(torch.abs(M_ortho))\n",
    "        ax[i].set_title(f'Room {i}')\n",
    "        is_ortho, max_val = is_unitary(M_ortho)\n",
    "        print(max_val)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/individual_feedback_matrices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Observe the input gains, coupling matrix and the coupled mixing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_feedback_matrix = opt_params['coupled_feedback_matrix']\n",
    "input_gains = opt_params['input_gains'][0]\n",
    "output_gains = opt_params['output_gains'][0]\n",
    "print(f'Norm of input gains {np.linalg.norm(input_gains)}')\n",
    "print(f'Norm of output gains {np.linalg.norm(output_gains)}')\n",
    "\n",
    "if config_dict.feedback_loop_config.coupling_matrix_type == CouplingMatrixType.SCALAR:\n",
    "    assert is_unitary(torch.from_numpy(coupled_feedback_matrix))[0]    \n",
    "    coupling_matrix = opt_params['coupling_matrix']\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.matshow(np.abs(coupling_matrix), fignum=False)\n",
    "    plt.colorbar()\n",
    "    plt.title('Coupling matrix')\n",
    "    plt.subplot(212)\n",
    "    plt.matshow(np.abs(coupled_feedback_matrix), fignum=False)\n",
    "    plt.colorbar()\n",
    "    plt.title('Coupled feedback matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/scalar_coupling_matrix.png')\n",
    "\n",
    "\n",
    "elif config_dict.feedback_loop_config.coupling_matrix_type == CouplingMatrixType.FILTER:\n",
    "    # assert is_paraunitary(torch.from_numpy(coupled_feedback_matrix))[0]\n",
    "    coupling_matrix = opt_params['coupling_matrix']\n",
    "    num_freq_bins = 2**10\n",
    "    plot_polynomial_matrix_magnitude_response(coupling_matrix, model.sample_rate, num_freq_bins, 'Coupling matrix response')\n",
    "    plt.savefig(f'{fig_path}/pu_coupling_matrix.png')\n",
    "\n",
    "else:\n",
    "    feedback_matrix = opt_params['coupled_feedback_matrix']\n",
    "    unit_flag, max_val = is_unitary(torch.tensor(feedback_matrix), max_tol=1e-4)\n",
    "    assert unit_flag\n",
    "    plt.figure()\n",
    "    plt.matshow(np.abs(feedback_matrix))\n",
    "    plt.title('Optimised feedback matrix')\n",
    "    plt.savefig(f'{fig_path}/random_coupling_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
