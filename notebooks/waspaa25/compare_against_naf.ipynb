{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from loguru import logger\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from typing import List\n",
    "from scipy.fft import rfft, irfft\n",
    "import spaudiopy as spa\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('../..')\n",
    "from spatial_sampling.dataloader import parse_three_room_data, SpatialRoomDataset, load_dataset\n",
    "from spatial_sampling.config import SpatialSamplingConfig\n",
    "from src.sofa_parser import HRIRSOFAReader, SRIRSOFAWriter, convert_srir_to_brir\n",
    "from src.sound_examples import binaural_dynamic_rendering\n",
    "from spatial_sampling.inference import get_ambisonic_rirs\n",
    "\n",
    "from diff_gfdn.plot import plot_edc_error_in_space, plot_edr_error_in_space\n",
    "from diff_gfdn.utils import ms_to_samps\n",
    "\n",
    "from diff_gfdn.config.config_loader import load_and_validate_config\n",
    "from src.dataclass import NAFDatasetUnpickler, NAFDatasetTrain, NAFDatasetInfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = 'output/spatial_sampling/sound_examples'\n",
    "room_data_pkl_path = Path('resources/Georg_3room_FDTD/srirs_spatial.pkl').resolve()\n",
    "config_path = Path('data/config/spatial_sampling/').resolve()\n",
    "fig_path = Path('figures/spatial_sampling').resolve()\n",
    "save_path = Path('resources/Georg_3room_FDTD').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = f'{config_path}/treble_data_grid_training_1000Hz_directional_spatial_sampling_test.yml'\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       SpatialSamplingConfig)\n",
    "hrtf_path = Path('resources/HRTF/48kHz/KEMAR_Knowl_EarSim_SmallEars_FreeFieldComp_48kHz.sofa')\n",
    "\n",
    "# get the original dataset\n",
    "room_data = parse_three_room_data(room_data_pkl_path)\n",
    "\n",
    "# get the HRTF\n",
    "hrtf_reader = HRIRSOFAReader(hrtf_path)\n",
    "\n",
    "if hrtf_reader.fs != room_data.sample_rate:\n",
    "    logger.info(\n",
    "            f\"Resampling HRTFs to {room_data.sample_rate:.0f} Hz\")\n",
    "    hrtf_reader.resample_hrirs(room_data.sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Get BRIRs from trained MLPs / NAFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get train dataset for different grid spacings\n",
    "grid_resolution_m = np.arange(config_dict.num_grid_spacing, 0,\n",
    "                                  -1) * room_data.grid_spacing_m\n",
    "head_orientations = np.zeros((4, 2))\n",
    "# these are the only directions in NAF\n",
    "head_orientations[:, 0] = np.array([0, 90, 180, 270])\n",
    "num_ori = head_orientations.shape[0]\n",
    "num_ears = 2\n",
    "error_edc = {}\n",
    "error_edr = {}\n",
    "leave_out_samps = ms_to_samps(5,room_data.sample_rate)\n",
    "mixing_time_samps = ms_to_samps(room_data.mixing_time_ms, room_data.sample_rate)\n",
    "trunc_at = ms_to_samps(2000, room_data.sample_rate)\n",
    "k = 0 #range(config_dict.num_grid_spacing-1)\n",
    "\n",
    "method = 'proposed'\n",
    "logger.info(f\"Creating BRIRs for spacing = {grid_resolution_m[k]:.1f}m\")\n",
    "if method == 'proposed':\n",
    "    brir_pkl_path = f'{save_path}/mlp_pred_brirs_test_pos_only_grid_spacing={grid_resolution_m[k]:.1f}m.pkl'\n",
    "elif method == 'naf':\n",
    "    brir_pkl_path = f'{save_path}/naf_dataset_infer_grid_spacing={grid_resolution_m[k]:.1f}m.pkl'\n",
    "input_pkl_path = f'{save_path}/naf_dataset_grid_spacing={grid_resolution_m[k]:.1f}m.pkl'\n",
    "cur_key = f'mlp_grid_spacing={grid_resolution_m[k]:.1f}'\n",
    "error_edc[cur_key] = np.zeros((num_ori, num_ears))\n",
    "error_edr[cur_key] = np.zeros((num_ori, num_ears))\n",
    "\n",
    "\n",
    "with open(input_pkl_path, \"rb\") as f:\n",
    "    ref_naf_dataset = NAFDatasetUnpickler(f).load()\n",
    "infer_pos_list = ref_naf_dataset.infer_receiver_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(brir_pkl_path):\n",
    "    logger.info(f'BRIRs already saved for grid spacing = {grid_resolution_m[k]:.1f}m')\n",
    "    with open(brir_pkl_path, \"rb\") as f:\n",
    "        brir_dataset = NAFDatasetUnpickler(f).load()\n",
    "    pred_brirs = brir_dataset.infer_brirs\n",
    "    pred_cs_room_data = deepcopy(room_data)\n",
    "    pred_cs_room_data.update_receiver_pos(infer_pos_list)\n",
    "else:\n",
    "\n",
    "    pred_cs_room_data = get_ambisonic_rirs(infer_pos_list, room_data, \n",
    "                                       use_trained_model=True, config_path=config_path, grid_resolution_m=grid_resolution_m[k])\n",
    "  \n",
    "    pred_brirs = convert_srir_to_brir(pred_cs_room_data.rirs, hrtf_reader, head_orientations)\n",
    "    mlp_brir_dataset = NAFDatasetInfer(head_orientations[:, 0],\n",
    "                                     ref_naf_dataset.num_infer_receivers,\n",
    "                                     ref_naf_dataset.infer_receiver_pos,\n",
    "                                     gt_brirs = ref_naf_dataset.infer_brirs,\n",
    "                                     infer_brirs = pred_brirs,\n",
    "                                     )\n",
    "    with open(brir_pkl_path, \"wb\") as f:\n",
    "        pickle.dump(mlp_brir_dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Calculate overall EDC error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the EDC error per orientation and ear\n",
    "time_slice_idx = np.arange(mixing_time_samps, mixing_time_samps + trunc_at-leave_out_samps, dtype=np.int32)\n",
    "\n",
    "for ori in range(head_orientations.shape[0]):\n",
    "    for ear in range(2):\n",
    "        cur_room_data = deepcopy(room_data)\n",
    "        cur_room_data.update_receiver_pos(infer_pos_list)\n",
    "        cur_room_data.update_rirs(ref_naf_dataset.infer_brirs[:, ori, time_slice_idx, ear])\n",
    "        cur_brirs = np.squeeze(pred_brirs[:, ori, :trunc_at-leave_out_samps, ear])\n",
    "\n",
    "        save_path_edc = f'{fig_path}/edc_error_{method}_brir_ori={int(head_orientations[ori, 0])}_ear={ear}_grid_spacing={grid_resolution_m[k]:.1f}m.png'\n",
    "        save_path_edr = f'{fig_path}/edr_error_{method}_brir_ori={int(head_orientations[ori, 0])}_ear={ear}_grid_spacing={grid_resolution_m[k]:.1f}m.png'\n",
    "        \n",
    "        ## NOTE- IT IS VERY IMPORTANT TO SET NORM_EDC = TRUE.\n",
    "        #This is because the MLPs were trained on EDCs created from the common slope parameters(this reduced the amount of\n",
    "        #data to be loaded during training and sped it up considerably). Now, the common slope amps have been normalised\n",
    "        #in the downloaded dataset. Therefore, the scale of the predicted and true EDC won't match unless we normalise the EDCs.\n",
    "        \n",
    "        err_edc = plot_edc_error_in_space(cur_room_data, cur_brirs, infer_pos_list, scatter=True, \n",
    "                                          pos_sorted=True, save_path=save_path_edc, norm_edc=True)\n",
    "        error_edc[cur_key][ori, ear] = err_edc\n",
    "        err_edr = plot_edr_error_in_space(cur_room_data, cur_brirs, infer_pos_list, \n",
    "                                          scatter=True, pos_sorted=True, save_path=save_path_edr)\n",
    "        error_edr[cur_key][ori, ear] = err_edr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Calculate octave band EDC errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from slope2noise.utils import octave_filtering\n",
    "\n",
    "# now plot the EDC error per orientation and ear\n",
    "f_bands = [63, 125, 250, 500, 1000, 2000, 4000, 8000]\n",
    "band_error_edc = {}\n",
    "band_error_edc[cur_key] = np.zeros((len(f_bands),num_ori, num_ears))\n",
    "time_slice_idx = np.arange(mixing_time_samps, mixing_time_samps + trunc_at-leave_out_samps, dtype=np.int32)\n",
    "\n",
    "\n",
    "for ori in range(num_ori):\n",
    "    for ear in range(num_ears):\n",
    "        cur_room_data = deepcopy(room_data)\n",
    "        cur_room_data.update_receiver_pos(infer_pos_list)\n",
    "        cur_ref_brirs = ref_naf_dataset.infer_brirs[:, ori, time_slice_idx, ear]\n",
    "        cur_pred_brirs = np.squeeze(pred_brirs[:, ori, :trunc_at-leave_out_samps, ear])\n",
    "\n",
    "        filtered_ref_brirs = octave_filtering(cur_ref_brirs, room_data.sample_rate, f_bands)\n",
    "        filtered_pred_brirs = octave_filtering(cur_pred_brirs, room_data.sample_rate, f_bands)\n",
    "\n",
    "        for b_idx in range(len(f_bands)):\n",
    "            logger.info(f'Plotting EDC error for freq = {f_bands[b_idx]}Hz, azimuth = {head_orientations[ori, 0]:.1f}, ear = {ear}')\n",
    "\n",
    "            cur_room_data.update_rirs(filtered_ref_brirs[..., b_idx])\n",
    "            save_path_edc = f'{fig_path}/edc_error_{method}_brir_ori={int(head_orientations[ori, 0])}_ear={ear}_freq={f_bands[b_idx]}Hz_grid_spacing={grid_resolution_m[k]:.1f}m.png'\n",
    "            save_path_edr = f'{fig_path}/edr_error_{method}_brir_ori={int(head_orientations[ori, 0])}_ear={ear}_freq={f_bands[b_idx]}Hz_grid_spacing={grid_resolution_m[k]:.1f}m.png'\n",
    "            \n",
    "            ## NOTE- IT IS VERY IMPORTANT TO SET NORM_EDC = TRUE.\n",
    "            #This is because the MLPs were trained on EDCs created from the common slope parameters(this reduced the amount of\n",
    "            #data to be loaded during training and sped it up considerably). Now, the common slope amps have been normalised\n",
    "            #in the downloaded dataset. Therefore, the scale of the predicted and true EDC won't match unless we normalise the EDCs.\n",
    "            \n",
    "            err_edc = plot_edc_error_in_space(cur_room_data, filtered_pred_brirs[..., b_idx], infer_pos_list, scatter=True, \n",
    "                                              pos_sorted=True, save_path=save_path_edc, norm_edc=True)\n",
    "            band_error_edc[cur_key][b_idx, ori, ear] = err_edc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Print EDC errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Overall EDC errors for grid spacing = {grid_resolution_m[k]:.1f}m are {np.round(error_edc[cur_key], 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Overall mean EDC error for grid spacing = {grid_resolution_m[k]:.1f}m are {np.round(np.mean(error_edc[cur_key]), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f'Bandwise BRIR EDC errors for grid spacing = {grid_resolution_m[k]:.1f}m are \\n {np.round(np.mean(band_error_edc[cur_key], axis=1), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Plot for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_gfdn.utils import ms_to_samps, db\n",
    "from slope2noise.utils import schroeder_backward_int\n",
    "\n",
    "edc_true = schroeder_backward_int(ref_naf_dataset.infer_brirs[52, ori, time_slice_idx, :], \n",
    "                                  time_axis=-2, normalize=True)\n",
    "edc_pred = schroeder_backward_int(pred_brirs[52, ori, :trunc_at-leave_out_samps, :], time_axis=-2, normalize=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(db(edc_true, is_squared=True))\n",
    "plt.plot(db(edc_pred, is_squared=True))\n",
    "plt.xlabel('Time (samples)')\n",
    "plt.ylabel('Magnitude (dB')\n",
    "plt.title('EDC')\n",
    "plt.legend(['Ref L', 'Ref R', 'Pred L', 'Pred R'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
