{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Load dataset and save IRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from loguru import logger\n",
    "\n",
    "os.chdir('..')  # This changes the working directory to DiffGFDN\n",
    "from diff_gfdn.dataloader import ThreeRoomDataset, load_dataset\n",
    "from diff_gfdn.config.config import DiffGFDNConfig, CouplingMatrixType\n",
    "from diff_gfdn.model import DiffGFDNVarReceiverPos\n",
    "from diff_gfdn.utils import get_response, db, ms_to_samps, is_unitary, is_paraunitary, is_unitary, normalised_echo_density\n",
    "from diff_gfdn.losses import get_stft_torch, get_edr_from_stft\n",
    "from diff_gfdn.plot import (plot_polynomial_matrix_magnitude_response, \n",
    "                            plot_edr, plot_subband_amplitudes, plot_subband_edc,\n",
    "                            plot_learned_svf_response, plot_amps_in_space, plot_magnitude_response, plot_edc_error_in_space)\n",
    "from diff_gfdn.analysis import get_amps_for_rir\n",
    "from diff_gfdn.config.config_loader import load_and_validate_config\n",
    "from diff_gfdn.inference import InferDiffGFDN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Read config files and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'data/config/'\n",
    "config_name = 'treble_data_grid_training_full_band_colorless_loss'\n",
    "config_file = config_path + f'{config_name}.yml'\n",
    "config_dict = load_and_validate_config(config_file,\n",
    "                                       DiffGFDNConfig)\n",
    "\n",
    "\n",
    "if \"3room_FDTD\" in config_dict.room_dataset_path:\n",
    "    room_data = ThreeRoomDataset(Path(config_dict.room_dataset_path).resolve(), config_dict)\n",
    "else:\n",
    "    room_data = convert_common_slopes_rir_to_room_dataset(config_dict.room_dataset_path, \n",
    "                                                          num_freq_bins=config_dict.trainer_config.num_freq_bins,\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add number of groups to the config dictionary\n",
    "config_dict = config_dict.model_copy(update={\"num_groups\": room_data.num_rooms})\n",
    "\n",
    "if config_dict.sample_rate != room_data.sample_rate:\n",
    "    logger.warn(\"Config sample rate does not match data, alterning it\")\n",
    "    config_dict.sample_rate = sample_rate\n",
    "\n",
    "# get the training config\n",
    "trainer_config = config_dict.trainer_config\n",
    "\n",
    "# force the trainer config device to be CPU\n",
    "if trainer_config.device != 'cpu':\n",
    "    trainer_config = trainer_config.model_copy(update={\"device\": 'cpu'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Run inference and compare with true IR at a single position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the model\n",
    "model = DiffGFDNVarReceiverPos(room_data.sample_rate, \n",
    "                               room_data.num_rooms,\n",
    "                               config_dict.delay_length_samps,\n",
    "                               trainer_config.device, \n",
    "                               config_dict.feedback_loop_config,\n",
    "                               config_dict.output_filter_config,\n",
    "                               config_dict.decay_filter_config.use_absorption_filters,\n",
    "                               common_decay_times=room_data.common_decay_times,\n",
    "                               band_centre_hz=room_data.band_centre_hz,\n",
    "                               use_colorless_loss = trainer_config.use_colorless_loss,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_directory  = Path(\"audio/\")\n",
    "fig_path = Path(\"figures\").resolve()\n",
    "checkpoint_dir = Path(trainer_config.train_dir + 'checkpoints/').resolve()\n",
    "max_epochs = trainer_config.max_epochs\n",
    "save_ir_dir = Path(trainer_config.ir_dir).resolve() \n",
    "plot_ir = False\n",
    "# investigate outputs at this position\n",
    "pos_to_investigate = [9.3, 6.60, 1.50] #[2.0, 6.8, 1.5]\n",
    "desired_filename = f'ir_({pos_to_investigate[0]:.2f}, {pos_to_investigate[1]:.2f}, {pos_to_investigate[2]:.2f}).wav'\n",
    "\n",
    "# find amplitudes corresponding to the receiver position\n",
    "rec_pos_idx = np.where(\n",
    "    np.all(np.round(room_data.receiver_position, 2) == pos_to_investigate, axis=1))[0]\n",
    "amplitudes = room_data.amplitudes[rec_pos_idx, ...]\n",
    "h_true = np.squeeze(room_data.rirs[rec_pos_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_gfdn = InferDiffGFDN(room_data, config_dict, model)\n",
    "epoch_list = [max_epochs-1]\n",
    "h_approx_list, all_pos, all_rirs, all_output_scalars, all_learned_params = infer_gfdn.get_model_output(epoch_list, \n",
    "                                                                                                       desired_filename, \n",
    "                                                                                                       True,\n",
    "                                                                                                       h_true,\n",
    "                                                                                                       config_name, \n",
    "                                                                                                       fig_path)\n",
    "\n",
    "input_gains = all_learned_params.input_gains\n",
    "output_gains = all_learned_params.output_gains\n",
    "input_scalars = all_learned_params.input_scalars\n",
    "output_biquad_coeffs = all_learned_params.output_biquad_coeffs\n",
    "coupled_feedback_matrix = all_learned_params.coupled_feedback_matrix\n",
    "coupling_matrix = all_learned_params.coupling_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "#### Plot subband EDC as a function of epoch number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(h_approx_list) > 0:\n",
    "    plot_subband_edc(h_true, h_approx_list, config_dict.sample_rate, room_data.band_centre_hz, pos_to_investigate, epoch_numbers=epoch_list,\n",
    "                     save_path=f'{fig_path}/compare_synth_edf_{pos_to_investigate}_{config_name}.png', \n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "#### Plot the output filter response for the position under investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(h_approx_list) > 0:\n",
    "    save_path = f'{fig_path}/{config_name}'\n",
    "    plot_learned_svf_response(room_data.num_rooms, int(room_data.sample_rate), \n",
    "                              output_biquad_coeffs, pos_to_investigate, save_path=save_path, epoch_numbers=epoch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Investigate the modes of the receiver filters to see how they affect the modes of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "from typing import Tuple, Optional, Dict, List\n",
    "from scipy.signal import sos2zpk, zpk2tf, residue\n",
    "\n",
    "def compute_modes_from_sos(sos: NDArray) -> Tuple[ArrayLike, ArrayLike]:\n",
    "    \"\"\"\n",
    "    Compute the modes (poles and residues) using partial fraction expansion from SOS representation.\n",
    "\n",
    "    Args:\n",
    "        sos (array-like): Second-order sections (SOS) filter representation.\n",
    "\n",
    "    Returns:\n",
    "        poles (np.ndarray): Poles of the system.\n",
    "        residues (np.ndarray): Residues corresponding to each pole.\n",
    "    \"\"\"\n",
    "    # Convert SOS to zero-pole-gain form\n",
    "    z, p, k = sos2zpk(sos)\n",
    "\n",
    "    # Convert to transfer function form\n",
    "    b, a = zpk2tf(z, p, k)  # Get numerator and denominator polynomials\n",
    "\n",
    "    # Perform partial fraction expansion\n",
    "    residues, poles, _ = residue(b, a)\n",
    "\n",
    "    return poles, residues\n",
    "    \n",
    "def zp_to_modes(residues: List, poles: List, fs: float) -> Dict:\n",
    "    radius = np.abs(poles)\n",
    "    angles = np.angle(poles)\n",
    "    assert (radius < np.ones_like(radius)).all()\n",
    "    modal_params = {}\n",
    "    # in Hz\n",
    "    modal_params['freqs'] = (angles * fs) / (2*np.pi)\n",
    "    # T60 in ms\n",
    "    modal_params['decay'] = (6.91 / (-np.log(radius) * fs)) * 1e3\n",
    "    # in db\n",
    "    modal_params['amps'] = db(residues)\n",
    "    return modal_params\n",
    "\n",
    "if len(output_biquad_coeffs) > 0:\n",
    "    for idx, epoch in zip([1], [max_epochs-1]):\n",
    "        cur_biquad_coeffs = output_biquad_coeffs[idx]\n",
    "        for k in range(room_data.num_rooms):\n",
    "            cur_sos = cur_biquad_coeffs[k]\n",
    "            poles, residues = compute_modes_from_sos(cur_sos)\n",
    "            modal_params = zp_to_modes(residues, poles, room_data.sample_rate)\n",
    "            logger.info(f'Modal parameters for receiver filters in group {k+1} are: ')\n",
    "            logger.info(f'{np.round(modal_params['freqs'], 3)} Hz, \\n {np.round(modal_params['decay'], 3)} ms, \\n {np.round(modal_params['amps'], 3)} dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Plot actual and achieved subband amplitudes for the position under investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the actual RIR levels\n",
    "if len(h_approx_list) > 0:\n",
    "    final_approx_rir = h_approx_list[-1].clone().detach()\n",
    "    plot_subband_amplitudes(h_true, final_approx_rir, room_data.sample_rate, \n",
    "                            config_dict.num_groups, amplitudes, np.squeeze(room_data.common_decay_times), room_data.band_centre_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Get the final trained parameters and investigate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = Path(trainer_config.train_dir + '/parameters_opt.mat').resolve()\n",
    "opt_params = loadmat(param_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Observe the individual mixing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config_dict.feedback_loop_config.coupling_matrix_type in (CouplingMatrixType.SCALAR, CouplingMatrixType.FILTER):\n",
    "    M_list = opt_params['feedback_loop.M']\n",
    "    num_groups = model.num_groups\n",
    "    fig, ax = plt.subplots(num_groups, 1, figsize=(6,6))\n",
    "    \n",
    "    for i in range(num_groups):\n",
    "        M = torch.from_numpy(M_list[i, ...])\n",
    "        with torch.no_grad():\n",
    "            M_ortho = model.feedback_loop.ortho_param(M)\n",
    "        ax[i].matshow(torch.abs(M_ortho))\n",
    "        ax[i].set_title(f'Room {i}')\n",
    "        is_ortho, max_val = is_unitary(M_ortho)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/individual_feedback_matrices.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### Observe the input gains, coupling matrix and the coupled mixing matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupled_feedback_matrix = opt_params['coupled_feedback_matrix']\n",
    "input_gains = opt_params['input_gains'][0]\n",
    "output_gains = opt_params['output_gains'][0]\n",
    "print(f'Norm of input gains {np.linalg.norm(input_gains)}')\n",
    "print(f'Norm of output gains {np.linalg.norm(output_gains)}')\n",
    "\n",
    "if config_dict.feedback_loop_config.coupling_matrix_type == CouplingMatrixType.SCALAR:\n",
    "    # assert is_unitary(torch.from_numpy(coupled_feedback_matrix))[0]    \n",
    "    coupling_matrix = opt_params['coupling_matrix']\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.matshow(np.abs(coupling_matrix), fignum=False)\n",
    "    plt.colorbar()\n",
    "    plt.title('Coupling matrix')\n",
    "    plt.subplot(212)\n",
    "    plt.matshow(np.abs(coupled_feedback_matrix), fignum=False)\n",
    "    plt.colorbar()\n",
    "    plt.title('Coupled feedback matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}/scalar_coupling_matrix.png')\n",
    "\n",
    "\n",
    "elif config_dict.feedback_loop_config.coupling_matrix_type == CouplingMatrixType.FILTER:\n",
    "    # assert is_paraunitary(torch.from_numpy(coupled_feedback_matrix))[0]\n",
    "    coupling_matrix = opt_params['coupling_matrix']\n",
    "    num_freq_bins = 2**10\n",
    "    plot_polynomial_matrix_magnitude_response(coupling_matrix, model.sample_rate, num_freq_bins, \n",
    "                                             'Coupling matrix response', save_path=f'{fig_path}/pu_coupling_matrix.png')\n",
    "else:\n",
    "    feedback_matrix = opt_params['coupled_feedback_matrix']\n",
    "    unit_flag, max_val = is_unitary(torch.tensor(feedback_matrix), max_tol=1e-4)\n",
    "    assert unit_flag\n",
    "    plt.figure()\n",
    "    plt.matshow(np.abs(feedback_matrix))\n",
    "    plt.title('Optimised feedback matrix')\n",
    "    plt.savefig(f'{fig_path}/random_coupling_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Plot magnitude response of each sub-FDN to inspect colouration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'{fig_path}/{config_name}_mag_spectrum.png'\n",
    "plot_magnitude_response(room_data, config_dict, model, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "#### Plot NED pre and post optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = room_data.sample_rate\n",
    "mixing_time_samp = ms_to_samps(20.0, fs)\n",
    "crop_end_samp = ms_to_samps(5.0, fs)\n",
    "trunc_true_ir = h_true[mixing_time_samp:-crop_end_samp]\n",
    "len_ir = len(trunc_true_ir)\n",
    "time = np.linspace(0, (len_ir-1)/ config_dict.sample_rate, len_ir-1)\n",
    "\n",
    "\n",
    "if len(h_approx_list) > 0:\n",
    "    ned_fdn = np.zeros((len_ir-1, max_epochs))\n",
    "    ned_true = normalised_echo_density(h_true[mixing_time_samp:-crop_end_samp], \n",
    "                                       config_dict.sample_rate, window_length_ms=50)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    # ax.plot(time, ned_true, label='Reference')\n",
    "    iterate_over_epochs = epoch_list\n",
    "    for k, epoch in zip(range(len(iterate_over_epochs)), iterate_over_epochs):\n",
    "        h_cur = h_approx_list[k]\n",
    "        ned_fdn[:, epoch] = normalised_echo_density(h_cur[mixing_time_samp: mixing_time_samp + len(trunc_true_ir)], \n",
    "                                                    config_dict.sample_rate, window_length_ms=50)\n",
    "        ax.plot(time, ned_fdn[:, epoch], label=f'GFDN, Epoch={epoch}')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('NED')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([0.001, max(time)])\n",
    "    fig.savefig(f'{fig_path}/{config_name}_ned.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Plot the EDC errors for different band centres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import diff_gfdn\n",
    "reload(diff_gfdn.plot)\n",
    "from diff_gfdn.plot import plot_edc_error_in_space\n",
    "\n",
    "# this will plot errors in all subbands\n",
    "plot_edc_error_in_space(room_data, all_rirs[-1], all_pos[-1], freq_to_plot=1000,  scatter=True, save_path=f'{fig_path}/{config_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
