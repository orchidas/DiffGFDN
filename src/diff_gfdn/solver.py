import os
from pathlib import Path
import pickle
import re
from typing import List, Optional, Tuple, Union

from loguru import logger
import matplotlib.pyplot as plt
import numpy as np
import optuna
from scipy.io import savemat
import torch
from torch.utils.data import DataLoader

from .colorless_fdn.dataloader import load_colorless_fdn_dataset
from .colorless_fdn.model import ColorlessFDN
from .colorless_fdn.trainer import ColorlessFDNTrainer
from .colorless_fdn.utils import ColorlessFDNResults
from .config.config import DiffGFDNConfig
from .dataloader import load_dataset, RIRData, RoomDataset, ThreeRoomDataset
from .model import DiffGFDN, DiffGFDNSinglePos, DiffGFDNVarReceiverPos
from .trainer import SinglePosTrainer, VarReceiverPosTrainer
from .utils import db

# pylint: disable=W0718


def save_diff_gfdn_parameters(net: DiffGFDN, dir_path: str, filename: str):
    """
    Save parameters of DiffGFDN() net to .mat file 
    Args    net (nn.Module): trained FDN() network
            dir_path (string): path to output firectory
            filename (string): name of the file 
    Output  param (dictionary of tensors): FDN() net parameters
            param_np (dictionary of numpy arrays): DiffGFDN() net parameters
    """
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

    param = fdn2dir(net)
    param_np = {}
    for name, value in param.items():
        try:
            param_np[name] = value.squeeze().cpu().numpy()
        except AttributeError:
            param_np[name] = value
    # save parameters in numpy format
    savemat(os.path.join(dir_path, filename), param_np)

    return param, param_np


def save_colorless_fdn_parameters(net: ColorlessFDN, dir_path: str,
                                  filename: str) -> ColorlessFDNResults:
    """
    Save parameters of ColorlessFDN() net to .pkl file 
    Args    net (nn.Module): trained FDN() network
            dir_path (string): path to output firectory
            filename (string): name of the file 
    Output  ColorlessFDNResults: dataclass containing the results of optimisation
    """
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

    param = fdn2dir(net)
    param_np = {}
    for name, value in param.items():
        try:
            param_np[name] = value.squeeze().cpu().numpy() if isinstance(
                value, torch.Tensor) else value
        except AttributeError:
            param_np[name] = value

    colorless_fdn_params = ColorlessFDNResults(
        opt_input_gains=param_np['input_gains'],
        opt_output_gains=param_np['output_gains'],
        opt_feedback_matrix=param_np['feedback_matrix'])
    # save parameters in numpy format
    with open(os.path.join(dir_path, filename), "wb") as f:
        pickle.dump(colorless_fdn_params, f)

    return colorless_fdn_params


def fdn2dir(net: Union[DiffGFDN, ColorlessFDN]):
    """
    Save learnable parameters to a dictionary  
    Args    net (nn.Module): trained FDN() network
    Output  d (dictionary of tensors): FDN() net parameters 
    """
    d = {}  # empty dictionary
    # from parameter dictionary of model
    d = net.get_param_dict()

    # MLP learned weights and biases
    for name, param in net.named_parameters():
        if param.requires_grad and name not in d.keys():
            d[name] = param.data

    return d


def save_loss(train_loss: List,
              output_dir: str,
              save_plot=True,
              filename: str = '',
              xaxis_label: Optional[str] = "epoch #"):
    """
    Save training and validation loss values in .mat format
    Args    train_loss (list): training loss values at each epoch
            output_dir (string): path to output directory
            save_plot (bool): if True saves the plot of the losses in .pdf format
            filename (string): additional string to add before .pdf and .mat
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    losses = {}
    losses['train'] = train_loss
    n_epochs = len(train_loss)

    if save_plot:
        plt.plot(range(1, n_epochs + 1), train_loss)
        plt.xlabel(xaxis_label)
        plt.ylabel('loss')
        plt.savefig(os.path.join(output_dir, filename + '.pdf'))
    savemat(os.path.join(output_dir, 'losses_' + filename + '.mat'), losses)


####################################################################
# For training with artificial dataset


class Slope2NoiseUnpickler(pickle.Unpickler):
    """Custom unpickler for serialised object generated by slope2noise"""

    def find_class(self, module, name: str):
        """Find the correct class in the submodule given a module name"""
        if module == "slope2noise.rooms":
            # Adjust the module path here if needed
            module = "slope2noise.slope2noise.rooms"
        return super().find_class(module, name)


def convert_common_slopes_rir_to_room_dataset(
        data_path: str, num_freq_bins: Optional[int] = None) -> RoomDataset:
    """Convert the dataclass CommonSlopesRIR to RoomDataset"""
    data_path = Path(data_path).resolve()
    with open(data_path, 'rb') as f:
        # rir_data = pickle.load(f)
        rir_data = Slope2NoiseUnpickler(f).load()

    num_rooms = rir_data.n_slopes
    room_dims = rir_data.room_dims
    room_start_coords = rir_data.room_start_coords
    try:
        aperture_coords = rir_data.aperture_coords
    except Exception as e:
        logger.warning(e)
        aperture_coords = None

    source_locs = rir_data.source_locs
    receiver_locs = rir_data.receiver_locs
    common_decay_times = np.array(rir_data.t_vals).T
    band_centre_hz = np.array(rir_data.f_bands)
    amplitudes = rir_data.a_vals
    rirs = rir_data.rir
    sample_rate = rir_data.sample_rate

    room_data = RoomDataset(
        num_rooms,
        sample_rate,
        source_locs,
        receiver_locs,
        rirs,
        common_decay_times=common_decay_times,
        room_dims=room_dims,
        room_start_coord=room_start_coords,
        amplitudes=amplitudes,
        band_centre_hz=band_centre_hz,
        aperture_coords=aperture_coords,
        nfft=num_freq_bins,
    )

    return room_data


def data_parser_var_receiver_pos(
        config_dict: DiffGFDNConfig,
        num_freq_bins: Optional[int] = None) -> RoomDataset:
    """
    Parse the training data for training over a grid of receiver positions (could belong to different rooms)
    Args:
        config_dict (DiffGFDNConfig): config dictionary
        num_freq_bins (int): number of frequency bins to train on
    Returns:
        RoomDataset: object of data type RoomDataset with all the room information
    """
    if "3room_FDTD" in config_dict.room_dataset_path:
        # read the coupled room dataset
        room_data = ThreeRoomDataset(Path(
            config_dict.room_dataset_path).resolve(),
                                     config_dict=config_dict)
    else:
        room_data = convert_common_slopes_rir_to_room_dataset(
            config_dict.room_dataset_path, num_freq_bins)

    return room_data


def data_parser_single_receiver_pos(
    config_dict: DiffGFDNConfig,
    num_freq_bins: Optional[int] = None,
    debug: bool = False,
) -> Tuple[RIRData, RoomDataset, str]:
    """
    Parse the training data for a single receiver position
    Args:
        config_dict (DiffGFDNConfig): config dictionary
        num_freq_bins (int): number of frequency bins to train on
        debug (bool): plots the EDC of the desired RIR, this has caused issues previously
    Returns:
        RIRData, RoomDataset, str: single position dataset, room dataset and the name of the ir
    """
    if "3room_FDTD" in config_dict.room_dataset_path:
        # read the coupled room dataset
        room_data = ThreeRoomDataset(
            Path(config_dict.room_dataset_path).resolve(), config_dict)

    # from the synthetic dataset created in slope2rir
    else:
        room_data = convert_common_slopes_rir_to_room_dataset(
            config_dict.room_dataset_path, num_freq_bins)

    # create a dataset for a single measured IR in the room dataset
    ir_path = Path(config_dict.ir_path).resolve()
    match = re.search(r'ir_\([^)]+\)', config_dict.ir_path)
    ir_name = match.group()

    # find receiver position from string
    match = re.search(r'ir_\(([^,]+), ([^,]+), ([^,]+)\)', ir_name)
    # Convert the extracted values to floats
    x, y, z = map(float, match.groups())
    rec_pos = np.array([x, y, z])

    # find amplitudes corresponding to the receiver position
    rec_pos_idx = np.where(
        np.all(np.round(room_data.receiver_position, 2) == rec_pos,
               axis=1))[0][0]
    amplitudes = np.squeeze(room_data.amplitudes[rec_pos_idx, :])

    # if the reference IR does not exist, create it from the dataset
    if not os.path.isfile(str(ir_path)):
        logger.warning("RIR does not exist in path, creating it...")
        room_data.save_individual_irs(directory=Path(ir_path).parent.resolve())

    rir_data = RIRData(rir=np.squeeze(room_data.rirs[rec_pos_idx, :]),
                       sample_rate=room_data.sample_rate,
                       common_decay_times=room_data.common_decay_times,
                       band_centre_hz=room_data.band_centre_hz,
                       amplitudes=amplitudes,
                       nfft=num_freq_bins)

    # for debugging
    if debug:
        true_rir = rir_data.rir
        true_rir_room_data = np.squeeze(room_data.rirs[rec_pos_idx, :])
        true_edf = np.flipud(np.cumsum(np.flipud(true_rir**2), axis=-1))
        true_edf_room_data = np.flipud(
            np.cumsum(np.flipud(true_rir_room_data**2), axis=-1))

        time = np.linspace(0, (len(true_rir) - 1) / rir_data.sample_rate,
                           len(true_rir))

        plt.figure()
        plt.plot(time, db(true_edf, is_squared=True))
        plt.plot(time, db(true_edf_room_data, is_squared=True))
        plt.plot(np.zeros(len(amplitudes)), db(amplitudes, is_squared=True),
                 'kx')
        plt.xlabel('Time (s)')
        plt.ylabel('Magnitude (dB)')
        plt.show()

    return rir_data, room_data, ir_name


##########################################################################
# For MLP hyperparameter tuning


class MLPTuningConfig:
    """Class for specifying input arguments to the hyperparameter tuning method"""

    def __init__(self,
                 config_dict: DiffGFDNConfig,
                 room_data: RoomDataset,
                 train_dataset: DataLoader,
                 valid_dataset: DataLoader,
                 colorless_fdn_params: Optional[ColorlessFDNResults] = None):
        """
        Args:
            config_dict (DiffGFDNConfig): config file for the network
            room_data (RoomDataset): object containing information about the room's geometry
            train_dataset (Dataloader): dataset containing training samples
            valid_dataset (Dataloader): dataset containing validation samples
            colorless_fdn_params (ColorlessFDNResults): if using a colorless FDN, then the optimised parameters
        """
        self.config_dict = config_dict
        self.room_data = room_data
        self.train_dataset = train_dataset
        self.valid_dataset = valid_dataset
        self.colorless_fdn_params = colorless_fdn_params


def mlp_hyperparameter_tuning(trial, hyp_config: MLPTuningConfig):
    """Do hyperparameter tuning for the MLP"""
    # Define hyperparameters to tune
    output_filter_config = hyp_config.config_dict.output_filter_config
    mlp_tuning_config = output_filter_config.mlp_tuning_config
    trainer_config = hyp_config.config_dict.trainer_config
    output_filter_config = output_filter_config.model_copy(
        update={
            'num_hidden_layers':
            trial.suggest_int('num_hidden_layers', mlp_tuning_config.
                              min_layers, mlp_tuning_config.max_layers),
            'num_neurons_per_layer':
            trial.suggest_int('num_neurons_per_layer',
                              mlp_tuning_config.min_neurons,
                              mlp_tuning_config.max_neurons,
                              step=mlp_tuning_config.step_size)
        })

    # initialise the model
    model = DiffGFDNVarReceiverPos(
        hyp_config.room_data.sample_rate,
        hyp_config.room_data.num_rooms,
        hyp_config.config_dict.delay_length_samps,
        trainer_config.device,
        hyp_config.config_dict.feedback_loop_config,
        output_filter_config,
        hyp_config.config_dict.use_absorption_filters,
        common_decay_times=hyp_config.room_data.common_decay_times,
        band_centre_hz=hyp_config.room_data.band_centre_hz,
        colorless_fdn_params=hyp_config.colorless_fdn_params,
        use_colorless_loss=trainer_config.use_colorless_loss)
    # set default device
    torch.set_default_device(trainer_config.device)
    # move model to device (cuda or cpu)
    model = model.to(trainer_config.device)
    # create the trainer object
    trainer = VarReceiverPosTrainer(model, trainer_config)
    # train the network
    trainer.train(hyp_config.train_dataset)

    # test the network with the validation set
    trainer.validate(hyp_config.valid_dataset)
    # save the validation loss
    save_loss(trainer.valid_loss,
              trainer_config.train_dir,
              save_plot=True,
              filename='test_loss_vs_position',
              xaxis_label='Position #')
    return trainer.valid_loss


#############################################################################
# For training the model


def run_training_colorless_fdn(
        config_dict: DiffGFDNConfig,
        num_freq_bins: int) -> List[ColorlessFDNResults]:
    """
    Run the training for a colorless prototype
    Returns:
        A list of ColorlessFDNResults dataclass, each for one FDN in the GFDN
    """
    logger.info("Training a colorless prototype")
    trainer_config = config_dict.trainer_config

    # prepare the training and validation data for DiffGFDN
    train_dataset, valid_dataset = load_colorless_fdn_dataset(
        num_freq_bins,
        trainer_config.device,
        config_dict.colorless_fdn_config.train_valid_split,
        config_dict.colorless_fdn_config.batch_size,
    )

    params_opt = []
    num_delay_lines_per_group = int(config_dict.num_delay_lines /
                                    config_dict.num_groups)
    for i in range(config_dict.num_groups):

        model = ColorlessFDN(
            config_dict.sample_rate,
            config_dict.delay_length_samps[i *
                                           num_delay_lines_per_group:(i + 1) *
                                           num_delay_lines_per_group],
            trainer_config.device)

        # set default device
        torch.set_default_device(trainer_config.device)
        # move model to device (cuda or cpu)
        model = model.to(trainer_config.device)
        # create the trainer object
        trainer = ColorlessFDNTrainer(model, trainer_config,
                                      config_dict.colorless_fdn_config)

        # save initial parameters and ir
        save_colorless_fdn_parameters(
            trainer.net, trainer_config.train_dir + "colorless-fdn/",
            f'parameters_init_group={i + 1}.pkl')

        # train the network
        trainer.train(train_dataset, valid_dataset)
        # save final trained parameters
        params_opt.append(
            save_colorless_fdn_parameters(
                trainer.net, trainer_config.train_dir + "colorless-fdn/",
                f'parameters_opt_group={i + 1}.pkl'))

        # save loss evolution
        save_loss(trainer.train_loss,
                  trainer_config.train_dir + "colorless-fdn/",
                  save_plot=True,
                  filename=f'training_loss_vs_epoch_group={i + 1}')

    return params_opt


def run_training_var_receiver_pos(config_dict: DiffGFDNConfig):
    """
    Run the training for the differentiable GFDN for a grid of different receiver positions, and save
    its parameters
    Args:
        config_dict (DiffGFDNTrainConfig): configuration parameters for training
    """
    logger.info("Training over a grid of listener positions")

    # get the data
    room_data = data_parser_var_receiver_pos(
        config_dict, num_freq_bins=config_dict.trainer_config.num_freq_bins)

    # add number of groups to the config dictionary
    config_dict = config_dict.model_copy(
        update={"num_groups": room_data.num_rooms})
    assert config_dict.num_delay_lines % config_dict.num_groups == 0, "Delay lines must be \
    divisible by number of groups in network"

    if config_dict.sample_rate != room_data.sample_rate:
        logger.warn("Config sample rate does not match data, alterning it")
        config_dict.sample_rate = room_data.sample_rate

    # get the training config
    trainer_config = config_dict.trainer_config
    # update num_freq_bins in pydantic class
    trainer_config = trainer_config.model_copy(
        update={"num_freq_bins": room_data.num_freq_bins})
    # also update the calculation of reduced_pole_radius
    trainer_config = trainer_config.calculate_reduced_pole_radius(
        trainer_config)

    if config_dict.colorless_fdn_config.use_colorless_prototype and trainer_config.use_colorless_loss:
        raise ValueError(
            "Cannot use optimised colorless FDN parameters and colorless FDN loss together"
        )

    # are we using a colorless FDN to get the feedback matrix?
    if config_dict.colorless_fdn_config.use_colorless_prototype:
        colorless_fdn_params = run_training_colorless_fdn(
            config_dict, room_data.num_freq_bins)
    else:
        colorless_fdn_params = None

    # prepare the training and validation data for DiffGFDN
    train_dataset, valid_dataset = load_dataset(
        room_data,
        trainer_config.device,
        trainer_config.train_valid_split,
        trainer_config.batch_size,
        new_sampling_radius=1.0 / trainer_config.reduced_pole_radius,
    )

    # are we tuning hyperparameters?
    if config_dict.output_filter_config.mlp_tuning_config is not None:
        logger.debug("Tuning MLP hyperparameters")

        study = optuna.create_study(direction="minimize")
        # to enable passing other parameters to this function
        mlp_tuning_with_params = MLPTuningConfig(config_dict, room_data,
                                                 train_dataset, valid_dataset,
                                                 colorless_fdn_params)
        study.optimize(
            lambda trial: mlp_hyperparameter_tuning(trial,
                                                    mlp_tuning_with_params),
            n_trials=config_dict.output_filter_config.mlp_tuning_config.
            num_trials)  # Set number of trials as needed

        logger.debug(f"Best hyperparameters: {study.best_params}")
        logger.debug(f"Best validation loss: {study.best_value}")
        with open(os.path.join(trainer_config.train_dir, "MLP_tuning.pkl"),
                  "wb") as f:
            pickle.dump(
                {
                    'best_hyperparameters': study.best_params,
                    'best_valid_loss': study.best_value
                }, f)
    # or are we running the network with fixed hyperparameters?
    else:
        # initialise the model
        model = DiffGFDNVarReceiverPos(
            room_data.sample_rate,
            room_data.num_rooms,
            config_dict.delay_length_samps,
            trainer_config.device,
            config_dict.feedback_loop_config,
            config_dict.output_filter_config,
            config_dict.use_absorption_filters,
            common_decay_times=room_data.common_decay_times,
            band_centre_hz=room_data.band_centre_hz,
            colorless_fdn_params=colorless_fdn_params,
            use_colorless_loss=trainer_config.use_colorless_loss,
        )
        # set default device
        torch.set_default_device(trainer_config.device)
        # move model to device (cuda or cpu)
        model = model.to(trainer_config.device)
        # create the trainer object
        trainer = VarReceiverPosTrainer(model, trainer_config)

        # save initial parameters and ir
        save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                                  'parameters_init.mat')

        # train the network
        trainer.train(train_dataset)
        # save final trained parameters
        save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                                  'parameters_opt.mat')
        # save loss evolution
        save_loss(trainer.train_loss,
                  trainer_config.train_dir,
                  save_plot=True,
                  filename='training_loss_vs_epoch')

        # test the network with the validation set
        trainer.validate(valid_dataset)
        # save the validation loss
        save_loss(trainer.valid_loss,
                  trainer_config.train_dir,
                  save_plot=True,
                  filename='test_loss_vs_position',
                  xaxis_label='Position #')


def run_training_single_pos(config_dict: DiffGFDNConfig):
    """
    Run the training for the differentiable GFDN for a single RIR measurement, and save its parameters
    Args:
        config_dict (DiffGFDNTrainConfig): configuration parameters for training
    """
    logger.info("Training for a single RIR measurement")

    # get the data
    rir_data, room_data, ir_name = data_parser_single_receiver_pos(
        config_dict, num_freq_bins=config_dict.trainer_config.num_freq_bins)

    # add number of groups to the config dictionary
    config_dict = config_dict.copy(update={"num_groups": room_data.num_rooms})
    assert config_dict.num_delay_lines % config_dict.num_groups == 0, "Delay lines must be \
    divisible by number of groups in network"

    if config_dict.sample_rate != room_data.sample_rate:
        logger.warn("Config sample rate does not match data, alterning it")
        config_dict.sample_rate = room_data.sample_rate

    # get the training config
    trainer_config = config_dict.trainer_config
    # update num_freq_bins in pydantic class
    trainer_config = trainer_config.model_copy(
        update={"num_freq_bins": rir_data.num_freq_bins})

    # prepare the training and validation data for DiffGFDN
    if trainer_config.train_valid_split < 1.0:
        logger.warning('There can be no data in the validation set!')
    if trainer_config.batch_size != rir_data.num_freq_bins:
        logger.warning(
            "Cannot train in batches here. Training on the full unit circle")
        trainer_config = trainer_config.copy(
            update={"batch_size": rir_data.num_freq_bins})
    if config_dict.colorless_fdn_config.use_colorless_prototype and trainer_config.use_colorless_loss:
        raise ValueError(
            "Cannot use optimised colorless FDN parameters and colorless FDN loss together"
        )

    # whether to use a colorless FDN to get input-output gains and feedback matrix
    if config_dict.colorless_fdn_config.use_colorless_prototype:
        colorless_fdn_params = run_training_colorless_fdn(
            config_dict, room_data.num_freq_bins)
    else:
        colorless_fdn_params = None

    train_dataset = load_dataset(rir_data,
                                 trainer_config.device,
                                 trainer_config.train_valid_split,
                                 trainer_config.batch_size,
                                 shuffle=False,
                                 new_sampling_radius=1.0 /
                                 trainer_config.reduced_pole_radius)

    # initialise the model
    model = DiffGFDNSinglePos(
        room_data.sample_rate,
        room_data.num_rooms,
        config_dict.delay_length_samps,
        trainer_config.device,
        config_dict.feedback_loop_config,
        config_dict.output_filter_config,
        config_dict.use_absorption_filters,
        common_decay_times=room_data.common_decay_times,
        band_centre_hz=room_data.band_centre_hz,
        colorless_fdn_params=colorless_fdn_params,
        use_colorless_loss=trainer_config.use_colorless_loss,
    )
    # set default device
    torch.set_default_device(trainer_config.device)
    # move model to device (cuda or cpu)
    model = model.to(trainer_config.device)
    # create the trainer object
    trainer = SinglePosTrainer(model, trainer_config, filename=ir_name)

    # save initial parameters and ir
    save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                              'parameters_init.mat')

    # train the network
    trainer.train(train_dataset)
    # save final trained parameters
    save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                              'parameters_opt.mat')
    # save loss evolution
    save_loss(trainer.train_loss,
              trainer_config.train_dir,
              save_plot=True,
              filename='training_loss_vs_epoch')
