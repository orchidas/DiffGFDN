import os
from pathlib import Path
import pickle
import re
from typing import List, Optional, Tuple, Union

from loguru import logger
import matplotlib.pyplot as plt
import numpy as np
from scipy.io import savemat
import torch

from .colorless_fdn.dataloader import ColorlessFDNResults, load_colorless_fdn_dataset
from .colorless_fdn.model import ColorlessFDN
from .colorless_fdn.trainer import ColorlessFDNTrainer
from .config.config import DiffGFDNConfig
from .dataloader import load_dataset, RIRData, RoomDataset, ThreeRoomDataset
from .model import DiffGFDN, DiffGFDNSinglePos, DiffGFDNVarReceiverPos
from .trainer import SinglePosTrainer, VarReceiverPosTrainer

# pylint: disable=W0718


class Slope2NoiseUnpickler(pickle.Unpickler):
    """Custom unpickler for serialised object generated by slope2noise"""

    def find_class(self, module, name: str):
        """Find the correct class in the submodule given a module name"""
        if module == "slope2noise.rooms":
            # Adjust the module path here if needed
            module = "slope2noise.slope2noise.rooms"
        return super().find_class(module, name)


def convert_common_slopes_rir_to_room_dataset(
        data_path: str, num_freq_bins: Optional[int] = None) -> RoomDataset:
    """Convert the dataclass CommonSlopesRIR to RoomDataset"""
    data_path = Path(data_path).resolve()
    with open(data_path, 'rb') as f:
        rir_data = Slope2NoiseUnpickler(f).load()

    num_rooms = rir_data.n_slopes
    room_dims = rir_data.room_dims
    room_start_coords = rir_data.room_start_coords
    try:
        aperture_coords = rir_data.aperture_coords
    except Exception as e:
        logger.warning(e)
        aperture_coords = None

    source_locs = rir_data.source_locs
    receiver_locs = rir_data.receiver_locs
    common_decay_times = np.array(rir_data.t_vals).T
    band_centre_hz = np.array(rir_data.f_bands)
    amplitudes = rir_data.a_vals
    rirs = rir_data.rir
    sample_rate = rir_data.sample_rate

    room_data = RoomDataset(
        num_rooms,
        sample_rate,
        source_locs,
        receiver_locs,
        rirs,
        common_decay_times=common_decay_times,
        room_dims=room_dims,
        room_start_coord=room_start_coords,
        amplitudes=amplitudes,
        band_centre_hz=band_centre_hz,
        aperture_coords=aperture_coords,
        nfft=num_freq_bins,
    )

    return room_data


def save_diff_gfdn_parameters(net: DiffGFDN, dir_path: str, filename: str):
    """
    Save parameters of DiffGFDN() net to .mat file 
    Args    net (nn.Module): trained FDN() network
            dir_path (string): path to output firectory
            filename (string): name of the file 
    Output  param (dictionary of tensors): FDN() net parameters
            param_np (dictionary of numpy arrays): DiffGFDN() net parameters
    """
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

    param = fdn2dir(net)
    param_np = {}
    for name, value in param.items():
        try:
            param_np[name] = value.squeeze().cpu().numpy()
        except AttributeError:
            param_np[name] = value
    # save parameters in numpy format
    savemat(os.path.join(dir_path, filename), param_np)

    return param, param_np


def save_colorless_fdn_parameters(net: ColorlessFDN, dir_path: str,
                                  filename: str) -> ColorlessFDNResults:
    """
    Save parameters of ColorlessFDN() net to .pkl file 
    Args    net (nn.Module): trained FDN() network
            dir_path (string): path to output firectory
            filename (string): name of the file 
    Output  ColorlessFDNResults: dataclass containing the results of optimisation
    """
    if not os.path.exists(dir_path):
        os.makedirs(dir_path)

    param = fdn2dir(net)
    param_np = {}
    for name, value in param.items():
        try:
            param_np[name] = value.squeeze().cpu().numpy()
        except AttributeError:
            param_np[name] = value

    colorless_fdn_params = ColorlessFDNResults(
        opt_input_gains=param_np['input_gains'],
        opt_output_gains=param_np['output_gains'],
        opt_feedback_matrix=param_np['feedback_matrix'])
    # save parameters in numpy format
    with open(os.path.join(dir_path, filename), "wb") as f:
        pickle.dump(colorless_fdn_params, f)

    return colorless_fdn_params


def fdn2dir(net: Union[DiffGFDN, ColorlessFDN]):
    """
    Save learnable parameters to a dictionary  
    Args    net (nn.Module): trained FDN() network
    Output  d (dictionary of tensors): FDN() net parameters 
    """
    d = {}  # empty dictionary
    # from parameter dictionary of model
    d = net.get_param_dict()

    # MLP learned weights and biases
    for name, param in net.named_parameters():
        if param.requires_grad and name not in d.keys():
            d[name] = param.data

    return d


def save_loss(train_loss: List,
              output_dir: str,
              save_plot=True,
              filename: str = '',
              xaxis_label: Optional[str] = "epoch #"):
    """
    Save training and validation loss values in .mat format
    Args    train_loss (list): training loss values at each epoch
            output_dir (string): path to output directory
            save_plot (bool): if True saves the plot of the losses in .pdf format
            filename (string): additional string to add before .pdf and .mat
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    losses = {}
    losses['train'] = train_loss
    n_epochs = len(train_loss)

    if save_plot:
        plt.plot(range(1, n_epochs + 1), train_loss)
        plt.xlabel(xaxis_label)
        plt.ylabel('loss')
        plt.savefig(os.path.join(output_dir, filename + '.pdf'))
    savemat(os.path.join(output_dir, 'losses_' + filename + '.mat'), losses)


def data_parser_var_receiver_pos(
        config_dict: DiffGFDNConfig,
        num_freq_bins: Optional[int] = None) -> RoomDataset:
    """
    Parse the training data for training over a grid of receiver positions (could belong to different rooms)
    Args:
        config_dict (DiffGFDNConfig): config dictionary
        num_freq_bins (int): number of frequency bins to train on
    Returns:
        RoomDataset: object of data type RoomDataset with all the room information
    """
    if "3room_FDTD" in config_dict.room_dataset_path:
        # read the coupled room dataset
        room_data = ThreeRoomDataset(Path(
            config_dict.room_dataset_path).resolve(),
                                     config_dict=config_dict)
    else:
        room_data = convert_common_slopes_rir_to_room_dataset(
            config_dict.room_dataset_path, num_freq_bins)

    return room_data


def data_parser_single_receiver_pos(
        config_dict: DiffGFDNConfig,
        num_freq_bins: Optional[int] = None
) -> Tuple[RIRData, RoomDataset, str]:
    """
    Parse the training data for a single receiver position
    Args:
        config_dict (DiffGFDNConfig): config dictionary
        num_freq_bins (int): number of frequency bins to train on
    Returns:
        RIRData, RoomDataset, str: single position dataset, room dataset and the name of the ir
    """
    if "3room_FDTD" in config_dict.room_dataset_path:
        # read the coupled room dataset
        room_data = ThreeRoomDataset(
            Path(config_dict.room_dataset_path).resolve(), config_dict)

    # from the synthetic dataset created in slope2rir
    else:
        room_data = convert_common_slopes_rir_to_room_dataset(
            config_dict.room_dataset_path, num_freq_bins)

    # create a dataset for a single measured IR in the room dataset
    ir_path = Path(config_dict.ir_path).resolve()
    match = re.search(r'ir_\([^)]+\)', config_dict.ir_path)
    ir_name = match.group()

    # find receiver position from string
    match = re.search(r'ir_\(([^,]+), ([^,]+), ([^,]+)\)', ir_name)
    # Convert the extracted values to floats
    x, y, z = map(float, match.groups())
    rec_pos = np.array([x, y, z])

    # find amplitudes corresponding to the receiver position
    rec_pos_idx = np.where(
        np.all(room_data.receiver_position == rec_pos, axis=1))[0]
    amplitudes = room_data.amplitudes[..., rec_pos_idx]

    # if the reference IR does not exist, create it from the dataset
    if not os.path.isfile(str(ir_path)):
        logger.warning("RIR does not exist in path, creating it...")
        room_data.save_individual_irs(directory=Path(ir_path).parent.resolve())

    rir_data = RIRData(ir_path,
                       common_decay_times=room_data.common_decay_times,
                       band_centre_hz=room_data.band_centre_hz,
                       amplitudes=amplitudes,
                       nfft=num_freq_bins)

    return rir_data, room_data, ir_name


def run_training_colorless_fdn(
        config_dict: DiffGFDNConfig,
        num_freq_bins: int) -> List[ColorlessFDNResults]:
    """
    Run the training for a colorless prototype
    Returns:
        A list of ColorlessFDNResults dataclass, each for one FDN in the GFDN
    """
    logger.info("Training a colorless prototype")
    trainer_config = config_dict.trainer_config

    # prepare the training and validation data for DiffGFDN
    train_dataset, valid_dataset = load_colorless_fdn_dataset(
        num_freq_bins,
        trainer_config.device,
        config_dict.colorless_fdn_config.train_valid_split,
        config_dict.colorless_fdn_config.batch_size,
    )

    params_opt = []
    num_delay_lines_per_group = int(config_dict.num_delay_lines /
                                    config_dict.num_groups)
    for i in range(config_dict.num_groups):

        model = ColorlessFDN(
            config_dict.sample_rate,
            config_dict.delay_length_samps[i *
                                           num_delay_lines_per_group:(i + 1) *
                                           num_delay_lines_per_group],
            trainer_config.device)

        # set default device
        torch.set_default_device(trainer_config.device)
        # move model to device (cuda or cpu)
        model = model.to(trainer_config.device)
        # create the trainer object
        trainer = ColorlessFDNTrainer(model, trainer_config,
                                      config_dict.colorless_fdn_config)

        # save initial parameters and ir
        save_colorless_fdn_parameters(
            trainer.net, trainer_config.train_dir + "colorless-fdn/",
            f'parameters_init_group={i + 1}.pkl')

        # train the network
        trainer.train(train_dataset, valid_dataset)
        # save final trained parameters
        params_opt.append(
            save_colorless_fdn_parameters(
                trainer.net, trainer_config.train_dir + "colorless-fdn/",
                f'parameters_opt_group={i + 1}.pkl'))

        # save loss evolution
        save_loss(trainer.train_loss,
                  trainer_config.train_dir + "colorless-fdn/",
                  save_plot=True,
                  filename=f'training_loss_vs_epoch_group={i + 1}')

    return params_opt


def run_training_var_receiver_pos(config_dict: DiffGFDNConfig):
    """
    Run the training for the differentiable GFDN for a grid of different receiver positions, and save
    its parameters
    Args:
        config_dict (DiffGFDNTrainConfig): configuration parameters for training
    """
    logger.info("Training over a grid of listener positions")

    # get the data
    room_data = data_parser_var_receiver_pos(
        config_dict, num_freq_bins=config_dict.trainer_config.num_freq_bins)

    # add number of groups to the config dictionary
    config_dict = config_dict.copy(update={"num_groups": room_data.num_rooms})
    assert config_dict.num_delay_lines % config_dict.num_groups == 0, "Delay lines must be \
    divisible by number of groups in network"

    if config_dict.sample_rate != room_data.sample_rate:
        logger.warn("Config sample rate does not match data, alterning it")
        config_dict.sample_rate = room_data.sample_rate

    # get the training config
    trainer_config = config_dict.trainer_config
    # update num_freq_bins in pydantic class
    trainer_config = trainer_config.model_copy(
        update={"num_freq_bins": room_data.num_freq_bins})
    # also update the calculation of reduced_pole_radius
    trainer_config = trainer_config.calculate_reduced_pole_radius(
        trainer_config)

    if config_dict.colorless_fdn_config.use_colorless_prototype:
        colorless_fdn_params = run_training_colorless_fdn(
            config_dict, room_data.num_freq_bins)
    else:
        colorless_fdn_params = None

    # prepare the training and validation data for DiffGFDN
    train_dataset, valid_dataset = load_dataset(
        room_data,
        trainer_config.device,
        trainer_config.train_valid_split,
        trainer_config.batch_size,
        new_sampling_radius=1.0 / trainer_config.reduced_pole_radius,
    )

    # initialise the model
    model = DiffGFDNVarReceiverPos(
        room_data.sample_rate,
        room_data.num_rooms,
        config_dict.delay_length_samps,
        trainer_config.device,
        config_dict.feedback_loop_config,
        config_dict.output_filter_config,
        config_dict.use_absorption_filters,
        common_decay_times=room_data.common_decay_times,
        band_centre_hz=room_data.band_centre_hz,
        colorless_fdn_params=colorless_fdn_params,
    )
    # set default device
    torch.set_default_device(trainer_config.device)
    # move model to device (cuda or cpu)
    model = model.to(trainer_config.device)
    # create the trainer object
    trainer = VarReceiverPosTrainer(model, trainer_config)

    # save initial parameters and ir
    save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                              'parameters_init.mat')

    # train the network
    trainer.train(train_dataset)
    # save final trained parameters
    save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                              'parameters_opt.mat')
    # save loss evolution
    save_loss(trainer.train_loss,
              trainer_config.train_dir,
              save_plot=True,
              filename='training_loss_vs_epoch')

    # test the network with the validation set
    trainer.validate(valid_dataset)
    # save the validation loss
    save_loss(trainer.valid_loss,
              trainer_config.train_dir,
              save_plot=True,
              filename='test_loss_vs_position',
              xaxis_label='Position #')


def run_training_single_pos(config_dict: DiffGFDNConfig):
    """
    Run the training for the differentiable GFDN for a single RIR measurement, and save its parameters
    Args:
        config_dict (DiffGFDNTrainConfig): configuration parameters for training
    """
    logger.info("Training for a single RIR measurement")

    # get the data
    rir_data, room_data, ir_name = data_parser_single_receiver_pos(
        config_dict, num_freq_bins=config_dict.trainer_config.num_freq_bins)

    # add number of groups to the config dictionary
    config_dict = config_dict.copy(update={"num_groups": room_data.num_rooms})
    assert config_dict.num_delay_lines % config_dict.num_groups == 0, "Delay lines must be \
    divisible by number of groups in network"

    if config_dict.sample_rate != room_data.sample_rate:
        logger.warn("Config sample rate does not match data, alterning it")
        config_dict.sample_rate = room_data.sample_rate

    # get the training config
    trainer_config = config_dict.trainer_config
    # update num_freq_bins in pydantic class
    trainer_config = trainer_config.model_copy(
        update={"num_freq_bins": rir_data.num_freq_bins})

    # prepare the training and validation data for DiffGFDN
    if trainer_config.train_valid_split < 1.0:
        logger.warning('There can be no data in the validation set!')
    if trainer_config.batch_size != rir_data.num_freq_bins:
        logger.warning(
            "Cannot train in batches here. Training on the full unit circle")
        trainer_config = trainer_config.copy(
            update={"batch_size": rir_data.num_freq_bins})

    # whether to use a colorless FDN to get input-output gains and feedback matrix
    if config_dict.colorless_fdn_config.use_colorless_prototype:
        colorless_fdn_params = run_training_colorless_fdn(
            config_dict, room_data.num_freq_bins)
    else:
        colorless_fdn_params = None

    train_dataset = load_dataset(rir_data,
                                 trainer_config.device,
                                 trainer_config.train_valid_split,
                                 trainer_config.batch_size,
                                 shuffle=False,
                                 new_sampling_radius=1.0 /
                                 trainer_config.reduced_pole_radius)

    # initialise the model
    model = DiffGFDNSinglePos(room_data.sample_rate,
                              room_data.num_rooms,
                              config_dict.delay_length_samps,
                              trainer_config.device,
                              config_dict.feedback_loop_config,
                              config_dict.output_filter_config,
                              config_dict.use_absorption_filters,
                              common_decay_times=room_data.common_decay_times,
                              band_centre_hz=room_data.band_centre_hz,
                              colorless_fdn_params=colorless_fdn_params)
    # set default device
    torch.set_default_device(trainer_config.device)
    # move model to device (cuda or cpu)
    model = model.to(trainer_config.device)
    # create the trainer object
    trainer = SinglePosTrainer(model, trainer_config, filename=ir_name)

    # save initial parameters and ir
    save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                              'parameters_init.mat')

    # train the network
    trainer.train(train_dataset)
    # save final trained parameters
    save_diff_gfdn_parameters(trainer.net, trainer_config.train_dir,
                              'parameters_opt.mat')
    # save loss evolution
    save_loss(trainer.train_loss,
              trainer_config.train_dir,
              save_plot=True,
              filename='training_loss_vs_epoch')
