from typing import Dict, List, Optional, Union

from loguru import logger
import numpy as np
from numpy.typing import ArrayLike
import torch
from torch import nn
import torchaudio.functional as Faudio


def db(x: Union[ArrayLike, torch.tensor],
       is_squared: bool = False,
       min_value: float = -200) -> Union[ArrayLike, torch.tensor]:
    """Convert values to decibels.

    Args:
        x (torch.tensor):
            value(s) to be converted to dB.
        is_squared (bool):
            Indicates whether `x` represents some power-like quantity (True) or some root-power-like quantity (False).
            Defaults to False, i.e. `x` is a root-power-like auqntity (e.g. Voltage, pressure, ...).
        min_value (float): cap the decibels to this value, cannot be lower

    Returns:
        An array with the converted values, in dB.
    """
    factor = 10.0 if is_squared else 20.0
    if torch.is_tensor(x):
        x = torch.abs(x)
        y = factor * torch.log10(x + torch.finfo(torch.float32).eps)
    else:
        x = np.abs(x)
        y = factor * np.log10(x + np.finfo(np.float32).eps)

    return y.clip(min=min_value)


def db2lin(
    x: Union[torch.tensor, ArrayLike],
    is_squared: bool = False,
) -> Union[torch.tensor, ArrayLike]:
    """Convert from decibels to linear

    Args:
        x (ArrayLike): value(s) to be converted

    Returns:
        (ArrayLike): values converted to linear
    """
    exp_factor = 0.1 if is_squared else 0.05
    if torch.is_tensor(x):
        return torch.pow(10.0, x * exp_factor)
    else:
        return np.power(10.0, x * exp_factor)


def ms_to_samps(ms: Union[float, ArrayLike],
                fs: float) -> Union[int, ArrayLike]:
    """
    Convert ms to samples
    Args:
        ms (float or ArrayLike): time in ms
        fs (float): sampling rate
    Returns:
        int, ArrayLike: time in samples
    """
    samp = ms * 1e-3 * fs
    if np.isscalar(samp):
        return int(samp)
    else:
        return samp.astype(np.int32)


def hertz2rad(hertz: torch.Tensor, fs: float):
    r"""
    Convert frequency from cycles per second to rad
    .. math::
        \omega = \frac{2\pi f}{f_s}
    where :math:`f` is the frequency in Hz and :math:`f_s` is the sampling frequency in Hz.

    **Args**:
        - hertz (torch.Tensor): The frequency in Hz.
        - fs (int): The sampling frequency in Hz.
    """
    return torch.divide(hertz, fs) * 2 * torch.pi


def rad2hertz(rad: torch.Tensor, fs: float):
    r"""
    Convert frequency from rad to cycles per second
    .. math::
        f = \frac{\omega f_s}{2\pi}
    where :math:`\omega` is the frequency in rad and :math:`f_s` is the sampling frequency in Hz.

    **Args**:
        - rad (torch.Tensor): The frequency in rad.
        - fs (int): The sampling frequency in Hz.
    """
    return torch.divide(rad * fs, 2 * torch.pi)


def get_frequency_samples(num: int, device: Optional[torch.device] = None):
    r"""
    Get frequency samples (in radians) sampled at linearly spaced points along the unit circle.

    **Args**
        - num (int): number of frequency samples
        - device (torch.device, optional): The device of constructed tensors. Default: None.

    **Returns**
        - frequency samples in radians between [0, pi]
    """
    angle = torch.linspace(0, 1, steps=num, device=device)
    mag = torch.ones(num, device=device)
    return torch.polar(mag, angle * np.pi)


def to_complex(X: torch.Tensor):
    """Make a real tensor complex"""
    return torch.complex(X, torch.zeros_like(X))


@torch.no_grad()
def get_response(x: Union[Dict, torch.tensor], net: nn.Module):
    """
    Get impulse and magnitude resoponse generated by the learned parameters of the DiffGFDN
    Args    net (nn.Module): trained GFDN network
            x (Dict): dictionary of features and labels
    Output  h (torch.tensor): GFDN impulse response
            H (torch.tensor): GFDN frequency response
            H_sub_fdn (torch.tensor): frequency response of each FDN in the GFDN
    """
    with torch.no_grad():
        try:
            if net.use_colorless_loss:
                H, H_sub_fdn = net(x)
                h = torch.fft.irfft(H, dim=-1)
                return H, H_sub_fdn, h
            else:
                H = net(x)
                h = torch.fft.irfft(H, dim=-1)
                return H, h
        except AttributeError as e:
            logger.warning(e)
            H = net(x)
            h = torch.fft.irfft(H, dim=-1)
            return H, h


def get_str_results(epoch: int = None,
                    train_loss: float = None,
                    time=None,
                    individual_losses: Optional[List[Dict]] = None):
    """Construct the string that has to be print at the end of the epoch"""
    to_print = ''

    if epoch is not None:
        to_print += 'epoch: {:3d} '.format(epoch)

    if train_loss is not None:
        to_print += ', train_loss: {:6.4f} '.format(train_loss[-1])

    if time is not None:
        to_print += ', time: {:6.4f}s'.format(time)

    if individual_losses is not None:
        last_loss = individual_losses[-1]
        for key, value in last_loss.items():
            to_print += f', {key}: {value: 3f}'

    return to_print


def hermitian_conjugate_polynomial_matrix(A: torch.tensor) -> torch.tensor:
    """
    For a polynomail matrix A(z), calculate A(z^{-1})^H
    Size of the matix is N x N x p, with polynomials along the last axis
    """
    Aconj = torch.conj(torch.flip(A, dims=[-1]))
    Aconj = Aconj.permute(1, 0, 2)
    return Aconj


def matrix_convolution(A: torch.tensor, B: torch.tensor) -> torch.tensor:
    """
    Take 2 polynomial matrices of orders (M, N, K) and (P, Q, R)
    and convolve them to produce a polynomial matrix of order (M, Q, R+K-1)
    """
    M, N, K = A.shape
    P, Q, R = B.shape
    assert N == P, "matrices must be commutable"

    C = torch.zeros((M, Q, K + R - 1), dtype=A.dtype)
    A = A.permute(2, 0, 1)
    B = B.permute(2, 0, 1)
    C = C.permute(2, 0, 1)

    for row in range(M):
        for col in range(Q):
            for it in range(N):
                # the unsqueeze operation is required because conv1d works with 3D tensors
                C[:, row, col] += Faudio.convolve(A[:, row, it],
                                                  B[:, it, col],
                                                  mode='full')

    C = C.permute(1, 2, 0)
    return C


def is_paraunitary(A: torch.tensor, max_tol: float = 1e-6) -> bool:
    """
    Check if a polynomial matrix A of size NxNxP is paraunitary by ensuring
    A(z) A(z^{-1})^H = I
    Args:
        A(NDArray): polynomial matrix of order NxNxp
        max_tol (float): maximum deviation from identity matrix
    Returns:
        bool: whether the matrix is PU
    """
    N = A.shape[0]
    p = A.shape[-1]

    # A(z^{-1})^H
    Aconj = hermitian_conjugate_polynomial_matrix(A)
    # A(z) A(z^{-1})^H
    T = matrix_convolution(A, Aconj)

    # must be close to 0
    T[:, :, p - 1] = T[:, :, p - 1] - torch.eye(N)
    max_off_diag_value = torch.max(torch.abs(T))
    return max_off_diag_value < max_tol, max_off_diag_value


def is_unitary(A: torch.tensor, max_tol: float = 1e-6) -> bool:
    """Check if a square matrix A is unitary"""
    N = A.shape[0]
    Aconj = torch.conj(A.T)
    T = torch.mm(A, Aconj)
    T -= torch.eye(N)
    max_off_diag_value = torch.max(torch.abs(T))
    return max_off_diag_value < max_tol, max_off_diag_value
