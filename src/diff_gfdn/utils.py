from typing import Dict, List, Optional, Union

from loguru import logger
import matplotlib.pyplot as plt
import numpy as np
from numpy.typing import ArrayLike, NDArray
from scipy.fft import irfft, rfft, rfftfreq
import torch
from torch import nn
import torchaudio.functional as Faudio

# pylint: disable=E1126


def db(x: Union[ArrayLike, torch.tensor],
       is_squared: bool = False,
       min_value: float = -200) -> Union[ArrayLike, torch.tensor]:
    """Convert values to decibels.

    Args:
        x (torch.tensor):
            value(s) to be converted to dB.
        is_squared (bool):
            Indicates whether `x` represents some power-like quantity (True) or some root-power-like quantity (False).
            Defaults to False, i.e. `x` is a root-power-like auqntity (e.g. Voltage, pressure, ...).
        min_value (float): cap the decibels to this value, cannot be lower

    Returns:
        An array with the converted values, in dB.
    """
    factor = 10.0 if is_squared else 20.0
    if torch.is_tensor(x):
        x = torch.abs(x)
        y = factor * torch.log10(x + torch.finfo(torch.float32).eps)
    else:
        x = np.abs(x)
        y = factor * np.log10(x + np.finfo(np.float32).eps)

    return y.clip(min=min_value)


def db2lin(
    x: Union[torch.tensor, ArrayLike],
    is_squared: bool = False,
) -> Union[torch.tensor, ArrayLike]:
    """Convert from decibels to linear

    Args:
        x (ArrayLike): value(s) to be converted

    Returns:
        (ArrayLike): values converted to linear
    """
    exp_factor = 0.1 if is_squared else 0.05
    if torch.is_tensor(x):
        return torch.pow(10.0, x * exp_factor)
    else:
        return np.power(10.0, x * exp_factor)


def ms_to_samps(ms: Union[float, ArrayLike, torch.Tensor],
                fs: float) -> Union[int, ArrayLike, torch.Tensor]:
    """
    Convert ms to samples
    Args:
        ms (float or ArrayLike): time in ms
        fs (float): sampling rate
    Returns:
        int, ArrayLike: time in samples
    """
    if isinstance(ms, torch.Tensor):
        samp = ms * 1e-3 * torch.tensor(fs)
        return samp.int()
    else:
        samp = ms * 1e-3 * fs
        if np.isscalar(samp):
            return int(samp)
        else:
            return samp.astype(np.int32)


def samps_to_ms(samps: Union[int, ArrayLike, torch.Tensor],
                fs: float) -> Union[float, ArrayLike, torch.Tensor]:
    """
    Convert samples to ms
    Args:
        samps (int or ArrayLike): time in samples
        fs (float): sampling rate
    Returns:
        float, ArrayLike: time in ms
    """
    if isinstance(samps, torch.Tensor):
        ms = samps.float() / torch.tensor(fs) * 1e3
    else:
        ms = float(samps) / fs * 1e3
    return ms


def hertz2rad(hertz: torch.Tensor, fs: float):
    r"""
    Convert frequency from cycles per second to rad
    .. math::
        \omega = \frac{2\pi f}{f_s}
    where :math:`f` is the frequency in Hz and :math:`f_s` is the sampling frequency in Hz.

    **Args**:
        - hertz (torch.Tensor): The frequency in Hz.
        - fs (int): The sampling frequency in Hz.
    """
    return torch.divide(hertz, fs) * 2 * torch.pi


def rad2hertz(rad: torch.Tensor, fs: float):
    r"""
    Convert frequency from rad to cycles per second
    .. math::
        f = \frac{\omega f_s}{2\pi}
    where :math:`\omega` is the frequency in rad and :math:`f_s` is the sampling frequency in Hz.

    **Args**:
        - rad (torch.Tensor): The frequency in rad.
        - fs (int): The sampling frequency in Hz.
    """
    return torch.divide(rad * fs, 2 * torch.pi)


def get_frequency_samples(num: int, device: Optional[torch.device] = None):
    r"""
    Get frequency samples (in radians) sampled at linearly spaced points along the unit circle.

    **Args**
        - num (int): number of frequency samples
        - device (torch.device, optional): The device of constructed tensors. Default: None.

    **Returns**
        - frequency samples in radians between [0, pi]
    """
    angle = torch.linspace(0, 1, steps=num, device=device)
    mag = torch.ones(num, device=device)
    return torch.polar(mag, angle * np.pi)


def to_complex(X: torch.Tensor):
    """Make a real tensor complex"""
    return torch.complex(X, torch.zeros_like(X))


@torch.no_grad()
def get_response(x: Union[Dict, torch.tensor],
                 net: nn.Module,
                 output_scalars: Optional[torch.tensor] = None):
    """
    Get impulse and magnitude resoponse generated by the learned parameters of the DiffGFDN
    Args    net (nn.Module): trained GFDN network
            x (Dict): dictionary of features and labels
            output_scalars (optional): fixed array of gains to be used as receiver_gains
    Output  h (torch.tensor): GFDN impulse response
            H (torch.tensor): GFDN frequency response
            H_sub_fdn (torch.tensor): frequency response of each FDN in the GFDN
    """
    with torch.no_grad():
        try:
            if net.use_colorless_loss:
                if output_scalars is not None:
                    H, H_sub_fdn = net(x, output_scalars)
                else:
                    H, H_sub_fdn = net(x)
                h = torch.fft.irfft(H, dim=-1)
                return H, H_sub_fdn, h
            else:
                H = net(x)
                h = torch.fft.irfft(H, dim=-1)
                return H, h
        except AttributeError as e:
            logger.warning(e)
            H, _ = net(x)
            h = torch.fft.irfft(H, dim=-1)
            return H, h


def get_str_results(epoch: int = None,
                    train_loss: float = None,
                    time=None,
                    individual_losses: Optional[List[Dict]] = None):
    """Construct the string that has to be print at the end of the epoch"""
    to_print = ''

    if epoch is not None:
        to_print += 'epoch: {:3d} '.format(epoch)

    if train_loss is not None:
        to_print += ', train_loss: {:6.4f} '.format(train_loss[-1])

    if time is not None:
        to_print += ', time: {:6.4f}s'.format(time)

    if individual_losses is not None:
        last_loss = individual_losses[-1]
        for key, value in last_loss.items():
            to_print += f', {key}: {value: 3f}'

    return to_print


def hermitian_conjugate_polynomial_matrix(A: torch.tensor) -> torch.tensor:
    """
    For a polynomail matrix A(z), calculate A(z^{-1})^H
    Size of the matix is N x N x p, with polynomials along the last axis
    """
    Aconj = torch.conj(torch.flip(A, dims=[-1]))
    Aconj = Aconj.permute(1, 0, 2)
    return Aconj


def matrix_convolution(A: torch.tensor, B: torch.tensor) -> torch.tensor:
    """
    Take 2 polynomial matrices of orders (M, N, K) and (P, Q, R)
    and convolve them to produce a polynomial matrix of order (M, Q, R+K-1)
    """
    M, N, K = A.shape
    P, Q, R = B.shape
    assert N == P, "matrices must be commutable"

    C = torch.zeros((M, Q, K + R - 1), dtype=A.dtype)
    A = A.permute(2, 0, 1)
    B = B.permute(2, 0, 1)
    C = C.permute(2, 0, 1)

    for row in range(M):
        for col in range(Q):
            for it in range(N):
                # the unsqueeze operation is required because conv1d works with 3D tensors
                C[:, row, col] += Faudio.convolve(A[:, row, it],
                                                  B[:, it, col],
                                                  mode='full')

    C = C.permute(1, 2, 0)
    return C


def is_paraunitary(A: torch.tensor, max_tol: float = 1e-6) -> bool:
    """
    Check if a polynomial matrix A of size NxNxP is paraunitary by ensuring
    A(z) A(z^{-1})^H = I
    Args:
        A(NDArray): polynomial matrix of order NxNxp
        max_tol (float): maximum deviation from identity matrix
    Returns:
        bool: whether the matrix is PU
    """
    N = A.shape[0]
    p = A.shape[-1]

    # A(z^{-1})^H
    Aconj = hermitian_conjugate_polynomial_matrix(A)
    # A(z) A(z^{-1})^H
    T = matrix_convolution(A, Aconj)

    # must be close to 0
    T[:, :, p - 1] = T[:, :, p - 1] - torch.eye(N)
    max_off_diag_value = torch.max(torch.abs(T))
    return max_off_diag_value < max_tol, max_off_diag_value


def is_unitary(A: torch.tensor, max_tol: float = 1e-6) -> bool:
    """Check if a square matrix A is unitary"""
    N = A.shape[0]
    Aconj = torch.conj(A.T)
    T = torch.mm(A, Aconj)
    T -= torch.eye(N)
    max_off_diag_value = torch.max(torch.abs(T))
    return max_off_diag_value < max_tol, max_off_diag_value


def spectral_flatness(X: ArrayLike, eps: float = 1e-10):
    """
    Compute spectral flatness of a power spectrum or magnitude spectrum.

    Args:
        X (numpy.ndarray): Power spectrum or magnitude spectrum of shape (K,).
        eps (float): Small value to avoid log(0).

    Returns:
        float: Spectral flatness value between 0 and 1.
    """
    X = np.abs(X)  # Ensure magnitude spectrum
    geometric_mean = np.exp(np.mean(np.log(X + eps)))  # Avoid log(0)
    arithmetic_mean = np.mean(X + eps)

    return geometric_mean / arithmetic_mean


def normalised_echo_density(rir: NDArray,
                            fs: float,
                            window_length_ms: float = 30,
                            window_type: str = 'hann',
                            use_local_avg: bool = False):
    """
    Compute the Echo Density Profile as defined by Abel.
    window_type should be one of ['rect', 'bart', 'blac', 'hamm', 'hann']
    """

    def weighted_std(signal: NDArray, window_func: NDArray,
                     use_local_avg: bool):
        """Returnsthe weighted standard deviation."""
        if use_local_avg:
            average = np.average(signal, weights=window_func)
            variance = np.average((signal - average)**2, weights=window_func)
        else:
            variance = np.average((signal)**2, weights=window_func)
        return np.sqrt(variance)

    if isinstance(rir, torch.Tensor):
        rir = rir.detach().cpu().numpy()

    # erfc(1/√2)
    ERFC = 0.3173
    window_length_samps = ms_to_samps(window_length_ms, fs)

    if not window_length_samps % 2:
        window_length_samps += 1
    half_window = int((window_length_samps - 1) / 2)

    padded_rir = np.zeros(len(rir) + 2 * half_window)
    padded_rir[half_window:-half_window] = rir
    output = np.zeros(len(rir) + 2 * half_window)

    if window_type == 'rect':
        window_func = np.ones(window_length_samps)
    elif window_type == 'hann':
        window_func = np.hanning(window_length_samps)
    elif window_type == 'hamm':
        window_func = np.hamming(window_length_samps)
    elif window_type == 'black':
        window_func = np.blackman(window_length_samps)
    elif window_type == 'bart':
        window_func = np.bartlett(window_length_samps)
    else:
        raise ValueError('Unavailable window type.')
    window_func = window_func / sum(window_func)

    for cursor in range(len(rir)):
        frame = padded_rir[cursor:cursor + window_length_samps]
        std = weighted_std(frame, window_func, use_local_avg)

        count = ((np.abs(frame) > std) * window_func).sum()

        output[cursor] = (1 / ERFC) * count

    ned = output[:-window_length_samps]
    return ned


def get_time_reversed_fir_filterbank(
        h: NDArray,
        freq_bins_rad: ArrayLike,
        num_freq_bins: int,
        plot: bool = False,
        freq_labels: Optional[List] = None) -> NDArray:
    """
    Time reverse an FIR filterbank according to flip{H}_k(z) = H_k(z^{-1)) / sum_i H_i(z) H_i(z^{-1})
    Args:
        h : FIR filter coefficients of size num_bands x num_coeffs
        freq_bins_rad: the frequency bins in radians for which the response will be calculated
        num_freq_bins: number of points for FFT
        plot: whether to plot the response or not
        freq_labels: the labels of the different frequency bands
    Returns:
        h_time_rev: frequency response of time reversed FIR filter, of shape num_bands x num_freq_bins
    """
    num_bands, num_coeffs = h.shape
    num = np.conj(rfft(h, n=num_freq_bins, axis=-1))
    norm_factor = np.zeros((num_bands, len(freq_bins_rad)), dtype=np.float64)
    # calculate normalising factor
    for b_idx in range(num_bands):
        cur_h = h[b_idx, :]

        # Compute autocorrelation (sum_coeffs for all k at once)
        sum_coeffs = np.array([
            np.dot(cur_h[:num_coeffs - k], cur_h[k:])
            for k in range(num_coeffs)
        ])

        # Compute cosine modulation for all k at once and sum over k
        norm_factor[b_idx, :] = 2 * np.sum(sum_coeffs[:, None] * np.cos(
            np.arange(num_coeffs)[:, None] * freq_bins_rad),
                                           axis=0)

    h_time_rev = num / np.sum(norm_factor, axis=0)
    if plot:
        fig, ax = plt.subplots(3, 1)
        ax[0].semilogx(
            freq_bins_rad,
            db(rfft(h, n=num_freq_bins, axis=-1)).T,
            label=[f"{freq_labels[k]} Hz" for k in range(len(freq_labels))])
        ax[0].set_title('Original mag response')
        ax[0].legend()
        ax[1].semilogx(freq_bins_rad, db(norm_factor).T)
        ax[1].set_title('Denominator mag response')
        ax[2].semilogx(
            freq_bins_rad,
            db(h_time_rev).T,
            label=[f"{freq_labels[k]} Hz" for k in range(len(freq_labels))])
        ax[2].set_title('Time reversed mag response')
        fig.suptitle('Time reversed FIR filterbank')
        plt.show()

    return h_time_rev


def time_reversed_filtering(
        input_signal: NDArray,
        subband_filters: NDArray,
        time_axis: int = 0,
        plot: bool = False,
        freq_labels: Optional[List[int]] = None) -> NDArray:
    """
    Time reversed filtering of the input_signal with the time-reversed version of subband_filters.
    Ensure linear convolution instead of circular convolution by zero padding both signals
    Args:
        input_signal (ArrayLike): input signal in the time domain, of size num_samps x num_chans
        subband_filters (NDArray): FIR filterbank coefficients of shape (num_bands, num_coeffs)
        time_axis (int): time axis in the input signal
        plot (bool): whether to plot the time reversed filter response
        freq_labels (List[int]): centre frequencies of the filterbank
    Returns:
        NDArray: time domain filtered signal of shape (ir_len, num_bands)
    """
    ir_len = input_signal.shape[time_axis]
    fft_size = 2**np.ceil(np.log2(ir_len)).astype(
        np.int32) + subband_filters.shape[-1] - 1
    freq_bins_rad = rfftfreq(fft_size) * 2 * np.pi

    time_rev_filterbank_resp = get_time_reversed_fir_filterbank(
        subband_filters,
        freq_bins_rad,
        fft_size,
        plot=plot,
        freq_labels=freq_labels)
    input_signal_resp = rfft(input_signal, n=fft_size, axis=time_axis)

    # Expand signal freq response for broadcasting
    if input_signal.ndim == 1:
        input_signal_resp = input_signal_resp[:, np.newaxis]

    # Element-wise multiply each band’s response
    filtered_signal_time_rev_freq_resp = np.einsum('bk, kn -> bkn',
                                                   time_rev_filterbank_resp,
                                                   input_signal_resp)
    # shape: (num_freq_bins, num_chans, num_bands)
    filtered_signal_time_rev_freq_resp = filtered_signal_time_rev_freq_resp.transpose(
        1, -1, 0)

    # Time-domain signals per band
    filtered_signal_time_rev = irfft(
        filtered_signal_time_rev_freq_resp, n=fft_size,
        axis=0)[:ir_len, ...]  # shape: (ir_len, num_chans, num_bands)

    return filtered_signal_time_rev
